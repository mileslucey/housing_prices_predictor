{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox1p\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, Imputer\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.linear_model import Ridge\n",
    "# from yellowbrick.regressor import ResidualsPlot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set maximum rows to a high number\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "training_data = pd.read_csv(\"02-cleaned_data/cleaned_training.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a scatter plot compaing home price and home square feet\n",
    "plt.scatter(training_data['GrLivArea'],training_data['SalePrice'],color=\"slateblue\",alpha=0.3)\n",
    "plt.title(\"Home Price Versus Square Feet\")\n",
    "plt.xlabel(\"Square Feet\")\n",
    "plt.ylabel(\"Home Price (USD)\")\n",
    "plt.grid(False)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop extreme outliers\n",
    "training_data.drop(index = training_data[(training_data.GrLivArea>4000) & (training_data.SalePrice<300000)].index.tolist(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a scatter plot compaing home price and home square feet\n",
    "plt.scatter(training_data['GrLivArea'],training_data['SalePrice'],color=\"slateblue\",alpha=0.3)\n",
    "plt.title(\"Home Price Versus Square Feet\")\n",
    "plt.xlabel(\"Square Feet\")\n",
    "plt.ylabel(\"Home Price (USD)\")\n",
    "plt.grid(False)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                    \n",
       "1           60       RL         65.0     8450   Pave  None      Reg   \n",
       "2           20       RL         80.0     9600   Pave  None      Reg   \n",
       "3           60       RL         68.0    11250   Pave  None      IR1   \n",
       "4           70       RL         60.0     9550   Pave  None      IR1   \n",
       "5           60       RL         84.0    14260   Pave  None      IR1   \n",
       "\n",
       "   LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "Id                                                                     \n",
       "1          Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "2          Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "3          Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "4          Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
       "5          Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
       "\n",
       "   Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                       \n",
       "1        Norm     1Fam     2Story            7            5       2003   \n",
       "2        Norm     1Fam     1Story            6            8       1976   \n",
       "3        Norm     1Fam     2Story            7            5       2001   \n",
       "4        Norm     1Fam     2Story            7            5       1915   \n",
       "5        Norm     1Fam     2Story            8            5       2000   \n",
       "\n",
       "    YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "Id                                                                       \n",
       "1           2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "2           1976     Gable  CompShg     MetalSd     MetalSd       None   \n",
       "3           2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "4           1970     Gable  CompShg     Wd Sdng     Wd Shng       None   \n",
       "5           2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "\n",
       "    MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "Id                                                                             \n",
       "1        196.0        Gd        TA      PConc       Gd       TA           No   \n",
       "2          0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
       "3        162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
       "4          0.0        TA        TA     BrkTil       TA       Gd           No   \n",
       "5        350.0        Gd        TA      PConc       Gd       TA           Av   \n",
       "\n",
       "   BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "Id                                                                             \n",
       "1           GLQ         706          Unf           0        150          856   \n",
       "2           ALQ         978          Unf           0        284         1262   \n",
       "3           GLQ         486          Unf           0        434          920   \n",
       "4           ALQ         216          Unf           0        540          756   \n",
       "5           GLQ         655          Unf           0        490         1145   \n",
       "\n",
       "   Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "Id                                                                             \n",
       "1     GasA        Ex          Y      SBrkr       856       854             0   \n",
       "2     GasA        Ex          Y      SBrkr      1262         0             0   \n",
       "3     GasA        Ex          Y      SBrkr       920       866             0   \n",
       "4     GasA        Gd          Y      SBrkr       961       756             0   \n",
       "5     GasA        Ex          Y      SBrkr      1145      1053             0   \n",
       "\n",
       "    GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "Id                                                                            \n",
       "1        1710             1             0         2         1             3   \n",
       "2        1262             0             1         2         0             3   \n",
       "3        1786             1             0         2         1             3   \n",
       "4        1717             1             0         1         0             3   \n",
       "5        2198             1             0         2         1             4   \n",
       "\n",
       "    KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "Id                                                                              \n",
       "1              1          Gd             8        Typ           0        None   \n",
       "2              1          TA             6        Typ           1          TA   \n",
       "3              1          Gd             6        Typ           1          TA   \n",
       "4              1          Gd             7        Typ           1          Gd   \n",
       "5              1          Gd             9        Typ           1          TA   \n",
       "\n",
       "   GarageType GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "Id                                                                          \n",
       "1      Attchd      2003.0          RFn           2         548         TA   \n",
       "2      Attchd      1976.0          RFn           2         460         TA   \n",
       "3      Attchd      2001.0          RFn           2         608         TA   \n",
       "4      Detchd      1998.0          Unf           3         642         TA   \n",
       "5      Attchd      2000.0          RFn           3         836         TA   \n",
       "\n",
       "   GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "Id                                                                            \n",
       "1          TA          Y           0           61              0          0   \n",
       "2          TA          Y         298            0              0          0   \n",
       "3          TA          Y           0           42              0          0   \n",
       "4          TA          Y           0           35            272          0   \n",
       "5          TA          Y         192           84              0          0   \n",
       "\n",
       "    ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "Id                                                                            \n",
       "1             0         0   None  None        None        0       2    2008   \n",
       "2             0         0   None  None        None        0       5    2007   \n",
       "3             0         0   None  None        None        0       9    2008   \n",
       "4             0         0   None  None        None        0       2    2006   \n",
       "5             0         0   None  None        None        0      12    2008   \n",
       "\n",
       "   SaleType SaleCondition  SalePrice  \n",
       "Id                                    \n",
       "1        WD        Normal     208500  \n",
       "2        WD        Normal     181500  \n",
       "3        WD        Normal     223500  \n",
       "4        WD       Abnorml     140000  \n",
       "5        WD        Normal     250000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data[[\"MSSubClass\",\"LotFrontage\",\"LotArea\",\"MasVnrArea\",\"Neighborhood\",\"OverallQual\",\"OverallCond\",\"YearBuilt\",\"ExterQual\",\"BsmtQual\",\"BsmtCond\",\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\",\"GrLivArea\",\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\"BedroomAbvGr\",\"KitchenAbvGr\",\"KitchenQual\",\"TotRmsAbvGrd\",\"Fireplaces\",\"FireplaceQu\",\"GarageType\",\"GarageCars\",\"GarageArea\",\"GarageQual\",\"GarageCond\",\"PoolQC\",\"YrSold\",\"SaleCondition\",\"SalePrice\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>196.0</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>856</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>None</td>\n",
       "      <td>2008</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>None</td>\n",
       "      <td>2007</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>162.0</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>920</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>None</td>\n",
       "      <td>2008</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>756</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>None</td>\n",
       "      <td>2006</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>350.0</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>1145</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>None</td>\n",
       "      <td>2008</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass  LotFrontage  LotArea  MasVnrArea Neighborhood  OverallQual  \\\n",
       "Id                                                                           \n",
       "1           60         65.0     8450       196.0      CollgCr            7   \n",
       "2           20         80.0     9600         0.0      Veenker            6   \n",
       "3           60         68.0    11250       162.0      CollgCr            7   \n",
       "4           70         60.0     9550         0.0      Crawfor            7   \n",
       "5           60         84.0    14260       350.0      NoRidge            8   \n",
       "\n",
       "    OverallCond  YearBuilt ExterQual BsmtQual BsmtCond  TotalBsmtSF  1stFlrSF  \\\n",
       "Id                                                                              \n",
       "1             5       2003        Gd       Gd       TA          856       856   \n",
       "2             8       1976        TA       Gd       TA         1262      1262   \n",
       "3             5       2001        Gd       Gd       TA          920       920   \n",
       "4             5       1915        TA       TA       Gd          756       961   \n",
       "5             5       2000        Gd       Gd       TA         1145      1145   \n",
       "\n",
       "    2ndFlrSF  GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  \\\n",
       "Id                                                                        \n",
       "1        854       1710             1             0         2         1   \n",
       "2          0       1262             0             1         2         0   \n",
       "3        866       1786             1             0         2         1   \n",
       "4        756       1717             1             0         1         0   \n",
       "5       1053       2198             1             0         2         1   \n",
       "\n",
       "    BedroomAbvGr  KitchenAbvGr KitchenQual  TotRmsAbvGrd  Fireplaces  \\\n",
       "Id                                                                     \n",
       "1              3             1          Gd             8           0   \n",
       "2              3             1          TA             6           1   \n",
       "3              3             1          Gd             6           1   \n",
       "4              3             1          Gd             7           1   \n",
       "5              4             1          Gd             9           1   \n",
       "\n",
       "   FireplaceQu GarageType  GarageCars  GarageArea GarageQual GarageCond  \\\n",
       "Id                                                                        \n",
       "1         None     Attchd           2         548         TA         TA   \n",
       "2           TA     Attchd           2         460         TA         TA   \n",
       "3           TA     Attchd           2         608         TA         TA   \n",
       "4           Gd     Detchd           3         642         TA         TA   \n",
       "5           TA     Attchd           3         836         TA         TA   \n",
       "\n",
       "   PoolQC  YrSold SaleCondition  SalePrice  \n",
       "Id                                          \n",
       "1    None    2008        Normal     208500  \n",
       "2    None    2007        Normal     181500  \n",
       "3    None    2008        Normal     223500  \n",
       "4    None    2006       Abnorml     140000  \n",
       "5    None    2008        Normal     250000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate x and y variables\n",
    "# Matrix of independent variable (square feet data)\n",
    "# X = np.log(training_data.loc[:,[\"GrLivArea\"]].values)\n",
    "X = training_data.iloc[:,:-1].values\n",
    "# Vector of dependent variable (home sale price)\n",
    "y = np.log(training_data.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = training_data.iloc[:,:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>MSSubClass_20</th>\n",
       "      <th>MSSubClass_30</th>\n",
       "      <th>MSSubClass_40</th>\n",
       "      <th>MSSubClass_45</th>\n",
       "      <th>MSSubClass_50</th>\n",
       "      <th>MSSubClass_60</th>\n",
       "      <th>MSSubClass_70</th>\n",
       "      <th>MSSubClass_75</th>\n",
       "      <th>MSSubClass_80</th>\n",
       "      <th>MSSubClass_85</th>\n",
       "      <th>MSSubClass_90</th>\n",
       "      <th>MSSubClass_120</th>\n",
       "      <th>MSSubClass_160</th>\n",
       "      <th>MSSubClass_180</th>\n",
       "      <th>MSSubClass_190</th>\n",
       "      <th>Neighborhood_Blmngtn</th>\n",
       "      <th>Neighborhood_Blueste</th>\n",
       "      <th>Neighborhood_BrDale</th>\n",
       "      <th>Neighborhood_BrkSide</th>\n",
       "      <th>Neighborhood_ClearCr</th>\n",
       "      <th>Neighborhood_CollgCr</th>\n",
       "      <th>Neighborhood_Crawfor</th>\n",
       "      <th>Neighborhood_Edwards</th>\n",
       "      <th>Neighborhood_Gilbert</th>\n",
       "      <th>Neighborhood_IDOTRR</th>\n",
       "      <th>Neighborhood_MeadowV</th>\n",
       "      <th>Neighborhood_Mitchel</th>\n",
       "      <th>Neighborhood_NAmes</th>\n",
       "      <th>Neighborhood_NPkVill</th>\n",
       "      <th>Neighborhood_NWAmes</th>\n",
       "      <th>Neighborhood_NoRidge</th>\n",
       "      <th>Neighborhood_NridgHt</th>\n",
       "      <th>Neighborhood_OldTown</th>\n",
       "      <th>Neighborhood_SWISU</th>\n",
       "      <th>Neighborhood_Sawyer</th>\n",
       "      <th>Neighborhood_SawyerW</th>\n",
       "      <th>Neighborhood_Somerst</th>\n",
       "      <th>Neighborhood_StoneBr</th>\n",
       "      <th>Neighborhood_Timber</th>\n",
       "      <th>Neighborhood_Veenker</th>\n",
       "      <th>OverallQual_1</th>\n",
       "      <th>OverallQual_2</th>\n",
       "      <th>OverallQual_3</th>\n",
       "      <th>OverallQual_4</th>\n",
       "      <th>OverallQual_5</th>\n",
       "      <th>OverallQual_6</th>\n",
       "      <th>OverallQual_7</th>\n",
       "      <th>OverallQual_8</th>\n",
       "      <th>OverallQual_9</th>\n",
       "      <th>OverallQual_10</th>\n",
       "      <th>ExterQual_Ex</th>\n",
       "      <th>ExterQual_Fa</th>\n",
       "      <th>ExterQual_Gd</th>\n",
       "      <th>ExterQual_TA</th>\n",
       "      <th>BsmtQual_Ex</th>\n",
       "      <th>BsmtQual_Fa</th>\n",
       "      <th>BsmtQual_Gd</th>\n",
       "      <th>BsmtQual_None</th>\n",
       "      <th>BsmtQual_TA</th>\n",
       "      <th>BsmtFullBath_0</th>\n",
       "      <th>BsmtFullBath_1</th>\n",
       "      <th>BsmtFullBath_2</th>\n",
       "      <th>BsmtFullBath_3</th>\n",
       "      <th>BsmtHalfBath_0</th>\n",
       "      <th>BsmtHalfBath_1</th>\n",
       "      <th>BsmtHalfBath_2</th>\n",
       "      <th>FullBath_0</th>\n",
       "      <th>FullBath_1</th>\n",
       "      <th>FullBath_2</th>\n",
       "      <th>FullBath_3</th>\n",
       "      <th>HalfBath_0</th>\n",
       "      <th>HalfBath_1</th>\n",
       "      <th>HalfBath_2</th>\n",
       "      <th>BedroomAbvGr_0</th>\n",
       "      <th>BedroomAbvGr_1</th>\n",
       "      <th>BedroomAbvGr_2</th>\n",
       "      <th>BedroomAbvGr_3</th>\n",
       "      <th>BedroomAbvGr_4</th>\n",
       "      <th>BedroomAbvGr_5</th>\n",
       "      <th>BedroomAbvGr_6</th>\n",
       "      <th>BedroomAbvGr_8</th>\n",
       "      <th>KitchenAbvGr_0</th>\n",
       "      <th>KitchenAbvGr_1</th>\n",
       "      <th>KitchenAbvGr_2</th>\n",
       "      <th>KitchenAbvGr_3</th>\n",
       "      <th>KitchenQual_Ex</th>\n",
       "      <th>KitchenQual_Fa</th>\n",
       "      <th>KitchenQual_Gd</th>\n",
       "      <th>KitchenQual_TA</th>\n",
       "      <th>TotRmsAbvGrd_2</th>\n",
       "      <th>TotRmsAbvGrd_3</th>\n",
       "      <th>TotRmsAbvGrd_4</th>\n",
       "      <th>TotRmsAbvGrd_5</th>\n",
       "      <th>TotRmsAbvGrd_6</th>\n",
       "      <th>TotRmsAbvGrd_7</th>\n",
       "      <th>TotRmsAbvGrd_8</th>\n",
       "      <th>TotRmsAbvGrd_9</th>\n",
       "      <th>TotRmsAbvGrd_10</th>\n",
       "      <th>TotRmsAbvGrd_11</th>\n",
       "      <th>TotRmsAbvGrd_12</th>\n",
       "      <th>TotRmsAbvGrd_14</th>\n",
       "      <th>Fireplaces_0</th>\n",
       "      <th>Fireplaces_1</th>\n",
       "      <th>Fireplaces_2</th>\n",
       "      <th>Fireplaces_3</th>\n",
       "      <th>FireplaceQu_Ex</th>\n",
       "      <th>FireplaceQu_Fa</th>\n",
       "      <th>FireplaceQu_Gd</th>\n",
       "      <th>FireplaceQu_None</th>\n",
       "      <th>FireplaceQu_Po</th>\n",
       "      <th>FireplaceQu_TA</th>\n",
       "      <th>GarageType_2Types</th>\n",
       "      <th>GarageType_Attchd</th>\n",
       "      <th>GarageType_Basment</th>\n",
       "      <th>GarageType_BuiltIn</th>\n",
       "      <th>GarageType_CarPort</th>\n",
       "      <th>GarageType_Detchd</th>\n",
       "      <th>GarageType_None</th>\n",
       "      <th>GarageCars_0</th>\n",
       "      <th>GarageCars_1</th>\n",
       "      <th>GarageCars_2</th>\n",
       "      <th>GarageCars_3</th>\n",
       "      <th>GarageCars_4</th>\n",
       "      <th>GarageQual_Ex</th>\n",
       "      <th>GarageQual_Fa</th>\n",
       "      <th>GarageQual_Gd</th>\n",
       "      <th>GarageQual_None</th>\n",
       "      <th>GarageQual_Po</th>\n",
       "      <th>GarageQual_TA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>196.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>TA</td>\n",
       "      <td>856</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>1710</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>None</td>\n",
       "      <td>2008</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>TA</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>None</td>\n",
       "      <td>2007</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>162.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>TA</td>\n",
       "      <td>920</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>1786</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>None</td>\n",
       "      <td>2008</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>Gd</td>\n",
       "      <td>756</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>1717</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>None</td>\n",
       "      <td>2006</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>350.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>TA</td>\n",
       "      <td>1145</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>2198</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>None</td>\n",
       "      <td>2008</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotFrontage  LotArea  MasVnrArea  OverallCond  YearBuilt BsmtCond  \\\n",
       "Id                                                                      \n",
       "1          65.0     8450       196.0            5       2003       TA   \n",
       "2          80.0     9600         0.0            8       1976       TA   \n",
       "3          68.0    11250       162.0            5       2001       TA   \n",
       "4          60.0     9550         0.0            5       1915       Gd   \n",
       "5          84.0    14260       350.0            5       2000       TA   \n",
       "\n",
       "    TotalBsmtSF  1stFlrSF  2ndFlrSF  GrLivArea  GarageArea GarageCond PoolQC  \\\n",
       "Id                                                                             \n",
       "1           856       856       854       1710         548         TA   None   \n",
       "2          1262      1262         0       1262         460         TA   None   \n",
       "3           920       920       866       1786         608         TA   None   \n",
       "4           756       961       756       1717         642         TA   None   \n",
       "5          1145      1145      1053       2198         836         TA   None   \n",
       "\n",
       "    YrSold SaleCondition  MSSubClass_20  MSSubClass_30  MSSubClass_40  \\\n",
       "Id                                                                      \n",
       "1     2008        Normal              0              0              0   \n",
       "2     2007        Normal              1              0              0   \n",
       "3     2008        Normal              0              0              0   \n",
       "4     2006       Abnorml              0              0              0   \n",
       "5     2008        Normal              0              0              0   \n",
       "\n",
       "    MSSubClass_45  MSSubClass_50  MSSubClass_60  MSSubClass_70  MSSubClass_75  \\\n",
       "Id                                                                              \n",
       "1               0              0              1              0              0   \n",
       "2               0              0              0              0              0   \n",
       "3               0              0              1              0              0   \n",
       "4               0              0              0              1              0   \n",
       "5               0              0              1              0              0   \n",
       "\n",
       "    MSSubClass_80  MSSubClass_85  MSSubClass_90  MSSubClass_120  \\\n",
       "Id                                                                \n",
       "1               0              0              0               0   \n",
       "2               0              0              0               0   \n",
       "3               0              0              0               0   \n",
       "4               0              0              0               0   \n",
       "5               0              0              0               0   \n",
       "\n",
       "    MSSubClass_160  MSSubClass_180  MSSubClass_190  Neighborhood_Blmngtn  \\\n",
       "Id                                                                         \n",
       "1                0               0               0                     0   \n",
       "2                0               0               0                     0   \n",
       "3                0               0               0                     0   \n",
       "4                0               0               0                     0   \n",
       "5                0               0               0                     0   \n",
       "\n",
       "    Neighborhood_Blueste  Neighborhood_BrDale  Neighborhood_BrkSide  \\\n",
       "Id                                                                    \n",
       "1                      0                    0                     0   \n",
       "2                      0                    0                     0   \n",
       "3                      0                    0                     0   \n",
       "4                      0                    0                     0   \n",
       "5                      0                    0                     0   \n",
       "\n",
       "    Neighborhood_ClearCr  Neighborhood_CollgCr  Neighborhood_Crawfor  \\\n",
       "Id                                                                     \n",
       "1                      0                     1                     0   \n",
       "2                      0                     0                     0   \n",
       "3                      0                     1                     0   \n",
       "4                      0                     0                     1   \n",
       "5                      0                     0                     0   \n",
       "\n",
       "    Neighborhood_Edwards  Neighborhood_Gilbert  Neighborhood_IDOTRR  \\\n",
       "Id                                                                    \n",
       "1                      0                     0                    0   \n",
       "2                      0                     0                    0   \n",
       "3                      0                     0                    0   \n",
       "4                      0                     0                    0   \n",
       "5                      0                     0                    0   \n",
       "\n",
       "    Neighborhood_MeadowV  Neighborhood_Mitchel  Neighborhood_NAmes  \\\n",
       "Id                                                                   \n",
       "1                      0                     0                   0   \n",
       "2                      0                     0                   0   \n",
       "3                      0                     0                   0   \n",
       "4                      0                     0                   0   \n",
       "5                      0                     0                   0   \n",
       "\n",
       "    Neighborhood_NPkVill  Neighborhood_NWAmes  Neighborhood_NoRidge  \\\n",
       "Id                                                                    \n",
       "1                      0                    0                     0   \n",
       "2                      0                    0                     0   \n",
       "3                      0                    0                     0   \n",
       "4                      0                    0                     0   \n",
       "5                      0                    0                     1   \n",
       "\n",
       "    Neighborhood_NridgHt  Neighborhood_OldTown  Neighborhood_SWISU  \\\n",
       "Id                                                                   \n",
       "1                      0                     0                   0   \n",
       "2                      0                     0                   0   \n",
       "3                      0                     0                   0   \n",
       "4                      0                     0                   0   \n",
       "5                      0                     0                   0   \n",
       "\n",
       "    Neighborhood_Sawyer  Neighborhood_SawyerW  Neighborhood_Somerst  \\\n",
       "Id                                                                    \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "5                     0                     0                     0   \n",
       "\n",
       "    Neighborhood_StoneBr  Neighborhood_Timber  Neighborhood_Veenker  \\\n",
       "Id                                                                    \n",
       "1                      0                    0                     0   \n",
       "2                      0                    0                     1   \n",
       "3                      0                    0                     0   \n",
       "4                      0                    0                     0   \n",
       "5                      0                    0                     0   \n",
       "\n",
       "    OverallQual_1  OverallQual_2  OverallQual_3  OverallQual_4  OverallQual_5  \\\n",
       "Id                                                                              \n",
       "1               0              0              0              0              0   \n",
       "2               0              0              0              0              0   \n",
       "3               0              0              0              0              0   \n",
       "4               0              0              0              0              0   \n",
       "5               0              0              0              0              0   \n",
       "\n",
       "    OverallQual_6  OverallQual_7  OverallQual_8  OverallQual_9  \\\n",
       "Id                                                               \n",
       "1               0              1              0              0   \n",
       "2               1              0              0              0   \n",
       "3               0              1              0              0   \n",
       "4               0              1              0              0   \n",
       "5               0              0              1              0   \n",
       "\n",
       "    OverallQual_10  ExterQual_Ex  ExterQual_Fa  ExterQual_Gd  ExterQual_TA  \\\n",
       "Id                                                                           \n",
       "1                0             0             0             1             0   \n",
       "2                0             0             0             0             1   \n",
       "3                0             0             0             1             0   \n",
       "4                0             0             0             0             1   \n",
       "5                0             0             0             1             0   \n",
       "\n",
       "    BsmtQual_Ex  BsmtQual_Fa  BsmtQual_Gd  BsmtQual_None  BsmtQual_TA  \\\n",
       "Id                                                                      \n",
       "1             0            0            1              0            0   \n",
       "2             0            0            1              0            0   \n",
       "3             0            0            1              0            0   \n",
       "4             0            0            0              0            1   \n",
       "5             0            0            1              0            0   \n",
       "\n",
       "    BsmtFullBath_0  BsmtFullBath_1  BsmtFullBath_2  BsmtFullBath_3  \\\n",
       "Id                                                                   \n",
       "1                0               1               0               0   \n",
       "2                1               0               0               0   \n",
       "3                0               1               0               0   \n",
       "4                0               1               0               0   \n",
       "5                0               1               0               0   \n",
       "\n",
       "    BsmtHalfBath_0  BsmtHalfBath_1  BsmtHalfBath_2  FullBath_0  FullBath_1  \\\n",
       "Id                                                                           \n",
       "1                1               0               0           0           0   \n",
       "2                0               1               0           0           0   \n",
       "3                1               0               0           0           0   \n",
       "4                1               0               0           0           1   \n",
       "5                1               0               0           0           0   \n",
       "\n",
       "    FullBath_2  FullBath_3  HalfBath_0  HalfBath_1  HalfBath_2  \\\n",
       "Id                                                               \n",
       "1            1           0           0           1           0   \n",
       "2            1           0           1           0           0   \n",
       "3            1           0           0           1           0   \n",
       "4            0           0           1           0           0   \n",
       "5            1           0           0           1           0   \n",
       "\n",
       "    BedroomAbvGr_0  BedroomAbvGr_1  BedroomAbvGr_2  BedroomAbvGr_3  \\\n",
       "Id                                                                   \n",
       "1                0               0               0               1   \n",
       "2                0               0               0               1   \n",
       "3                0               0               0               1   \n",
       "4                0               0               0               1   \n",
       "5                0               0               0               0   \n",
       "\n",
       "    BedroomAbvGr_4  BedroomAbvGr_5  BedroomAbvGr_6  BedroomAbvGr_8  \\\n",
       "Id                                                                   \n",
       "1                0               0               0               0   \n",
       "2                0               0               0               0   \n",
       "3                0               0               0               0   \n",
       "4                0               0               0               0   \n",
       "5                1               0               0               0   \n",
       "\n",
       "    KitchenAbvGr_0  KitchenAbvGr_1  KitchenAbvGr_2  KitchenAbvGr_3  \\\n",
       "Id                                                                   \n",
       "1                0               1               0               0   \n",
       "2                0               1               0               0   \n",
       "3                0               1               0               0   \n",
       "4                0               1               0               0   \n",
       "5                0               1               0               0   \n",
       "\n",
       "    KitchenQual_Ex  KitchenQual_Fa  KitchenQual_Gd  KitchenQual_TA  \\\n",
       "Id                                                                   \n",
       "1                0               0               1               0   \n",
       "2                0               0               0               1   \n",
       "3                0               0               1               0   \n",
       "4                0               0               1               0   \n",
       "5                0               0               1               0   \n",
       "\n",
       "    TotRmsAbvGrd_2  TotRmsAbvGrd_3  TotRmsAbvGrd_4  TotRmsAbvGrd_5  \\\n",
       "Id                                                                   \n",
       "1                0               0               0               0   \n",
       "2                0               0               0               0   \n",
       "3                0               0               0               0   \n",
       "4                0               0               0               0   \n",
       "5                0               0               0               0   \n",
       "\n",
       "    TotRmsAbvGrd_6  TotRmsAbvGrd_7  TotRmsAbvGrd_8  TotRmsAbvGrd_9  \\\n",
       "Id                                                                   \n",
       "1                0               0               1               0   \n",
       "2                1               0               0               0   \n",
       "3                1               0               0               0   \n",
       "4                0               1               0               0   \n",
       "5                0               0               0               1   \n",
       "\n",
       "    TotRmsAbvGrd_10  TotRmsAbvGrd_11  TotRmsAbvGrd_12  TotRmsAbvGrd_14  \\\n",
       "Id                                                                       \n",
       "1                 0                0                0                0   \n",
       "2                 0                0                0                0   \n",
       "3                 0                0                0                0   \n",
       "4                 0                0                0                0   \n",
       "5                 0                0                0                0   \n",
       "\n",
       "    Fireplaces_0  Fireplaces_1  Fireplaces_2  Fireplaces_3  FireplaceQu_Ex  \\\n",
       "Id                                                                           \n",
       "1              1             0             0             0               0   \n",
       "2              0             1             0             0               0   \n",
       "3              0             1             0             0               0   \n",
       "4              0             1             0             0               0   \n",
       "5              0             1             0             0               0   \n",
       "\n",
       "    FireplaceQu_Fa  FireplaceQu_Gd  FireplaceQu_None  FireplaceQu_Po  \\\n",
       "Id                                                                     \n",
       "1                0               0                 1               0   \n",
       "2                0               0                 0               0   \n",
       "3                0               0                 0               0   \n",
       "4                0               1                 0               0   \n",
       "5                0               0                 0               0   \n",
       "\n",
       "    FireplaceQu_TA  GarageType_2Types  GarageType_Attchd  GarageType_Basment  \\\n",
       "Id                                                                             \n",
       "1                0                  0                  1                   0   \n",
       "2                1                  0                  1                   0   \n",
       "3                1                  0                  1                   0   \n",
       "4                0                  0                  0                   0   \n",
       "5                1                  0                  1                   0   \n",
       "\n",
       "    GarageType_BuiltIn  GarageType_CarPort  GarageType_Detchd  \\\n",
       "Id                                                              \n",
       "1                    0                   0                  0   \n",
       "2                    0                   0                  0   \n",
       "3                    0                   0                  0   \n",
       "4                    0                   0                  1   \n",
       "5                    0                   0                  0   \n",
       "\n",
       "    GarageType_None  GarageCars_0  GarageCars_1  GarageCars_2  GarageCars_3  \\\n",
       "Id                                                                            \n",
       "1                 0             0             0             1             0   \n",
       "2                 0             0             0             1             0   \n",
       "3                 0             0             0             1             0   \n",
       "4                 0             0             0             0             1   \n",
       "5                 0             0             0             0             1   \n",
       "\n",
       "    GarageCars_4  GarageQual_Ex  GarageQual_Fa  GarageQual_Gd  \\\n",
       "Id                                                              \n",
       "1              0              0              0              0   \n",
       "2              0              0              0              0   \n",
       "3              0              0              0              0   \n",
       "4              0              0              0              0   \n",
       "5              0              0              0              0   \n",
       "\n",
       "    GarageQual_None  GarageQual_Po  GarageQual_TA  \n",
       "Id                                                 \n",
       "1                 0              0              1  \n",
       "2                 0              0              1  \n",
       "3                 0              0              1  \n",
       "4                 0              0              1  \n",
       "5                 0              0              1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded = pd.get_dummies(data,columns=[\"MSSubClass\",\"Neighborhood\",\"OverallQual\",\"ExterQual\",\"BsmtQual\",\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\"BedroomAbvGr\",\"KitchenAbvGr\",\"KitchenQual\",\"TotRmsAbvGrd\",\"Fireplaces\",\"FireplaceQu\",\"GarageType\",\"GarageCars\",\"GarageQual\"])\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform logarithmic transformation on columns\n",
    "data_encoded[[\"GrLivArea\",\"1stFlrSF\"]] = np.log(data_encoded[[\"GrLivArea\",\"1stFlrSF\"]])\n",
    "# Perform logarithmic transformation on columns with 0s\n",
    "data_encoded[\"TotalBsmtSF\"] = np.log(data_encoded[\"TotalBsmtSF\"].replace(0, np.nan))\n",
    "data_encoded.update(training_data[\"TotalBsmtSF\"].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform square root transformation on relevant columns\n",
    "data_encoded[\"2ndFlrSF\"] = np.sqrt(data_encoded[\"2ndFlrSF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cube root transformation on relevant columns\n",
    "data_encoded[[\"LotFrontage\",\"MasVnrArea\"]] = np.cbrt(data_encoded[[\"LotFrontage\",\"MasVnrArea\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 10 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:54:27</td>     <th>  Log-Likelihood:    </th> <td>  808.13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1458</td>      <th>  AIC:               </th> <td>  -1494.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1397</td>      <th>  BIC:               </th> <td>  -1172.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    60</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.3503</td> <td>    0.347</td> <td>   26.920</td> <td> 0.000</td> <td>    8.669</td> <td>   10.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4422</td> <td>    0.024</td> <td>   18.466</td> <td> 0.000</td> <td>    0.395</td> <td>    0.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1865</td> <td>    0.041</td> <td>    4.564</td> <td> 0.000</td> <td>    0.106</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0788</td> <td>    0.040</td> <td>   -1.985</td> <td> 0.047</td> <td>   -0.157</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1140</td> <td>    0.023</td> <td>    4.850</td> <td> 0.000</td> <td>    0.068</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3069</td> <td>    0.031</td> <td>    9.919</td> <td> 0.000</td> <td>    0.246</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2270</td> <td>    0.021</td> <td>   10.757</td> <td> 0.000</td> <td>    0.186</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2737</td> <td>    0.025</td> <td>   11.084</td> <td> 0.000</td> <td>    0.225</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0761</td> <td>    0.020</td> <td>    3.747</td> <td> 0.000</td> <td>    0.036</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2113</td> <td>    0.024</td> <td>    8.730</td> <td> 0.000</td> <td>    0.164</td> <td>    0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0491</td> <td>    0.028</td> <td>   -1.763</td> <td> 0.078</td> <td>   -0.104</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0131</td> <td>    0.039</td> <td>   -0.333</td> <td> 0.739</td> <td>   -0.090</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1862</td> <td>    0.025</td> <td>    7.346</td> <td> 0.000</td> <td>    0.136</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.1678</td> <td>    0.017</td> <td>    9.807</td> <td> 0.000</td> <td>    0.134</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.1334</td> <td>    0.051</td> <td>    2.595</td> <td> 0.010</td> <td>    0.033</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.1992</td> <td>    0.023</td> <td>    8.513</td> <td> 0.000</td> <td>    0.153</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.3022</td> <td>    0.031</td> <td>    9.830</td> <td> 0.000</td> <td>    0.242</td> <td>    0.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.2701</td> <td>    0.027</td> <td>    9.973</td> <td> 0.000</td> <td>    0.217</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.0805</td> <td>    0.033</td> <td>    2.440</td> <td> 0.015</td> <td>    0.016</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.1657</td> <td>    0.022</td> <td>    7.379</td> <td> 0.000</td> <td>    0.122</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.1714</td> <td>    0.025</td> <td>    6.934</td> <td> 0.000</td> <td>    0.123</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2316</td> <td>    0.025</td> <td>    9.351</td> <td> 0.000</td> <td>    0.183</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.2866</td> <td>    0.036</td> <td>    8.062</td> <td> 0.000</td> <td>    0.217</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.2466</td> <td>    0.029</td> <td>    8.437</td> <td> 0.000</td> <td>    0.189</td> <td>    0.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.3114</td> <td>    0.047</td> <td>    6.610</td> <td> 0.000</td> <td>    0.219</td> <td>    0.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.0799</td> <td>    0.136</td> <td>   -0.587</td> <td> 0.557</td> <td>   -0.347</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   -0.0027</td> <td>    0.128</td> <td>   -0.021</td> <td> 0.983</td> <td>   -0.253</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.1795</td> <td>    0.125</td> <td>    1.437</td> <td> 0.151</td> <td>   -0.066</td> <td>    0.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.2535</td> <td>    0.126</td> <td>    2.012</td> <td> 0.044</td> <td>    0.006</td> <td>    0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.3142</td> <td>    0.126</td> <td>    2.490</td> <td> 0.013</td> <td>    0.067</td> <td>    0.562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.3809</td> <td>    0.127</td> <td>    3.002</td> <td> 0.003</td> <td>    0.132</td> <td>    0.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>    0.4825</td> <td>    0.128</td> <td>    3.771</td> <td> 0.000</td> <td>    0.231</td> <td>    0.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>    0.6011</td> <td>    0.131</td> <td>    4.590</td> <td> 0.000</td> <td>    0.344</td> <td>    0.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>    0.6814</td> <td>    0.136</td> <td>    5.010</td> <td> 0.000</td> <td>    0.415</td> <td>    0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>   -0.2779</td> <td>    0.068</td> <td>   -4.060</td> <td> 0.000</td> <td>   -0.412</td> <td>   -0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.1783</td> <td>    0.067</td> <td>   -2.652</td> <td> 0.008</td> <td>   -0.310</td> <td>   -0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.1296</td> <td>    0.067</td> <td>   -1.941</td> <td> 0.052</td> <td>   -0.261</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.0390</td> <td>    0.068</td> <td>   -0.571</td> <td> 0.568</td> <td>   -0.173</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>    0.0917</td> <td>    0.031</td> <td>    2.929</td> <td> 0.003</td> <td>    0.030</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.0901</td> <td>    0.047</td> <td>   -1.932</td> <td> 0.054</td> <td>   -0.182</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>    0.0197</td> <td>    0.014</td> <td>    1.389</td> <td> 0.165</td> <td>   -0.008</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.4164</td> <td>    0.147</td> <td>   -2.835</td> <td> 0.005</td> <td>   -0.704</td> <td>   -0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.3227</td> <td>    0.147</td> <td>   -2.194</td> <td> 0.028</td> <td>   -0.611</td> <td>   -0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.1764</td> <td>    0.153</td> <td>   -1.150</td> <td> 0.250</td> <td>   -0.477</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.2455</td> <td>    0.111</td> <td>   -2.207</td> <td> 0.027</td> <td>   -0.464</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.1851</td> <td>    0.112</td> <td>   -1.651</td> <td> 0.099</td> <td>   -0.405</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>   -0.2973</td> <td>    0.089</td> <td>   -3.331</td> <td> 0.001</td> <td>   -0.472</td> <td>   -0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.1231</td> <td>    0.032</td> <td>   -3.835</td> <td> 0.000</td> <td>   -0.186</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -0.1187</td> <td>    0.028</td> <td>   -4.191</td> <td> 0.000</td> <td>   -0.174</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>    0.0591</td> <td>    0.047</td> <td>    1.267</td> <td> 0.205</td> <td>   -0.032</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>    0.0668</td> <td>    0.046</td> <td>    1.438</td> <td> 0.151</td> <td>   -0.024</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>   -0.1397</td> <td>    0.178</td> <td>   -0.785</td> <td> 0.432</td> <td>   -0.489</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>   -0.2615</td> <td>    0.158</td> <td>   -1.660</td> <td> 0.097</td> <td>   -0.570</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>   -0.2552</td> <td>    0.156</td> <td>   -1.641</td> <td> 0.101</td> <td>   -0.560</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>   -0.2559</td> <td>    0.155</td> <td>   -1.650</td> <td> 0.099</td> <td>   -0.560</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>   -0.2939</td> <td>    0.155</td> <td>   -1.901</td> <td> 0.058</td> <td>   -0.597</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>   -0.3823</td> <td>    0.156</td> <td>   -2.444</td> <td> 0.015</td> <td>   -0.689</td> <td>   -0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>   <td>   -0.3986</td> <td>    0.163</td> <td>   -2.449</td> <td> 0.014</td> <td>   -0.718</td> <td>   -0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>   <td>    0.1285</td> <td>    0.023</td> <td>    5.657</td> <td> 0.000</td> <td>    0.084</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>   <td>   -0.0448</td> <td>    0.026</td> <td>   -1.697</td> <td> 0.090</td> <td>   -0.096</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>   <td>    0.0602</td> <td>    0.012</td> <td>    5.212</td> <td> 0.000</td> <td>    0.038</td> <td>    0.083</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.840</td> <th>  Durbin-Watson:     </th> <td>   1.947</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 891.907</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.826</td>  <th>  Prob(JB):          </th> <td>2.11e-194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.458</td>  <th>  Cond. No.          </th> <td>1.02e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.02e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.879\n",
       "Model:                            OLS   Adj. R-squared:                  0.874\n",
       "Method:                 Least Squares   F-statistic:                     169.1\n",
       "Date:                Fri, 10 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        23:54:27   Log-Likelihood:                 808.13\n",
       "No. Observations:                1458   AIC:                            -1494.\n",
       "Df Residuals:                    1397   BIC:                            -1172.\n",
       "Df Model:                          60                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.3503      0.347     26.920      0.000       8.669      10.032\n",
       "x1             0.4422      0.024     18.466      0.000       0.395       0.489\n",
       "x2             0.1865      0.041      4.564      0.000       0.106       0.267\n",
       "x3            -0.0788      0.040     -1.985      0.047      -0.157      -0.001\n",
       "x4             0.1140      0.023      4.850      0.000       0.068       0.160\n",
       "x5             0.3069      0.031      9.919      0.000       0.246       0.368\n",
       "x6             0.2270      0.021     10.757      0.000       0.186       0.268\n",
       "x7             0.2737      0.025     11.084      0.000       0.225       0.322\n",
       "x8             0.0761      0.020      3.747      0.000       0.036       0.116\n",
       "x9             0.2113      0.024      8.730      0.000       0.164       0.259\n",
       "x10           -0.0491      0.028     -1.763      0.078      -0.104       0.006\n",
       "x11           -0.0131      0.039     -0.333      0.739      -0.090       0.064\n",
       "x12            0.1862      0.025      7.346      0.000       0.136       0.236\n",
       "x13            0.1678      0.017      9.807      0.000       0.134       0.201\n",
       "x14            0.1334      0.051      2.595      0.010       0.033       0.234\n",
       "x15            0.1992      0.023      8.513      0.000       0.153       0.245\n",
       "x16            0.3022      0.031      9.830      0.000       0.242       0.363\n",
       "x17            0.2701      0.027      9.973      0.000       0.217       0.323\n",
       "x18            0.0805      0.033      2.440      0.015       0.016       0.145\n",
       "x19            0.1657      0.022      7.379      0.000       0.122       0.210\n",
       "x20            0.1714      0.025      6.934      0.000       0.123       0.220\n",
       "x21            0.2316      0.025      9.351      0.000       0.183       0.280\n",
       "x22            0.2866      0.036      8.062      0.000       0.217       0.356\n",
       "x23            0.2466      0.029      8.437      0.000       0.189       0.304\n",
       "x24            0.3114      0.047      6.610      0.000       0.219       0.404\n",
       "x25           -0.0799      0.136     -0.587      0.557      -0.347       0.187\n",
       "x26           -0.0027      0.128     -0.021      0.983      -0.253       0.248\n",
       "x27            0.1795      0.125      1.437      0.151      -0.066       0.425\n",
       "x28            0.2535      0.126      2.012      0.044       0.006       0.501\n",
       "x29            0.3142      0.126      2.490      0.013       0.067       0.562\n",
       "x30            0.3809      0.127      3.002      0.003       0.132       0.630\n",
       "x31            0.4825      0.128      3.771      0.000       0.231       0.733\n",
       "x32            0.6011      0.131      4.590      0.000       0.344       0.858\n",
       "x33            0.6814      0.136      5.010      0.000       0.415       0.948\n",
       "x34           -0.2779      0.068     -4.060      0.000      -0.412      -0.144\n",
       "x35           -0.1783      0.067     -2.652      0.008      -0.310      -0.046\n",
       "x36           -0.1296      0.067     -1.941      0.052      -0.261       0.001\n",
       "x37           -0.0390      0.068     -0.571      0.568      -0.173       0.095\n",
       "x38            0.0917      0.031      2.929      0.003       0.030       0.153\n",
       "x39           -0.0901      0.047     -1.932      0.054      -0.182       0.001\n",
       "x40            0.0197      0.014      1.389      0.165      -0.008       0.047\n",
       "x41           -0.4164      0.147     -2.835      0.005      -0.704      -0.128\n",
       "x42           -0.3227      0.147     -2.194      0.028      -0.611      -0.034\n",
       "x43           -0.1764      0.153     -1.150      0.250      -0.477       0.125\n",
       "x44           -0.2455      0.111     -2.207      0.027      -0.464      -0.027\n",
       "x45           -0.1851      0.112     -1.651      0.099      -0.405       0.035\n",
       "x46           -0.2973      0.089     -3.331      0.001      -0.472      -0.122\n",
       "x47           -0.1231      0.032     -3.835      0.000      -0.186      -0.060\n",
       "x48           -0.1187      0.028     -4.191      0.000      -0.174      -0.063\n",
       "x49            0.0591      0.047      1.267      0.205      -0.032       0.151\n",
       "x50            0.0668      0.046      1.438      0.151      -0.024       0.158\n",
       "x51           -0.1397      0.178     -0.785      0.432      -0.489       0.209\n",
       "x52           -0.2615      0.158     -1.660      0.097      -0.570       0.048\n",
       "x53           -0.2552      0.156     -1.641      0.101      -0.560       0.050\n",
       "x54           -0.2559      0.155     -1.650      0.099      -0.560       0.048\n",
       "x55           -0.2939      0.155     -1.901      0.058      -0.597       0.009\n",
       "x56           -0.3823      0.156     -2.444      0.015      -0.689      -0.075\n",
       "x57           -0.3986      0.163     -2.449      0.014      -0.718      -0.079\n",
       "x58            0.1285      0.023      5.657      0.000       0.084       0.173\n",
       "x59           -0.0448      0.026     -1.697      0.090      -0.096       0.007\n",
       "x60            0.0602      0.012      5.212      0.000       0.038       0.083\n",
       "==============================================================================\n",
       "Omnibus:                      252.840   Durbin-Watson:                   1.947\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              891.907\n",
       "Skew:                          -0.826   Prob(JB):                    2.11e-194\n",
       "Kurtosis:                       6.458   Cond. No.                     1.02e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.02e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables for the multiple linear regression\n",
    "X_2 = data_encoded[[\"GrLivArea\",\"Neighborhood_Blmngtn\",\"Neighborhood_BrDale\",\"Neighborhood_BrkSide\",\"Neighborhood_ClearCr\",\"Neighborhood_CollgCr\",\"Neighborhood_Crawfor\",\"Neighborhood_Edwards\",\"Neighborhood_Gilbert\",\"Neighborhood_IDOTRR\",\"Neighborhood_MeadowV\",\"Neighborhood_Mitchel\",\"Neighborhood_NAmes\",\"Neighborhood_NPkVill\",\"Neighborhood_NWAmes\",\"Neighborhood_NoRidge\",\"Neighborhood_NridgHt\",\"Neighborhood_SWISU\",\"Neighborhood_Sawyer\",\"Neighborhood_SawyerW\",\"Neighborhood_Somerst\",\"Neighborhood_StoneBr\",\"Neighborhood_Timber\",\"Neighborhood_Veenker\",\"OverallQual_2\",\"OverallQual_3\",\"OverallQual_4\",\"OverallQual_5\",\"OverallQual_6\",\"OverallQual_7\",\"OverallQual_8\",\"OverallQual_9\",\"OverallQual_10\",\"GarageCars_0\",\"GarageCars_1\",\"GarageCars_2\",\"GarageCars_3\",\"ExterQual_Ex\",\"ExterQual_Fa\",\"ExterQual_Gd\",\"BsmtFullBath_0\",\"BsmtFullBath_1\",\"BsmtFullBath_2\",\"BsmtHalfBath_0\",\"BsmtHalfBath_1\",\"FullBath_0\",\"FullBath_1\",\"FullBath_2\",\"HalfBath_0\",\"HalfBath_1\",\"BedroomAbvGr_0\",\"BedroomAbvGr_1\",\"BedroomAbvGr_2\",\"BedroomAbvGr_3\",\"BedroomAbvGr_4\",\"BedroomAbvGr_5\",\"BedroomAbvGr_6\",\"KitchenQual_Ex\",\"KitchenQual_Fa\",\"KitchenQual_Gd\"]]\n",
    "# Ignores these variables to avoid the dummy variable trap: \"Neighborhood_Blueste\",\"OverallQual_1\", \"GarageCars_4\",\"ExterQual_TA\", \"BsmtFullBath_3\",\"BsmtHalfBath_2\",\"HalfBath_2\",\"FullBath_3\",\"BedroomAbvGr_8\",\"KitchenQual_TA\"\n",
    "# Redefine X\n",
    "X = X_2.values\n",
    "# Split data into training and testing set\n",
    "# random_state ensures answers are reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2, random_state = 0)\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "regressor = LinearRegression()\n",
    "# fitting linear regressor to our training dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Build the optimal model using backward elimination\n",
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "# X_opt = X[:, [0,1]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   172.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 10 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:58:14</td>     <th>  Log-Likelihood:    </th> <td>  808.13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1458</td>      <th>  AIC:               </th> <td>  -1496.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1398</td>      <th>  BIC:               </th> <td>  -1179.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    59</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.3474</td> <td>    0.319</td> <td>   29.326</td> <td> 0.000</td> <td>    8.722</td> <td>    9.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4422</td> <td>    0.024</td> <td>   18.590</td> <td> 0.000</td> <td>    0.396</td> <td>    0.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1865</td> <td>    0.041</td> <td>    4.566</td> <td> 0.000</td> <td>    0.106</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0788</td> <td>    0.040</td> <td>   -1.985</td> <td> 0.047</td> <td>   -0.157</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1140</td> <td>    0.023</td> <td>    4.862</td> <td> 0.000</td> <td>    0.068</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3069</td> <td>    0.031</td> <td>    9.925</td> <td> 0.000</td> <td>    0.246</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2270</td> <td>    0.021</td> <td>   10.761</td> <td> 0.000</td> <td>    0.186</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2737</td> <td>    0.025</td> <td>   11.093</td> <td> 0.000</td> <td>    0.225</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0761</td> <td>    0.020</td> <td>    3.754</td> <td> 0.000</td> <td>    0.036</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2113</td> <td>    0.024</td> <td>    8.733</td> <td> 0.000</td> <td>    0.164</td> <td>    0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0491</td> <td>    0.028</td> <td>   -1.773</td> <td> 0.076</td> <td>   -0.103</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0131</td> <td>    0.039</td> <td>   -0.334</td> <td> 0.739</td> <td>   -0.090</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1862</td> <td>    0.025</td> <td>    7.350</td> <td> 0.000</td> <td>    0.137</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.1678</td> <td>    0.017</td> <td>    9.818</td> <td> 0.000</td> <td>    0.134</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.1334</td> <td>    0.051</td> <td>    2.595</td> <td> 0.010</td> <td>    0.033</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.1992</td> <td>    0.023</td> <td>    8.517</td> <td> 0.000</td> <td>    0.153</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.3023</td> <td>    0.031</td> <td>    9.835</td> <td> 0.000</td> <td>    0.242</td> <td>    0.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.2701</td> <td>    0.027</td> <td>    9.978</td> <td> 0.000</td> <td>    0.217</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.0805</td> <td>    0.033</td> <td>    2.441</td> <td> 0.015</td> <td>    0.016</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.1657</td> <td>    0.022</td> <td>    7.383</td> <td> 0.000</td> <td>    0.122</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.1714</td> <td>    0.025</td> <td>    6.936</td> <td> 0.000</td> <td>    0.123</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2316</td> <td>    0.025</td> <td>    9.355</td> <td> 0.000</td> <td>    0.183</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.2866</td> <td>    0.036</td> <td>    8.067</td> <td> 0.000</td> <td>    0.217</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.2466</td> <td>    0.029</td> <td>    8.443</td> <td> 0.000</td> <td>    0.189</td> <td>    0.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.3114</td> <td>    0.047</td> <td>    6.613</td> <td> 0.000</td> <td>    0.219</td> <td>    0.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.0778</td> <td>    0.094</td> <td>   -0.827</td> <td> 0.409</td> <td>   -0.262</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.1821</td> <td>    0.034</td> <td>    5.334</td> <td> 0.000</td> <td>    0.115</td> <td>    0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.2561</td> <td>    0.033</td> <td>    7.697</td> <td> 0.000</td> <td>    0.191</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.3167</td> <td>    0.034</td> <td>    9.389</td> <td> 0.000</td> <td>    0.251</td> <td>    0.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.3835</td> <td>    0.035</td> <td>   10.874</td> <td> 0.000</td> <td>    0.314</td> <td>    0.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.4851</td> <td>    0.038</td> <td>   12.803</td> <td> 0.000</td> <td>    0.411</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>    0.6037</td> <td>    0.047</td> <td>   12.748</td> <td> 0.000</td> <td>    0.511</td> <td>    0.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>    0.6839</td> <td>    0.058</td> <td>   11.716</td> <td> 0.000</td> <td>    0.569</td> <td>    0.798</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.2780</td> <td>    0.068</td> <td>   -4.063</td> <td> 0.000</td> <td>   -0.412</td> <td>   -0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>   -0.1783</td> <td>    0.067</td> <td>   -2.656</td> <td> 0.008</td> <td>   -0.310</td> <td>   -0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.1297</td> <td>    0.067</td> <td>   -1.945</td> <td> 0.052</td> <td>   -0.261</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.0391</td> <td>    0.068</td> <td>   -0.573</td> <td> 0.567</td> <td>   -0.173</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>    0.0917</td> <td>    0.031</td> <td>    2.930</td> <td> 0.003</td> <td>    0.030</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.0898</td> <td>    0.044</td> <td>   -2.043</td> <td> 0.041</td> <td>   -0.176</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>    0.0197</td> <td>    0.014</td> <td>    1.390</td> <td> 0.165</td> <td>   -0.008</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.4163</td> <td>    0.147</td> <td>   -2.836</td> <td> 0.005</td> <td>   -0.704</td> <td>   -0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.3227</td> <td>    0.147</td> <td>   -2.195</td> <td> 0.028</td> <td>   -0.611</td> <td>   -0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.1764</td> <td>    0.153</td> <td>   -1.150</td> <td> 0.250</td> <td>   -0.477</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.2452</td> <td>    0.110</td> <td>   -2.224</td> <td> 0.026</td> <td>   -0.461</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.1848</td> <td>    0.111</td> <td>   -1.663</td> <td> 0.097</td> <td>   -0.403</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.2967</td> <td>    0.084</td> <td>   -3.529</td> <td> 0.000</td> <td>   -0.462</td> <td>   -0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>   -0.1231</td> <td>    0.032</td> <td>   -3.843</td> <td> 0.000</td> <td>   -0.186</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.1187</td> <td>    0.028</td> <td>   -4.193</td> <td> 0.000</td> <td>   -0.174</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>    0.0591</td> <td>    0.046</td> <td>    1.272</td> <td> 0.203</td> <td>   -0.032</td> <td>    0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>    0.0669</td> <td>    0.046</td> <td>    1.446</td> <td> 0.148</td> <td>   -0.024</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>   -0.1398</td> <td>    0.178</td> <td>   -0.786</td> <td> 0.432</td> <td>   -0.489</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>   -0.2610</td> <td>    0.156</td> <td>   -1.674</td> <td> 0.094</td> <td>   -0.567</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>   -0.2548</td> <td>    0.154</td> <td>   -1.650</td> <td> 0.099</td> <td>   -0.558</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>   -0.2555</td> <td>    0.154</td> <td>   -1.660</td> <td> 0.097</td> <td>   -0.557</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>   -0.2935</td> <td>    0.153</td> <td>   -1.913</td> <td> 0.056</td> <td>   -0.594</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>   -0.3819</td> <td>    0.155</td> <td>   -2.461</td> <td> 0.014</td> <td>   -0.686</td> <td>   -0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>   -0.3982</td> <td>    0.162</td> <td>   -2.462</td> <td> 0.014</td> <td>   -0.715</td> <td>   -0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>   <td>    0.1285</td> <td>    0.023</td> <td>    5.661</td> <td> 0.000</td> <td>    0.084</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>   <td>   -0.0447</td> <td>    0.026</td> <td>   -1.707</td> <td> 0.088</td> <td>   -0.096</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>   <td>    0.0602</td> <td>    0.012</td> <td>    5.214</td> <td> 0.000</td> <td>    0.038</td> <td>    0.083</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.832</td> <th>  Durbin-Watson:     </th> <td>   1.947</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 891.742</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.826</td>  <th>  Prob(JB):          </th> <td>2.29e-194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.457</td>  <th>  Cond. No.          </th> <td>    949.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.879\n",
       "Model:                            OLS   Adj. R-squared:                  0.874\n",
       "Method:                 Least Squares   F-statistic:                     172.1\n",
       "Date:                Fri, 10 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        23:58:14   Log-Likelihood:                 808.13\n",
       "No. Observations:                1458   AIC:                            -1496.\n",
       "Df Residuals:                    1398   BIC:                            -1179.\n",
       "Df Model:                          59                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.3474      0.319     29.326      0.000       8.722       9.973\n",
       "x1             0.4422      0.024     18.590      0.000       0.396       0.489\n",
       "x2             0.1865      0.041      4.566      0.000       0.106       0.267\n",
       "x3            -0.0788      0.040     -1.985      0.047      -0.157      -0.001\n",
       "x4             0.1140      0.023      4.862      0.000       0.068       0.160\n",
       "x5             0.3069      0.031      9.925      0.000       0.246       0.368\n",
       "x6             0.2270      0.021     10.761      0.000       0.186       0.268\n",
       "x7             0.2737      0.025     11.093      0.000       0.225       0.322\n",
       "x8             0.0761      0.020      3.754      0.000       0.036       0.116\n",
       "x9             0.2113      0.024      8.733      0.000       0.164       0.259\n",
       "x10           -0.0491      0.028     -1.773      0.076      -0.103       0.005\n",
       "x11           -0.0131      0.039     -0.334      0.739      -0.090       0.064\n",
       "x12            0.1862      0.025      7.350      0.000       0.137       0.236\n",
       "x13            0.1678      0.017      9.818      0.000       0.134       0.201\n",
       "x14            0.1334      0.051      2.595      0.010       0.033       0.234\n",
       "x15            0.1992      0.023      8.517      0.000       0.153       0.245\n",
       "x16            0.3023      0.031      9.835      0.000       0.242       0.363\n",
       "x17            0.2701      0.027      9.978      0.000       0.217       0.323\n",
       "x18            0.0805      0.033      2.441      0.015       0.016       0.145\n",
       "x19            0.1657      0.022      7.383      0.000       0.122       0.210\n",
       "x20            0.1714      0.025      6.936      0.000       0.123       0.220\n",
       "x21            0.2316      0.025      9.355      0.000       0.183       0.280\n",
       "x22            0.2866      0.036      8.067      0.000       0.217       0.356\n",
       "x23            0.2466      0.029      8.443      0.000       0.189       0.304\n",
       "x24            0.3114      0.047      6.613      0.000       0.219       0.404\n",
       "x25           -0.0778      0.094     -0.827      0.409      -0.262       0.107\n",
       "x26            0.1821      0.034      5.334      0.000       0.115       0.249\n",
       "x27            0.2561      0.033      7.697      0.000       0.191       0.321\n",
       "x28            0.3167      0.034      9.389      0.000       0.251       0.383\n",
       "x29            0.3835      0.035     10.874      0.000       0.314       0.453\n",
       "x30            0.4851      0.038     12.803      0.000       0.411       0.559\n",
       "x31            0.6037      0.047     12.748      0.000       0.511       0.697\n",
       "x32            0.6839      0.058     11.716      0.000       0.569       0.798\n",
       "x33           -0.2780      0.068     -4.063      0.000      -0.412      -0.144\n",
       "x34           -0.1783      0.067     -2.656      0.008      -0.310      -0.047\n",
       "x35           -0.1297      0.067     -1.945      0.052      -0.261       0.001\n",
       "x36           -0.0391      0.068     -0.573      0.567      -0.173       0.095\n",
       "x37            0.0917      0.031      2.930      0.003       0.030       0.153\n",
       "x38           -0.0898      0.044     -2.043      0.041      -0.176      -0.004\n",
       "x39            0.0197      0.014      1.390      0.165      -0.008       0.047\n",
       "x40           -0.4163      0.147     -2.836      0.005      -0.704      -0.128\n",
       "x41           -0.3227      0.147     -2.195      0.028      -0.611      -0.034\n",
       "x42           -0.1764      0.153     -1.150      0.250      -0.477       0.124\n",
       "x43           -0.2452      0.110     -2.224      0.026      -0.461      -0.029\n",
       "x44           -0.1848      0.111     -1.663      0.097      -0.403       0.033\n",
       "x45           -0.2967      0.084     -3.529      0.000      -0.462      -0.132\n",
       "x46           -0.1231      0.032     -3.843      0.000      -0.186      -0.060\n",
       "x47           -0.1187      0.028     -4.193      0.000      -0.174      -0.063\n",
       "x48            0.0591      0.046      1.272      0.203      -0.032       0.150\n",
       "x49            0.0669      0.046      1.446      0.148      -0.024       0.158\n",
       "x50           -0.1398      0.178     -0.786      0.432      -0.489       0.209\n",
       "x51           -0.2610      0.156     -1.674      0.094      -0.567       0.045\n",
       "x52           -0.2548      0.154     -1.650      0.099      -0.558       0.048\n",
       "x53           -0.2555      0.154     -1.660      0.097      -0.557       0.046\n",
       "x54           -0.2935      0.153     -1.913      0.056      -0.594       0.007\n",
       "x55           -0.3819      0.155     -2.461      0.014      -0.686      -0.077\n",
       "x56           -0.3982      0.162     -2.462      0.014      -0.715      -0.081\n",
       "x57            0.1285      0.023      5.661      0.000       0.084       0.173\n",
       "x58           -0.0447      0.026     -1.707      0.088      -0.096       0.007\n",
       "x59            0.0602      0.012      5.214      0.000       0.038       0.083\n",
       "==============================================================================\n",
       "Omnibus:                      252.832   Durbin-Watson:                   1.947\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              891.742\n",
       "Skew:                          -0.826   Prob(JB):                    2.29e-194\n",
       "Kurtosis:                       6.457   Cond. No.                         949.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables for the multiple linear regression\n",
    "X_3 = data_encoded[[\"GrLivArea\",\"Neighborhood_Blmngtn\",\"Neighborhood_BrDale\",\"Neighborhood_BrkSide\",\"Neighborhood_ClearCr\",\"Neighborhood_CollgCr\",\"Neighborhood_Crawfor\",\"Neighborhood_Edwards\",\"Neighborhood_Gilbert\",\"Neighborhood_IDOTRR\",\"Neighborhood_MeadowV\",\"Neighborhood_Mitchel\",\"Neighborhood_NAmes\",\"Neighborhood_NPkVill\",\"Neighborhood_NWAmes\",\"Neighborhood_NoRidge\",\"Neighborhood_NridgHt\",\"Neighborhood_SWISU\",\"Neighborhood_Sawyer\",\"Neighborhood_SawyerW\",\"Neighborhood_Somerst\",\"Neighborhood_StoneBr\",\"Neighborhood_Timber\",\"Neighborhood_Veenker\",\"OverallQual_2\",\"OverallQual_4\",\"OverallQual_5\",\"OverallQual_6\",\"OverallQual_7\",\"OverallQual_8\",\"OverallQual_9\",\"OverallQual_10\",\"GarageCars_0\",\"GarageCars_1\",\"GarageCars_2\",\"GarageCars_3\",\"ExterQual_Ex\",\"ExterQual_Fa\",\"ExterQual_Gd\",\"BsmtFullBath_0\",\"BsmtFullBath_1\",\"BsmtFullBath_2\",\"BsmtHalfBath_0\",\"BsmtHalfBath_1\",\"FullBath_0\",\"FullBath_1\",\"FullBath_2\",\"HalfBath_0\",\"HalfBath_1\",\"BedroomAbvGr_0\",\"BedroomAbvGr_1\",\"BedroomAbvGr_2\",\"BedroomAbvGr_3\",\"BedroomAbvGr_4\",\"BedroomAbvGr_5\",\"BedroomAbvGr_6\",\"KitchenQual_Ex\",\"KitchenQual_Fa\",\"KitchenQual_Gd\"]]\n",
    "# Ignores these variables to avoid the dummy variable trap: \"Neighborhood_Blueste\",\"OverallQual_1\", \"GarageCars_4\",\"ExterQual_TA\", \"BsmtFullBath_3\",\"BsmtHalfBath_2\",\"HalfBath_2\",\"FullBath_3\",\"BedroomAbvGr_8\",\"KitchenQual_TA\"\n",
    "# Removing these variables because they're not statistically significant: \"OverallQual_3\",\n",
    "# Redefine X\n",
    "X = X_3.values\n",
    "# Split data into training and testing set\n",
    "# random_state ensures answers are reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2, random_state = 0)\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "regressor = LinearRegression()\n",
    "# fitting linear regressor to our training dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Build the optimal model using backward elimination\n",
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "# X_opt = X[:, [0,1]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   175.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 10 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:59:47</td>     <th>  Log-Likelihood:    </th> <td>  808.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1458</td>      <th>  AIC:               </th> <td>  -1498.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1399</td>      <th>  BIC:               </th> <td>  -1186.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    58</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.3368</td> <td>    0.317</td> <td>   29.449</td> <td> 0.000</td> <td>    8.715</td> <td>    9.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4433</td> <td>    0.024</td> <td>   18.818</td> <td> 0.000</td> <td>    0.397</td> <td>    0.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1880</td> <td>    0.041</td> <td>    4.629</td> <td> 0.000</td> <td>    0.108</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0769</td> <td>    0.039</td> <td>   -1.958</td> <td> 0.050</td> <td>   -0.154</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1156</td> <td>    0.023</td> <td>    5.043</td> <td> 0.000</td> <td>    0.071</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3085</td> <td>    0.031</td> <td>   10.108</td> <td> 0.000</td> <td>    0.249</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2288</td> <td>    0.020</td> <td>   11.230</td> <td> 0.000</td> <td>    0.189</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2751</td> <td>    0.024</td> <td>   11.325</td> <td> 0.000</td> <td>    0.227</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0779</td> <td>    0.019</td> <td>    3.998</td> <td> 0.000</td> <td>    0.040</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2131</td> <td>    0.024</td> <td>    9.042</td> <td> 0.000</td> <td>    0.167</td> <td>    0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0475</td> <td>    0.027</td> <td>   -1.742</td> <td> 0.082</td> <td>   -0.101</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1880</td> <td>    0.025</td> <td>    7.588</td> <td> 0.000</td> <td>    0.139</td> <td>    0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1695</td> <td>    0.016</td> <td>   10.387</td> <td> 0.000</td> <td>    0.138</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.1352</td> <td>    0.051</td> <td>    2.646</td> <td> 0.008</td> <td>    0.035</td> <td>    0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.2009</td> <td>    0.023</td> <td>    8.788</td> <td> 0.000</td> <td>    0.156</td> <td>    0.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.3038</td> <td>    0.030</td> <td>   10.007</td> <td> 0.000</td> <td>    0.244</td> <td>    0.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.2716</td> <td>    0.027</td> <td>   10.188</td> <td> 0.000</td> <td>    0.219</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0821</td> <td>    0.033</td> <td>    2.519</td> <td> 0.012</td> <td>    0.018</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.1676</td> <td>    0.022</td> <td>    7.712</td> <td> 0.000</td> <td>    0.125</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.1731</td> <td>    0.024</td> <td>    7.159</td> <td> 0.000</td> <td>    0.126</td> <td>    0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.2333</td> <td>    0.024</td> <td>    9.633</td> <td> 0.000</td> <td>    0.186</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2883</td> <td>    0.035</td> <td>    8.201</td> <td> 0.000</td> <td>    0.219</td> <td>    0.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.2482</td> <td>    0.029</td> <td>    8.609</td> <td> 0.000</td> <td>    0.192</td> <td>    0.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.3132</td> <td>    0.047</td> <td>    6.702</td> <td> 0.000</td> <td>    0.222</td> <td>    0.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -0.0767</td> <td>    0.094</td> <td>   -0.816</td> <td> 0.415</td> <td>   -0.261</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.1809</td> <td>    0.034</td> <td>    5.329</td> <td> 0.000</td> <td>    0.114</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.2557</td> <td>    0.033</td> <td>    7.692</td> <td> 0.000</td> <td>    0.190</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.3164</td> <td>    0.034</td> <td>    9.386</td> <td> 0.000</td> <td>    0.250</td> <td>    0.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.3832</td> <td>    0.035</td> <td>   10.873</td> <td> 0.000</td> <td>    0.314</td> <td>    0.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.4847</td> <td>    0.038</td> <td>   12.803</td> <td> 0.000</td> <td>    0.410</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.6032</td> <td>    0.047</td> <td>   12.748</td> <td> 0.000</td> <td>    0.510</td> <td>    0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>    0.6836</td> <td>    0.058</td> <td>   11.716</td> <td> 0.000</td> <td>    0.569</td> <td>    0.798</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.2787</td> <td>    0.068</td> <td>   -4.077</td> <td> 0.000</td> <td>   -0.413</td> <td>   -0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.1789</td> <td>    0.067</td> <td>   -2.666</td> <td> 0.008</td> <td>   -0.310</td> <td>   -0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>   -0.1301</td> <td>    0.067</td> <td>   -1.951</td> <td> 0.051</td> <td>   -0.261</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.0395</td> <td>    0.068</td> <td>   -0.578</td> <td> 0.563</td> <td>   -0.173</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>    0.0917</td> <td>    0.031</td> <td>    2.931</td> <td> 0.003</td> <td>    0.030</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.0892</td> <td>    0.044</td> <td>   -2.032</td> <td> 0.042</td> <td>   -0.175</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>    0.0196</td> <td>    0.014</td> <td>    1.387</td> <td> 0.166</td> <td>   -0.008</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.4169</td> <td>    0.147</td> <td>   -2.842</td> <td> 0.005</td> <td>   -0.705</td> <td>   -0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.3236</td> <td>    0.147</td> <td>   -2.203</td> <td> 0.028</td> <td>   -0.612</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.1771</td> <td>    0.153</td> <td>   -1.155</td> <td> 0.248</td> <td>   -0.478</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.2452</td> <td>    0.110</td> <td>   -2.224</td> <td> 0.026</td> <td>   -0.461</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.1849</td> <td>    0.111</td> <td>   -1.664</td> <td> 0.096</td> <td>   -0.403</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.2956</td> <td>    0.084</td> <td>   -3.519</td> <td> 0.000</td> <td>   -0.460</td> <td>   -0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.1224</td> <td>    0.032</td> <td>   -3.830</td> <td> 0.000</td> <td>   -0.185</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>   -0.1185</td> <td>    0.028</td> <td>   -4.187</td> <td> 0.000</td> <td>   -0.174</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>    0.0598</td> <td>    0.046</td> <td>    1.287</td> <td> 0.198</td> <td>   -0.031</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>    0.0670</td> <td>    0.046</td> <td>    1.449</td> <td> 0.147</td> <td>   -0.024</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>   -0.1380</td> <td>    0.178</td> <td>   -0.777</td> <td> 0.437</td> <td>   -0.487</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>   -0.2605</td> <td>    0.156</td> <td>   -1.672</td> <td> 0.095</td> <td>   -0.566</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>   -0.2528</td> <td>    0.154</td> <td>   -1.639</td> <td> 0.102</td> <td>   -0.556</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>   -0.2539</td> <td>    0.154</td> <td>   -1.650</td> <td> 0.099</td> <td>   -0.556</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>   -0.2918</td> <td>    0.153</td> <td>   -1.904</td> <td> 0.057</td> <td>   -0.593</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>   -0.3807</td> <td>    0.155</td> <td>   -2.454</td> <td> 0.014</td> <td>   -0.685</td> <td>   -0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>   -0.3967</td> <td>    0.162</td> <td>   -2.455</td> <td> 0.014</td> <td>   -0.714</td> <td>   -0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>    0.1286</td> <td>    0.023</td> <td>    5.665</td> <td> 0.000</td> <td>    0.084</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>   <td>   -0.0443</td> <td>    0.026</td> <td>   -1.693</td> <td> 0.091</td> <td>   -0.096</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>   <td>    0.0603</td> <td>    0.012</td> <td>    5.226</td> <td> 0.000</td> <td>    0.038</td> <td>    0.083</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.042</td> <th>  Durbin-Watson:     </th> <td>   1.947</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 888.100</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.823</td>  <th>  Prob(JB):          </th> <td>1.42e-193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.451</td>  <th>  Cond. No.          </th> <td>    947.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.879\n",
       "Model:                            OLS   Adj. R-squared:                  0.874\n",
       "Method:                 Least Squares   F-statistic:                     175.2\n",
       "Date:                Fri, 10 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        23:59:47   Log-Likelihood:                 808.07\n",
       "No. Observations:                1458   AIC:                            -1498.\n",
       "Df Residuals:                    1399   BIC:                            -1186.\n",
       "Df Model:                          58                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.3368      0.317     29.449      0.000       8.715       9.959\n",
       "x1             0.4433      0.024     18.818      0.000       0.397       0.489\n",
       "x2             0.1880      0.041      4.629      0.000       0.108       0.268\n",
       "x3            -0.0769      0.039     -1.958      0.050      -0.154       0.000\n",
       "x4             0.1156      0.023      5.043      0.000       0.071       0.161\n",
       "x5             0.3085      0.031     10.108      0.000       0.249       0.368\n",
       "x6             0.2288      0.020     11.230      0.000       0.189       0.269\n",
       "x7             0.2751      0.024     11.325      0.000       0.227       0.323\n",
       "x8             0.0779      0.019      3.998      0.000       0.040       0.116\n",
       "x9             0.2131      0.024      9.042      0.000       0.167       0.259\n",
       "x10           -0.0475      0.027     -1.742      0.082      -0.101       0.006\n",
       "x11            0.1880      0.025      7.588      0.000       0.139       0.237\n",
       "x12            0.1695      0.016     10.387      0.000       0.138       0.202\n",
       "x13            0.1352      0.051      2.646      0.008       0.035       0.235\n",
       "x14            0.2009      0.023      8.788      0.000       0.156       0.246\n",
       "x15            0.3038      0.030     10.007      0.000       0.244       0.363\n",
       "x16            0.2716      0.027     10.188      0.000       0.219       0.324\n",
       "x17            0.0821      0.033      2.519      0.012       0.018       0.146\n",
       "x18            0.1676      0.022      7.712      0.000       0.125       0.210\n",
       "x19            0.1731      0.024      7.159      0.000       0.126       0.221\n",
       "x20            0.2333      0.024      9.633      0.000       0.186       0.281\n",
       "x21            0.2883      0.035      8.201      0.000       0.219       0.357\n",
       "x22            0.2482      0.029      8.609      0.000       0.192       0.305\n",
       "x23            0.3132      0.047      6.702      0.000       0.222       0.405\n",
       "x24           -0.0767      0.094     -0.816      0.415      -0.261       0.108\n",
       "x25            0.1809      0.034      5.329      0.000       0.114       0.248\n",
       "x26            0.2557      0.033      7.692      0.000       0.190       0.321\n",
       "x27            0.3164      0.034      9.386      0.000       0.250       0.383\n",
       "x28            0.3832      0.035     10.873      0.000       0.314       0.452\n",
       "x29            0.4847      0.038     12.803      0.000       0.410       0.559\n",
       "x30            0.6032      0.047     12.748      0.000       0.510       0.696\n",
       "x31            0.6836      0.058     11.716      0.000       0.569       0.798\n",
       "x32           -0.2787      0.068     -4.077      0.000      -0.413      -0.145\n",
       "x33           -0.1789      0.067     -2.666      0.008      -0.310      -0.047\n",
       "x34           -0.1301      0.067     -1.951      0.051      -0.261       0.001\n",
       "x35           -0.0395      0.068     -0.578      0.563      -0.173       0.094\n",
       "x36            0.0917      0.031      2.931      0.003       0.030       0.153\n",
       "x37           -0.0892      0.044     -2.032      0.042      -0.175      -0.003\n",
       "x38            0.0196      0.014      1.387      0.166      -0.008       0.047\n",
       "x39           -0.4169      0.147     -2.842      0.005      -0.705      -0.129\n",
       "x40           -0.3236      0.147     -2.203      0.028      -0.612      -0.035\n",
       "x41           -0.1771      0.153     -1.155      0.248      -0.478       0.124\n",
       "x42           -0.2452      0.110     -2.224      0.026      -0.461      -0.029\n",
       "x43           -0.1849      0.111     -1.664      0.096      -0.403       0.033\n",
       "x44           -0.2956      0.084     -3.519      0.000      -0.460      -0.131\n",
       "x45           -0.1224      0.032     -3.830      0.000      -0.185      -0.060\n",
       "x46           -0.1185      0.028     -4.187      0.000      -0.174      -0.063\n",
       "x47            0.0598      0.046      1.287      0.198      -0.031       0.151\n",
       "x48            0.0670      0.046      1.449      0.147      -0.024       0.158\n",
       "x49           -0.1380      0.178     -0.777      0.437      -0.487       0.211\n",
       "x50           -0.2605      0.156     -1.672      0.095      -0.566       0.045\n",
       "x51           -0.2528      0.154     -1.639      0.102      -0.556       0.050\n",
       "x52           -0.2539      0.154     -1.650      0.099      -0.556       0.048\n",
       "x53           -0.2918      0.153     -1.904      0.057      -0.593       0.009\n",
       "x54           -0.3807      0.155     -2.454      0.014      -0.685      -0.076\n",
       "x55           -0.3967      0.162     -2.455      0.014      -0.714      -0.080\n",
       "x56            0.1286      0.023      5.665      0.000       0.084       0.173\n",
       "x57           -0.0443      0.026     -1.693      0.091      -0.096       0.007\n",
       "x58            0.0603      0.012      5.226      0.000       0.038       0.083\n",
       "==============================================================================\n",
       "Omnibus:                      252.042   Durbin-Watson:                   1.947\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              888.100\n",
       "Skew:                          -0.823   Prob(JB):                    1.42e-193\n",
       "Kurtosis:                       6.451   Cond. No.                         947.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables for the multiple linear regression\n",
    "X_4 = data_encoded[[\"GrLivArea\",\"Neighborhood_Blmngtn\",\"Neighborhood_BrDale\",\"Neighborhood_BrkSide\",\"Neighborhood_ClearCr\",\"Neighborhood_CollgCr\",\"Neighborhood_Crawfor\",\"Neighborhood_Edwards\",\"Neighborhood_Gilbert\",\"Neighborhood_IDOTRR\",\"Neighborhood_Mitchel\",\"Neighborhood_NAmes\",\"Neighborhood_NPkVill\",\"Neighborhood_NWAmes\",\"Neighborhood_NoRidge\",\"Neighborhood_NridgHt\",\"Neighborhood_SWISU\",\"Neighborhood_Sawyer\",\"Neighborhood_SawyerW\",\"Neighborhood_Somerst\",\"Neighborhood_StoneBr\",\"Neighborhood_Timber\",\"Neighborhood_Veenker\",\"OverallQual_2\",\"OverallQual_4\",\"OverallQual_5\",\"OverallQual_6\",\"OverallQual_7\",\"OverallQual_8\",\"OverallQual_9\",\"OverallQual_10\",\"GarageCars_0\",\"GarageCars_1\",\"GarageCars_2\",\"GarageCars_3\",\"ExterQual_Ex\",\"ExterQual_Fa\",\"ExterQual_Gd\",\"BsmtFullBath_0\",\"BsmtFullBath_1\",\"BsmtFullBath_2\",\"BsmtHalfBath_0\",\"BsmtHalfBath_1\",\"FullBath_0\",\"FullBath_1\",\"FullBath_2\",\"HalfBath_0\",\"HalfBath_1\",\"BedroomAbvGr_0\",\"BedroomAbvGr_1\",\"BedroomAbvGr_2\",\"BedroomAbvGr_3\",\"BedroomAbvGr_4\",\"BedroomAbvGr_5\",\"BedroomAbvGr_6\",\"KitchenQual_Ex\",\"KitchenQual_Fa\",\"KitchenQual_Gd\"]]\n",
    "# Ignores these variables to avoid the dummy variable trap: \"Neighborhood_Blueste\",\"OverallQual_1\", \"GarageCars_4\",\"ExterQual_TA\", \"BsmtFullBath_3\",\"BsmtHalfBath_2\",\"HalfBath_2\",\"FullBath_3\",\"BedroomAbvGr_8\",\"KitchenQual_TA\"\n",
    "# Removing these variables because they're not statistically significant: \"OverallQual_3\",\"Neighborhood_MeadowV\",\n",
    "# Redefine X\n",
    "X = X_4.values\n",
    "# Split data into training and testing set\n",
    "# random_state ensures answers are reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2, random_state = 0)\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "regressor = LinearRegression()\n",
    "# fitting linear regressor to our training dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Build the optimal model using backward elimination\n",
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "# X_opt = X[:, [0,1]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   178.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:02:08</td>     <th>  Log-Likelihood:    </th> <td>  807.90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1458</td>      <th>  AIC:               </th> <td>  -1500.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1400</td>      <th>  BIC:               </th> <td>  -1193.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    57</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.3018</td> <td>    0.311</td> <td>   29.896</td> <td> 0.000</td> <td>    8.691</td> <td>    9.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4435</td> <td>    0.024</td> <td>   18.835</td> <td> 0.000</td> <td>    0.397</td> <td>    0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1869</td> <td>    0.041</td> <td>    4.609</td> <td> 0.000</td> <td>    0.107</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0771</td> <td>    0.039</td> <td>   -1.963</td> <td> 0.050</td> <td>   -0.154</td> <td>-5.65e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1154</td> <td>    0.023</td> <td>    5.033</td> <td> 0.000</td> <td>    0.070</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3081</td> <td>    0.031</td> <td>   10.100</td> <td> 0.000</td> <td>    0.248</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2283</td> <td>    0.020</td> <td>   11.218</td> <td> 0.000</td> <td>    0.188</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2748</td> <td>    0.024</td> <td>   11.316</td> <td> 0.000</td> <td>    0.227</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0776</td> <td>    0.019</td> <td>    3.986</td> <td> 0.000</td> <td>    0.039</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2127</td> <td>    0.024</td> <td>    9.032</td> <td> 0.000</td> <td>    0.167</td> <td>    0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0478</td> <td>    0.027</td> <td>   -1.754</td> <td> 0.080</td> <td>   -0.101</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1890</td> <td>    0.025</td> <td>    7.653</td> <td> 0.000</td> <td>    0.141</td> <td>    0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1695</td> <td>    0.016</td> <td>   10.387</td> <td> 0.000</td> <td>    0.137</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.1350</td> <td>    0.051</td> <td>    2.644</td> <td> 0.008</td> <td>    0.035</td> <td>    0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.2005</td> <td>    0.023</td> <td>    8.777</td> <td> 0.000</td> <td>    0.156</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.3026</td> <td>    0.030</td> <td>    9.993</td> <td> 0.000</td> <td>    0.243</td> <td>    0.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.2707</td> <td>    0.027</td> <td>   10.174</td> <td> 0.000</td> <td>    0.218</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0819</td> <td>    0.033</td> <td>    2.513</td> <td> 0.012</td> <td>    0.018</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.1673</td> <td>    0.022</td> <td>    7.703</td> <td> 0.000</td> <td>    0.125</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.1725</td> <td>    0.024</td> <td>    7.143</td> <td> 0.000</td> <td>    0.125</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.2327</td> <td>    0.024</td> <td>    9.619</td> <td> 0.000</td> <td>    0.185</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2878</td> <td>    0.035</td> <td>    8.192</td> <td> 0.000</td> <td>    0.219</td> <td>    0.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.2472</td> <td>    0.029</td> <td>    8.592</td> <td> 0.000</td> <td>    0.191</td> <td>    0.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.3126</td> <td>    0.047</td> <td>    6.692</td> <td> 0.000</td> <td>    0.221</td> <td>    0.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -0.0752</td> <td>    0.094</td> <td>   -0.800</td> <td> 0.424</td> <td>   -0.259</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.1815</td> <td>    0.034</td> <td>    5.349</td> <td> 0.000</td> <td>    0.115</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.2554</td> <td>    0.033</td> <td>    7.686</td> <td> 0.000</td> <td>    0.190</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.3163</td> <td>    0.034</td> <td>    9.384</td> <td> 0.000</td> <td>    0.250</td> <td>    0.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.3833</td> <td>    0.035</td> <td>   10.879</td> <td> 0.000</td> <td>    0.314</td> <td>    0.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.4840</td> <td>    0.038</td> <td>   12.795</td> <td> 0.000</td> <td>    0.410</td> <td>    0.558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.6022</td> <td>    0.047</td> <td>   12.739</td> <td> 0.000</td> <td>    0.510</td> <td>    0.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>    0.6824</td> <td>    0.058</td> <td>   11.705</td> <td> 0.000</td> <td>    0.568</td> <td>    0.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.2417</td> <td>    0.024</td> <td>  -10.006</td> <td> 0.000</td> <td>   -0.289</td> <td>   -0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.1416</td> <td>    0.019</td> <td>   -7.645</td> <td> 0.000</td> <td>   -0.178</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>   -0.0925</td> <td>    0.015</td> <td>   -6.057</td> <td> 0.000</td> <td>   -0.122</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    0.0918</td> <td>    0.031</td> <td>    2.933</td> <td> 0.003</td> <td>    0.030</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.0892</td> <td>    0.044</td> <td>   -2.034</td> <td> 0.042</td> <td>   -0.175</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>    0.0198</td> <td>    0.014</td> <td>    1.399</td> <td> 0.162</td> <td>   -0.008</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.4181</td> <td>    0.147</td> <td>   -2.851</td> <td> 0.004</td> <td>   -0.706</td> <td>   -0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.3247</td> <td>    0.147</td> <td>   -2.211</td> <td> 0.027</td> <td>   -0.613</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.1749</td> <td>    0.153</td> <td>   -1.141</td> <td> 0.254</td> <td>   -0.475</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.2450</td> <td>    0.110</td> <td>   -2.223</td> <td> 0.026</td> <td>   -0.461</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.1843</td> <td>    0.111</td> <td>   -1.659</td> <td> 0.097</td> <td>   -0.402</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.2979</td> <td>    0.084</td> <td>   -3.552</td> <td> 0.000</td> <td>   -0.462</td> <td>   -0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.1219</td> <td>    0.032</td> <td>   -3.817</td> <td> 0.000</td> <td>   -0.185</td> <td>   -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.1182</td> <td>    0.028</td> <td>   -4.181</td> <td> 0.000</td> <td>   -0.174</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>    0.0573</td> <td>    0.046</td> <td>    1.240</td> <td> 0.215</td> <td>   -0.033</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>    0.0647</td> <td>    0.046</td> <td>    1.404</td> <td> 0.161</td> <td>   -0.026</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -0.1395</td> <td>    0.178</td> <td>   -0.785</td> <td> 0.432</td> <td>   -0.488</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>   -0.2614</td> <td>    0.156</td> <td>   -1.678</td> <td> 0.094</td> <td>   -0.567</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>   -0.2534</td> <td>    0.154</td> <td>   -1.643</td> <td> 0.101</td> <td>   -0.556</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>   -0.2546</td> <td>    0.154</td> <td>   -1.656</td> <td> 0.098</td> <td>   -0.556</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>   -0.2927</td> <td>    0.153</td> <td>   -1.910</td> <td> 0.056</td> <td>   -0.593</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>   -0.3819</td> <td>    0.155</td> <td>   -2.463</td> <td> 0.014</td> <td>   -0.686</td> <td>   -0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>   -0.3921</td> <td>    0.161</td> <td>   -2.430</td> <td> 0.015</td> <td>   -0.709</td> <td>   -0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>    0.1282</td> <td>    0.023</td> <td>    5.653</td> <td> 0.000</td> <td>    0.084</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>   -0.0444</td> <td>    0.026</td> <td>   -1.701</td> <td> 0.089</td> <td>   -0.096</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>   <td>    0.0602</td> <td>    0.012</td> <td>    5.220</td> <td> 0.000</td> <td>    0.038</td> <td>    0.083</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.994</td> <th>  Durbin-Watson:     </th> <td>   1.947</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 893.531</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.826</td>  <th>  Prob(JB):          </th> <td>9.38e-195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.461</td>  <th>  Cond. No.          </th> <td>    944.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.879\n",
       "Model:                            OLS   Adj. R-squared:                  0.874\n",
       "Method:                 Least Squares   F-statistic:                     178.3\n",
       "Date:                Sat, 11 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        00:02:08   Log-Likelihood:                 807.90\n",
       "No. Observations:                1458   AIC:                            -1500.\n",
       "Df Residuals:                    1400   BIC:                            -1193.\n",
       "Df Model:                          57                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.3018      0.311     29.896      0.000       8.691       9.912\n",
       "x1             0.4435      0.024     18.835      0.000       0.397       0.490\n",
       "x2             0.1869      0.041      4.609      0.000       0.107       0.267\n",
       "x3            -0.0771      0.039     -1.963      0.050      -0.154   -5.65e-05\n",
       "x4             0.1154      0.023      5.033      0.000       0.070       0.160\n",
       "x5             0.3081      0.031     10.100      0.000       0.248       0.368\n",
       "x6             0.2283      0.020     11.218      0.000       0.188       0.268\n",
       "x7             0.2748      0.024     11.316      0.000       0.227       0.322\n",
       "x8             0.0776      0.019      3.986      0.000       0.039       0.116\n",
       "x9             0.2127      0.024      9.032      0.000       0.167       0.259\n",
       "x10           -0.0478      0.027     -1.754      0.080      -0.101       0.006\n",
       "x11            0.1890      0.025      7.653      0.000       0.141       0.237\n",
       "x12            0.1695      0.016     10.387      0.000       0.137       0.201\n",
       "x13            0.1350      0.051      2.644      0.008       0.035       0.235\n",
       "x14            0.2005      0.023      8.777      0.000       0.156       0.245\n",
       "x15            0.3026      0.030      9.993      0.000       0.243       0.362\n",
       "x16            0.2707      0.027     10.174      0.000       0.218       0.323\n",
       "x17            0.0819      0.033      2.513      0.012       0.018       0.146\n",
       "x18            0.1673      0.022      7.703      0.000       0.125       0.210\n",
       "x19            0.1725      0.024      7.143      0.000       0.125       0.220\n",
       "x20            0.2327      0.024      9.619      0.000       0.185       0.280\n",
       "x21            0.2878      0.035      8.192      0.000       0.219       0.357\n",
       "x22            0.2472      0.029      8.592      0.000       0.191       0.304\n",
       "x23            0.3126      0.047      6.692      0.000       0.221       0.404\n",
       "x24           -0.0752      0.094     -0.800      0.424      -0.259       0.109\n",
       "x25            0.1815      0.034      5.349      0.000       0.115       0.248\n",
       "x26            0.2554      0.033      7.686      0.000       0.190       0.321\n",
       "x27            0.3163      0.034      9.384      0.000       0.250       0.382\n",
       "x28            0.3833      0.035     10.879      0.000       0.314       0.452\n",
       "x29            0.4840      0.038     12.795      0.000       0.410       0.558\n",
       "x30            0.6022      0.047     12.739      0.000       0.510       0.695\n",
       "x31            0.6824      0.058     11.705      0.000       0.568       0.797\n",
       "x32           -0.2417      0.024    -10.006      0.000      -0.289      -0.194\n",
       "x33           -0.1416      0.019     -7.645      0.000      -0.178      -0.105\n",
       "x34           -0.0925      0.015     -6.057      0.000      -0.122      -0.063\n",
       "x35            0.0918      0.031      2.933      0.003       0.030       0.153\n",
       "x36           -0.0892      0.044     -2.034      0.042      -0.175      -0.003\n",
       "x37            0.0198      0.014      1.399      0.162      -0.008       0.047\n",
       "x38           -0.4181      0.147     -2.851      0.004      -0.706      -0.130\n",
       "x39           -0.3247      0.147     -2.211      0.027      -0.613      -0.037\n",
       "x40           -0.1749      0.153     -1.141      0.254      -0.475       0.126\n",
       "x41           -0.2450      0.110     -2.223      0.026      -0.461      -0.029\n",
       "x42           -0.1843      0.111     -1.659      0.097      -0.402       0.034\n",
       "x43           -0.2979      0.084     -3.552      0.000      -0.462      -0.133\n",
       "x44           -0.1219      0.032     -3.817      0.000      -0.185      -0.059\n",
       "x45           -0.1182      0.028     -4.181      0.000      -0.174      -0.063\n",
       "x46            0.0573      0.046      1.240      0.215      -0.033       0.148\n",
       "x47            0.0647      0.046      1.404      0.161      -0.026       0.155\n",
       "x48           -0.1395      0.178     -0.785      0.432      -0.488       0.209\n",
       "x49           -0.2614      0.156     -1.678      0.094      -0.567       0.044\n",
       "x50           -0.2534      0.154     -1.643      0.101      -0.556       0.049\n",
       "x51           -0.2546      0.154     -1.656      0.098      -0.556       0.047\n",
       "x52           -0.2927      0.153     -1.910      0.056      -0.593       0.008\n",
       "x53           -0.3819      0.155     -2.463      0.014      -0.686      -0.078\n",
       "x54           -0.3921      0.161     -2.430      0.015      -0.709      -0.076\n",
       "x55            0.1282      0.023      5.653      0.000       0.084       0.173\n",
       "x56           -0.0444      0.026     -1.701      0.089      -0.096       0.007\n",
       "x57            0.0602      0.012      5.220      0.000       0.038       0.083\n",
       "==============================================================================\n",
       "Omnibus:                      252.994   Durbin-Watson:                   1.947\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              893.531\n",
       "Skew:                          -0.826   Prob(JB):                    9.38e-195\n",
       "Kurtosis:                       6.461   Cond. No.                         944.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables for the multiple linear regression\n",
    "X_5 = data_encoded[[\"GrLivArea\",\"Neighborhood_Blmngtn\",\"Neighborhood_BrDale\",\"Neighborhood_BrkSide\",\"Neighborhood_ClearCr\",\"Neighborhood_CollgCr\",\"Neighborhood_Crawfor\",\"Neighborhood_Edwards\",\"Neighborhood_Gilbert\",\"Neighborhood_IDOTRR\",\"Neighborhood_Mitchel\",\"Neighborhood_NAmes\",\"Neighborhood_NPkVill\",\"Neighborhood_NWAmes\",\"Neighborhood_NoRidge\",\"Neighborhood_NridgHt\",\"Neighborhood_SWISU\",\"Neighborhood_Sawyer\",\"Neighborhood_SawyerW\",\"Neighborhood_Somerst\",\"Neighborhood_StoneBr\",\"Neighborhood_Timber\",\"Neighborhood_Veenker\",\"OverallQual_2\",\"OverallQual_4\",\"OverallQual_5\",\"OverallQual_6\",\"OverallQual_7\",\"OverallQual_8\",\"OverallQual_9\",\"OverallQual_10\",\"GarageCars_0\",\"GarageCars_1\",\"GarageCars_2\",\"ExterQual_Ex\",\"ExterQual_Fa\",\"ExterQual_Gd\",\"BsmtFullBath_0\",\"BsmtFullBath_1\",\"BsmtFullBath_2\",\"BsmtHalfBath_0\",\"BsmtHalfBath_1\",\"FullBath_0\",\"FullBath_1\",\"FullBath_2\",\"HalfBath_0\",\"HalfBath_1\",\"BedroomAbvGr_0\",\"BedroomAbvGr_1\",\"BedroomAbvGr_2\",\"BedroomAbvGr_3\",\"BedroomAbvGr_4\",\"BedroomAbvGr_5\",\"BedroomAbvGr_6\",\"KitchenQual_Ex\",\"KitchenQual_Fa\",\"KitchenQual_Gd\"]]\n",
    "# Ignores these variables to avoid the dummy variable trap: \"Neighborhood_Blueste\",\"OverallQual_1\", \"GarageCars_4\",\"ExterQual_TA\", \"BsmtFullBath_3\",\"BsmtHalfBath_2\",\"HalfBath_2\",\"FullBath_3\",\"BedroomAbvGr_8\",\"KitchenQual_TA\"\n",
    "# Removing these variables because they're not statistically significant: \"OverallQual_3\",\"Neighborhood_MeadowV\", \"GarageCars_3\",\n",
    "# Redefine X\n",
    "X = X_5.values\n",
    "# Split data into training and testing set\n",
    "# random_state ensures answers are reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2, random_state = 0)\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "regressor = LinearRegression()\n",
    "# fitting linear regressor to our training dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Build the optimal model using backward elimination\n",
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "# X_opt = X[:, [0,1]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   181.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:05:23</td>     <th>  Log-Likelihood:    </th> <td>  807.56</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1458</td>      <th>  AIC:               </th> <td>  -1501.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1401</td>      <th>  BIC:               </th> <td>  -1200.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    56</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.2905</td> <td>    0.311</td> <td>   29.894</td> <td> 0.000</td> <td>    8.681</td> <td>    9.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4454</td> <td>    0.023</td> <td>   19.018</td> <td> 0.000</td> <td>    0.399</td> <td>    0.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1876</td> <td>    0.041</td> <td>    4.626</td> <td> 0.000</td> <td>    0.108</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0773</td> <td>    0.039</td> <td>   -1.969</td> <td> 0.049</td> <td>   -0.154</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1146</td> <td>    0.023</td> <td>    5.006</td> <td> 0.000</td> <td>    0.070</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3078</td> <td>    0.031</td> <td>   10.091</td> <td> 0.000</td> <td>    0.248</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2284</td> <td>    0.020</td> <td>   11.224</td> <td> 0.000</td> <td>    0.188</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2743</td> <td>    0.024</td> <td>   11.302</td> <td> 0.000</td> <td>    0.227</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0778</td> <td>    0.019</td> <td>    3.993</td> <td> 0.000</td> <td>    0.040</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2126</td> <td>    0.024</td> <td>    9.028</td> <td> 0.000</td> <td>    0.166</td> <td>    0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0489</td> <td>    0.027</td> <td>   -1.798</td> <td> 0.072</td> <td>   -0.102</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1887</td> <td>    0.025</td> <td>    7.643</td> <td> 0.000</td> <td>    0.140</td> <td>    0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1692</td> <td>    0.016</td> <td>   10.372</td> <td> 0.000</td> <td>    0.137</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.1351</td> <td>    0.051</td> <td>    2.646</td> <td> 0.008</td> <td>    0.035</td> <td>    0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.2003</td> <td>    0.023</td> <td>    8.768</td> <td> 0.000</td> <td>    0.155</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.3021</td> <td>    0.030</td> <td>    9.978</td> <td> 0.000</td> <td>    0.243</td> <td>    0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.2704</td> <td>    0.027</td> <td>   10.166</td> <td> 0.000</td> <td>    0.218</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0790</td> <td>    0.032</td> <td>    2.440</td> <td> 0.015</td> <td>    0.015</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.1671</td> <td>    0.022</td> <td>    7.696</td> <td> 0.000</td> <td>    0.125</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.1724</td> <td>    0.024</td> <td>    7.139</td> <td> 0.000</td> <td>    0.125</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.2327</td> <td>    0.024</td> <td>    9.619</td> <td> 0.000</td> <td>    0.185</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2876</td> <td>    0.035</td> <td>    8.186</td> <td> 0.000</td> <td>    0.219</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.2468</td> <td>    0.029</td> <td>    8.579</td> <td> 0.000</td> <td>    0.190</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.3127</td> <td>    0.047</td> <td>    6.695</td> <td> 0.000</td> <td>    0.221</td> <td>    0.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.1885</td> <td>    0.033</td> <td>    5.746</td> <td> 0.000</td> <td>    0.124</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.2618</td> <td>    0.032</td> <td>    8.126</td> <td> 0.000</td> <td>    0.199</td> <td>    0.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.3227</td> <td>    0.033</td> <td>    9.866</td> <td> 0.000</td> <td>    0.259</td> <td>    0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.3894</td> <td>    0.034</td> <td>   11.323</td> <td> 0.000</td> <td>    0.322</td> <td>    0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.4900</td> <td>    0.037</td> <td>   13.210</td> <td> 0.000</td> <td>    0.417</td> <td>    0.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.6082</td> <td>    0.047</td> <td>   13.028</td> <td> 0.000</td> <td>    0.517</td> <td>    0.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.6878</td> <td>    0.058</td> <td>   11.880</td> <td> 0.000</td> <td>    0.574</td> <td>    0.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.2413</td> <td>    0.024</td> <td>   -9.990</td> <td> 0.000</td> <td>   -0.289</td> <td>   -0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.1418</td> <td>    0.019</td> <td>   -7.661</td> <td> 0.000</td> <td>   -0.178</td> <td>   -0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.0926</td> <td>    0.015</td> <td>   -6.065</td> <td> 0.000</td> <td>   -0.123</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.0920</td> <td>    0.031</td> <td>    2.943</td> <td> 0.003</td> <td>    0.031</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.0898</td> <td>    0.044</td> <td>   -2.047</td> <td> 0.041</td> <td>   -0.176</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>    0.0199</td> <td>    0.014</td> <td>    1.411</td> <td> 0.158</td> <td>   -0.008</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.4180</td> <td>    0.147</td> <td>   -2.850</td> <td> 0.004</td> <td>   -0.706</td> <td>   -0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.3245</td> <td>    0.147</td> <td>   -2.210</td> <td> 0.027</td> <td>   -0.613</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.1728</td> <td>    0.153</td> <td>   -1.128</td> <td> 0.259</td> <td>   -0.473</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.2505</td> <td>    0.110</td> <td>   -2.278</td> <td> 0.023</td> <td>   -0.466</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.1898</td> <td>    0.111</td> <td>   -1.712</td> <td> 0.087</td> <td>   -0.407</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.3104</td> <td>    0.082</td> <td>   -3.767</td> <td> 0.000</td> <td>   -0.472</td> <td>   -0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.1209</td> <td>    0.032</td> <td>   -3.787</td> <td> 0.000</td> <td>   -0.183</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.1179</td> <td>    0.028</td> <td>   -4.169</td> <td> 0.000</td> <td>   -0.173</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>    0.0564</td> <td>    0.046</td> <td>    1.220</td> <td> 0.223</td> <td>   -0.034</td> <td>    0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>    0.0636</td> <td>    0.046</td> <td>    1.381</td> <td> 0.167</td> <td>   -0.027</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.1330</td> <td>    0.177</td> <td>   -0.750</td> <td> 0.453</td> <td>   -0.481</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -0.2675</td> <td>    0.156</td> <td>   -1.719</td> <td> 0.086</td> <td>   -0.573</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>   -0.2559</td> <td>    0.154</td> <td>   -1.659</td> <td> 0.097</td> <td>   -0.558</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>   -0.2575</td> <td>    0.154</td> <td>   -1.675</td> <td> 0.094</td> <td>   -0.559</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>   -0.2959</td> <td>    0.153</td> <td>   -1.932</td> <td> 0.054</td> <td>   -0.596</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>   -0.3852</td> <td>    0.155</td> <td>   -2.485</td> <td> 0.013</td> <td>   -0.689</td> <td>   -0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>   -0.3951</td> <td>    0.161</td> <td>   -2.449</td> <td> 0.014</td> <td>   -0.712</td> <td>   -0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>    0.1281</td> <td>    0.023</td> <td>    5.648</td> <td> 0.000</td> <td>    0.084</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>   -0.0462</td> <td>    0.026</td> <td>   -1.775</td> <td> 0.076</td> <td>   -0.097</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>    0.0602</td> <td>    0.012</td> <td>    5.224</td> <td> 0.000</td> <td>    0.038</td> <td>    0.083</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.332</td> <th>  Durbin-Watson:     </th> <td>   1.946</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 889.751</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.824</td>  <th>  Prob(JB):          </th> <td>6.21e-194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.454</td>  <th>  Cond. No.          </th> <td>    944.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.879\n",
       "Model:                            OLS   Adj. R-squared:                  0.874\n",
       "Method:                 Least Squares   F-statistic:                     181.5\n",
       "Date:                Sat, 11 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        00:05:23   Log-Likelihood:                 807.56\n",
       "No. Observations:                1458   AIC:                            -1501.\n",
       "Df Residuals:                    1401   BIC:                            -1200.\n",
       "Df Model:                          56                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.2905      0.311     29.894      0.000       8.681       9.900\n",
       "x1             0.4454      0.023     19.018      0.000       0.399       0.491\n",
       "x2             0.1876      0.041      4.626      0.000       0.108       0.267\n",
       "x3            -0.0773      0.039     -1.969      0.049      -0.154      -0.000\n",
       "x4             0.1146      0.023      5.006      0.000       0.070       0.160\n",
       "x5             0.3078      0.031     10.091      0.000       0.248       0.368\n",
       "x6             0.2284      0.020     11.224      0.000       0.188       0.268\n",
       "x7             0.2743      0.024     11.302      0.000       0.227       0.322\n",
       "x8             0.0778      0.019      3.993      0.000       0.040       0.116\n",
       "x9             0.2126      0.024      9.028      0.000       0.166       0.259\n",
       "x10           -0.0489      0.027     -1.798      0.072      -0.102       0.004\n",
       "x11            0.1887      0.025      7.643      0.000       0.140       0.237\n",
       "x12            0.1692      0.016     10.372      0.000       0.137       0.201\n",
       "x13            0.1351      0.051      2.646      0.008       0.035       0.235\n",
       "x14            0.2003      0.023      8.768      0.000       0.155       0.245\n",
       "x15            0.3021      0.030      9.978      0.000       0.243       0.361\n",
       "x16            0.2704      0.027     10.166      0.000       0.218       0.323\n",
       "x17            0.0790      0.032      2.440      0.015       0.015       0.143\n",
       "x18            0.1671      0.022      7.696      0.000       0.125       0.210\n",
       "x19            0.1724      0.024      7.139      0.000       0.125       0.220\n",
       "x20            0.2327      0.024      9.619      0.000       0.185       0.280\n",
       "x21            0.2876      0.035      8.186      0.000       0.219       0.356\n",
       "x22            0.2468      0.029      8.579      0.000       0.190       0.303\n",
       "x23            0.3127      0.047      6.695      0.000       0.221       0.404\n",
       "x24            0.1885      0.033      5.746      0.000       0.124       0.253\n",
       "x25            0.2618      0.032      8.126      0.000       0.199       0.325\n",
       "x26            0.3227      0.033      9.866      0.000       0.259       0.387\n",
       "x27            0.3894      0.034     11.323      0.000       0.322       0.457\n",
       "x28            0.4900      0.037     13.210      0.000       0.417       0.563\n",
       "x29            0.6082      0.047     13.028      0.000       0.517       0.700\n",
       "x30            0.6878      0.058     11.880      0.000       0.574       0.801\n",
       "x31           -0.2413      0.024     -9.990      0.000      -0.289      -0.194\n",
       "x32           -0.1418      0.019     -7.661      0.000      -0.178      -0.106\n",
       "x33           -0.0926      0.015     -6.065      0.000      -0.123      -0.063\n",
       "x34            0.0920      0.031      2.943      0.003       0.031       0.153\n",
       "x35           -0.0898      0.044     -2.047      0.041      -0.176      -0.004\n",
       "x36            0.0199      0.014      1.411      0.158      -0.008       0.048\n",
       "x37           -0.4180      0.147     -2.850      0.004      -0.706      -0.130\n",
       "x38           -0.3245      0.147     -2.210      0.027      -0.613      -0.036\n",
       "x39           -0.1728      0.153     -1.128      0.259      -0.473       0.128\n",
       "x40           -0.2505      0.110     -2.278      0.023      -0.466      -0.035\n",
       "x41           -0.1898      0.111     -1.712      0.087      -0.407       0.028\n",
       "x42           -0.3104      0.082     -3.767      0.000      -0.472      -0.149\n",
       "x43           -0.1209      0.032     -3.787      0.000      -0.183      -0.058\n",
       "x44           -0.1179      0.028     -4.169      0.000      -0.173      -0.062\n",
       "x45            0.0564      0.046      1.220      0.223      -0.034       0.147\n",
       "x46            0.0636      0.046      1.381      0.167      -0.027       0.154\n",
       "x47           -0.1330      0.177     -0.750      0.453      -0.481       0.215\n",
       "x48           -0.2675      0.156     -1.719      0.086      -0.573       0.038\n",
       "x49           -0.2559      0.154     -1.659      0.097      -0.558       0.047\n",
       "x50           -0.2575      0.154     -1.675      0.094      -0.559       0.044\n",
       "x51           -0.2959      0.153     -1.932      0.054      -0.596       0.005\n",
       "x52           -0.3852      0.155     -2.485      0.013      -0.689      -0.081\n",
       "x53           -0.3951      0.161     -2.449      0.014      -0.712      -0.079\n",
       "x54            0.1281      0.023      5.648      0.000       0.084       0.173\n",
       "x55           -0.0462      0.026     -1.775      0.076      -0.097       0.005\n",
       "x56            0.0602      0.012      5.224      0.000       0.038       0.083\n",
       "==============================================================================\n",
       "Omnibus:                      252.332   Durbin-Watson:                   1.946\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              889.751\n",
       "Skew:                          -0.824   Prob(JB):                    6.21e-194\n",
       "Kurtosis:                       6.454   Cond. No.                         944.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables for the multiple linear regression\n",
    "X_6 = data_encoded[[\"GrLivArea\",\"Neighborhood_Blmngtn\",\"Neighborhood_BrDale\",\"Neighborhood_BrkSide\",\"Neighborhood_ClearCr\",\"Neighborhood_CollgCr\",\"Neighborhood_Crawfor\",\"Neighborhood_Edwards\",\"Neighborhood_Gilbert\",\"Neighborhood_IDOTRR\",\"Neighborhood_Mitchel\",\"Neighborhood_NAmes\",\"Neighborhood_NPkVill\",\"Neighborhood_NWAmes\",\"Neighborhood_NoRidge\",\"Neighborhood_NridgHt\",\"Neighborhood_SWISU\",\"Neighborhood_Sawyer\",\"Neighborhood_SawyerW\",\"Neighborhood_Somerst\",\"Neighborhood_StoneBr\",\"Neighborhood_Timber\",\"Neighborhood_Veenker\",\"OverallQual_4\",\"OverallQual_5\",\"OverallQual_6\",\"OverallQual_7\",\"OverallQual_8\",\"OverallQual_9\",\"OverallQual_10\",\"GarageCars_0\",\"GarageCars_1\",\"GarageCars_2\",\"ExterQual_Ex\",\"ExterQual_Fa\",\"ExterQual_Gd\",\"BsmtFullBath_0\",\"BsmtFullBath_1\",\"BsmtFullBath_2\",\"BsmtHalfBath_0\",\"BsmtHalfBath_1\",\"FullBath_0\",\"FullBath_1\",\"FullBath_2\",\"HalfBath_0\",\"HalfBath_1\",\"BedroomAbvGr_0\",\"BedroomAbvGr_1\",\"BedroomAbvGr_2\",\"BedroomAbvGr_3\",\"BedroomAbvGr_4\",\"BedroomAbvGr_5\",\"BedroomAbvGr_6\",\"KitchenQual_Ex\",\"KitchenQual_Fa\",\"KitchenQual_Gd\"]]\n",
    "# Ignores these variables to avoid the dummy variable trap: \"Neighborhood_Blueste\",\"OverallQual_1\", \"GarageCars_4\",\"ExterQual_TA\", \"BsmtFullBath_3\",\"BsmtHalfBath_2\",\"HalfBath_2\",\"FullBath_3\",\"BedroomAbvGr_8\",\"KitchenQual_TA\"\n",
    "# Removing these variables because they're not statistically significant: \"OverallQual_3\",\"Neighborhood_MeadowV\", \"GarageCars_3\",\"OverallQual_2\",\n",
    "# Redefine X\n",
    "X = X_6.values\n",
    "# Split data into training and testing set\n",
    "# random_state ensures answers are reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2, random_state = 0)\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "regressor = LinearRegression()\n",
    "# fitting linear regressor to our training dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Build the optimal model using backward elimination\n",
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "# X_opt = X[:, [0,1]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   184.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:06:51</td>     <th>  Log-Likelihood:    </th> <td>  807.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1458</td>      <th>  AIC:               </th> <td>  -1503.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1402</td>      <th>  BIC:               </th> <td>  -1207.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    55</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.1820</td> <td>    0.275</td> <td>   33.383</td> <td> 0.000</td> <td>    8.642</td> <td>    9.722</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4476</td> <td>    0.023</td> <td>   19.262</td> <td> 0.000</td> <td>    0.402</td> <td>    0.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1882</td> <td>    0.041</td> <td>    4.644</td> <td> 0.000</td> <td>    0.109</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0768</td> <td>    0.039</td> <td>   -1.957</td> <td> 0.051</td> <td>   -0.154</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1144</td> <td>    0.023</td> <td>    4.998</td> <td> 0.000</td> <td>    0.070</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3077</td> <td>    0.030</td> <td>   10.088</td> <td> 0.000</td> <td>    0.248</td> <td>    0.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2289</td> <td>    0.020</td> <td>   11.259</td> <td> 0.000</td> <td>    0.189</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2743</td> <td>    0.024</td> <td>   11.304</td> <td> 0.000</td> <td>    0.227</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0782</td> <td>    0.019</td> <td>    4.016</td> <td> 0.000</td> <td>    0.040</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2130</td> <td>    0.024</td> <td>    9.052</td> <td> 0.000</td> <td>    0.167</td> <td>    0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0493</td> <td>    0.027</td> <td>   -1.812</td> <td> 0.070</td> <td>   -0.103</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1892</td> <td>    0.025</td> <td>    7.663</td> <td> 0.000</td> <td>    0.141</td> <td>    0.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1696</td> <td>    0.016</td> <td>   10.406</td> <td> 0.000</td> <td>    0.138</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.1355</td> <td>    0.051</td> <td>    2.654</td> <td> 0.008</td> <td>    0.035</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.2005</td> <td>    0.023</td> <td>    8.784</td> <td> 0.000</td> <td>    0.156</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.3025</td> <td>    0.030</td> <td>    9.994</td> <td> 0.000</td> <td>    0.243</td> <td>    0.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.2709</td> <td>    0.027</td> <td>   10.186</td> <td> 0.000</td> <td>    0.219</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0825</td> <td>    0.032</td> <td>    2.575</td> <td> 0.010</td> <td>    0.020</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.1673</td> <td>    0.022</td> <td>    7.703</td> <td> 0.000</td> <td>    0.125</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.1730</td> <td>    0.024</td> <td>    7.171</td> <td> 0.000</td> <td>    0.126</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.2332</td> <td>    0.024</td> <td>    9.647</td> <td> 0.000</td> <td>    0.186</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2866</td> <td>    0.035</td> <td>    8.166</td> <td> 0.000</td> <td>    0.218</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.2473</td> <td>    0.029</td> <td>    8.601</td> <td> 0.000</td> <td>    0.191</td> <td>    0.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.3125</td> <td>    0.047</td> <td>    6.691</td> <td> 0.000</td> <td>    0.221</td> <td>    0.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.1884</td> <td>    0.033</td> <td>    5.745</td> <td> 0.000</td> <td>    0.124</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.2625</td> <td>    0.032</td> <td>    8.149</td> <td> 0.000</td> <td>    0.199</td> <td>    0.326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.3233</td> <td>    0.033</td> <td>    9.885</td> <td> 0.000</td> <td>    0.259</td> <td>    0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.3895</td> <td>    0.034</td> <td>   11.329</td> <td> 0.000</td> <td>    0.322</td> <td>    0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.4899</td> <td>    0.037</td> <td>   13.210</td> <td> 0.000</td> <td>    0.417</td> <td>    0.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.6079</td> <td>    0.047</td> <td>   13.025</td> <td> 0.000</td> <td>    0.516</td> <td>    0.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.6874</td> <td>    0.058</td> <td>   11.875</td> <td> 0.000</td> <td>    0.574</td> <td>    0.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.2403</td> <td>    0.024</td> <td>   -9.966</td> <td> 0.000</td> <td>   -0.288</td> <td>   -0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.1417</td> <td>    0.019</td> <td>   -7.655</td> <td> 0.000</td> <td>   -0.178</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.0927</td> <td>    0.015</td> <td>   -6.073</td> <td> 0.000</td> <td>   -0.123</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.0922</td> <td>    0.031</td> <td>    2.948</td> <td> 0.003</td> <td>    0.031</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.0820</td> <td>    0.043</td> <td>   -1.924</td> <td> 0.055</td> <td>   -0.166</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>    0.0197</td> <td>    0.014</td> <td>    1.397</td> <td> 0.163</td> <td>   -0.008</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.4169</td> <td>    0.147</td> <td>   -2.844</td> <td> 0.005</td> <td>   -0.705</td> <td>   -0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.3235</td> <td>    0.147</td> <td>   -2.203</td> <td> 0.028</td> <td>   -0.611</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.1751</td> <td>    0.153</td> <td>   -1.143</td> <td> 0.253</td> <td>   -0.475</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.2586</td> <td>    0.109</td> <td>   -2.364</td> <td> 0.018</td> <td>   -0.473</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.1982</td> <td>    0.110</td> <td>   -1.798</td> <td> 0.072</td> <td>   -0.415</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.3284</td> <td>    0.079</td> <td>   -4.164</td> <td> 0.000</td> <td>   -0.483</td> <td>   -0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.1208</td> <td>    0.032</td> <td>   -3.786</td> <td> 0.000</td> <td>   -0.183</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.1177</td> <td>    0.028</td> <td>   -4.164</td> <td> 0.000</td> <td>   -0.173</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>    0.0548</td> <td>    0.046</td> <td>    1.188</td> <td> 0.235</td> <td>   -0.036</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>    0.0617</td> <td>    0.046</td> <td>    1.343</td> <td> 0.180</td> <td>   -0.028</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.1656</td> <td>    0.076</td> <td>   -2.188</td> <td> 0.029</td> <td>   -0.314</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -0.1549</td> <td>    0.075</td> <td>   -2.060</td> <td> 0.040</td> <td>   -0.302</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>   -0.1569</td> <td>    0.075</td> <td>   -2.093</td> <td> 0.037</td> <td>   -0.304</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>   -0.1960</td> <td>    0.076</td> <td>   -2.591</td> <td> 0.010</td> <td>   -0.344</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>   -0.2862</td> <td>    0.081</td> <td>   -3.518</td> <td> 0.000</td> <td>   -0.446</td> <td>   -0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>   -0.2967</td> <td>    0.094</td> <td>   -3.160</td> <td> 0.002</td> <td>   -0.481</td> <td>   -0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>    0.1276</td> <td>    0.023</td> <td>    5.629</td> <td> 0.000</td> <td>    0.083</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>   -0.0450</td> <td>    0.026</td> <td>   -1.731</td> <td> 0.084</td> <td>   -0.096</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>    0.0601</td> <td>    0.012</td> <td>    5.218</td> <td> 0.000</td> <td>    0.038</td> <td>    0.083</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>251.997</td> <th>  Durbin-Watson:     </th> <td>   1.945</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 886.289</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.824</td>  <th>  Prob(JB):          </th> <td>3.51e-193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.446</td>  <th>  Cond. No.          </th> <td>    682.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.879\n",
       "Model:                            OLS   Adj. R-squared:                  0.874\n",
       "Method:                 Least Squares   F-statistic:                     184.9\n",
       "Date:                Sat, 11 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        00:06:51   Log-Likelihood:                 807.27\n",
       "No. Observations:                1458   AIC:                            -1503.\n",
       "Df Residuals:                    1402   BIC:                            -1207.\n",
       "Df Model:                          55                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.1820      0.275     33.383      0.000       8.642       9.722\n",
       "x1             0.4476      0.023     19.262      0.000       0.402       0.493\n",
       "x2             0.1882      0.041      4.644      0.000       0.109       0.268\n",
       "x3            -0.0768      0.039     -1.957      0.051      -0.154       0.000\n",
       "x4             0.1144      0.023      4.998      0.000       0.070       0.159\n",
       "x5             0.3077      0.030     10.088      0.000       0.248       0.367\n",
       "x6             0.2289      0.020     11.259      0.000       0.189       0.269\n",
       "x7             0.2743      0.024     11.304      0.000       0.227       0.322\n",
       "x8             0.0782      0.019      4.016      0.000       0.040       0.116\n",
       "x9             0.2130      0.024      9.052      0.000       0.167       0.259\n",
       "x10           -0.0493      0.027     -1.812      0.070      -0.103       0.004\n",
       "x11            0.1892      0.025      7.663      0.000       0.141       0.238\n",
       "x12            0.1696      0.016     10.406      0.000       0.138       0.202\n",
       "x13            0.1355      0.051      2.654      0.008       0.035       0.236\n",
       "x14            0.2005      0.023      8.784      0.000       0.156       0.245\n",
       "x15            0.3025      0.030      9.994      0.000       0.243       0.362\n",
       "x16            0.2709      0.027     10.186      0.000       0.219       0.323\n",
       "x17            0.0825      0.032      2.575      0.010       0.020       0.145\n",
       "x18            0.1673      0.022      7.703      0.000       0.125       0.210\n",
       "x19            0.1730      0.024      7.171      0.000       0.126       0.220\n",
       "x20            0.2332      0.024      9.647      0.000       0.186       0.281\n",
       "x21            0.2866      0.035      8.166      0.000       0.218       0.356\n",
       "x22            0.2473      0.029      8.601      0.000       0.191       0.304\n",
       "x23            0.3125      0.047      6.691      0.000       0.221       0.404\n",
       "x24            0.1884      0.033      5.745      0.000       0.124       0.253\n",
       "x25            0.2625      0.032      8.149      0.000       0.199       0.326\n",
       "x26            0.3233      0.033      9.885      0.000       0.259       0.387\n",
       "x27            0.3895      0.034     11.329      0.000       0.322       0.457\n",
       "x28            0.4899      0.037     13.210      0.000       0.417       0.563\n",
       "x29            0.6079      0.047     13.025      0.000       0.516       0.699\n",
       "x30            0.6874      0.058     11.875      0.000       0.574       0.801\n",
       "x31           -0.2403      0.024     -9.966      0.000      -0.288      -0.193\n",
       "x32           -0.1417      0.019     -7.655      0.000      -0.178      -0.105\n",
       "x33           -0.0927      0.015     -6.073      0.000      -0.123      -0.063\n",
       "x34            0.0922      0.031      2.948      0.003       0.031       0.154\n",
       "x35           -0.0820      0.043     -1.924      0.055      -0.166       0.002\n",
       "x36            0.0197      0.014      1.397      0.163      -0.008       0.047\n",
       "x37           -0.4169      0.147     -2.844      0.005      -0.705      -0.129\n",
       "x38           -0.3235      0.147     -2.203      0.028      -0.611      -0.035\n",
       "x39           -0.1751      0.153     -1.143      0.253      -0.475       0.125\n",
       "x40           -0.2586      0.109     -2.364      0.018      -0.473      -0.044\n",
       "x41           -0.1982      0.110     -1.798      0.072      -0.415       0.018\n",
       "x42           -0.3284      0.079     -4.164      0.000      -0.483      -0.174\n",
       "x43           -0.1208      0.032     -3.786      0.000      -0.183      -0.058\n",
       "x44           -0.1177      0.028     -4.164      0.000      -0.173      -0.062\n",
       "x45            0.0548      0.046      1.188      0.235      -0.036       0.145\n",
       "x46            0.0617      0.046      1.343      0.180      -0.028       0.152\n",
       "x47           -0.1656      0.076     -2.188      0.029      -0.314      -0.017\n",
       "x48           -0.1549      0.075     -2.060      0.040      -0.302      -0.007\n",
       "x49           -0.1569      0.075     -2.093      0.037      -0.304      -0.010\n",
       "x50           -0.1960      0.076     -2.591      0.010      -0.344      -0.048\n",
       "x51           -0.2862      0.081     -3.518      0.000      -0.446      -0.127\n",
       "x52           -0.2967      0.094     -3.160      0.002      -0.481      -0.113\n",
       "x53            0.1276      0.023      5.629      0.000       0.083       0.172\n",
       "x54           -0.0450      0.026     -1.731      0.084      -0.096       0.006\n",
       "x55            0.0601      0.012      5.218      0.000       0.038       0.083\n",
       "==============================================================================\n",
       "Omnibus:                      251.997   Durbin-Watson:                   1.945\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              886.289\n",
       "Skew:                          -0.824   Prob(JB):                    3.51e-193\n",
       "Kurtosis:                       6.446   Cond. No.                         682.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables for the multiple linear regression\n",
    "X_7 = data_encoded[[\"GrLivArea\",\"Neighborhood_Blmngtn\",\"Neighborhood_BrDale\",\"Neighborhood_BrkSide\",\"Neighborhood_ClearCr\",\"Neighborhood_CollgCr\",\"Neighborhood_Crawfor\",\"Neighborhood_Edwards\",\"Neighborhood_Gilbert\",\"Neighborhood_IDOTRR\",\"Neighborhood_Mitchel\",\"Neighborhood_NAmes\",\"Neighborhood_NPkVill\",\"Neighborhood_NWAmes\",\"Neighborhood_NoRidge\",\"Neighborhood_NridgHt\",\"Neighborhood_SWISU\",\"Neighborhood_Sawyer\",\"Neighborhood_SawyerW\",\"Neighborhood_Somerst\",\"Neighborhood_StoneBr\",\"Neighborhood_Timber\",\"Neighborhood_Veenker\",\"OverallQual_4\",\"OverallQual_5\",\"OverallQual_6\",\"OverallQual_7\",\"OverallQual_8\",\"OverallQual_9\",\"OverallQual_10\",\"GarageCars_0\",\"GarageCars_1\",\"GarageCars_2\",\"ExterQual_Ex\",\"ExterQual_Fa\",\"ExterQual_Gd\",\"BsmtFullBath_0\",\"BsmtFullBath_1\",\"BsmtFullBath_2\",\"BsmtHalfBath_0\",\"BsmtHalfBath_1\",\"FullBath_0\",\"FullBath_1\",\"FullBath_2\",\"HalfBath_0\",\"HalfBath_1\",\"BedroomAbvGr_1\",\"BedroomAbvGr_2\",\"BedroomAbvGr_3\",\"BedroomAbvGr_4\",\"BedroomAbvGr_5\",\"BedroomAbvGr_6\",\"KitchenQual_Ex\",\"KitchenQual_Fa\",\"KitchenQual_Gd\"]]\n",
    "# Ignores these variables to avoid the dummy variable trap: \"Neighborhood_Blueste\",\"OverallQual_1\", \"GarageCars_4\",\"ExterQual_TA\", \"BsmtFullBath_3\",\"BsmtHalfBath_2\",\"HalfBath_2\",\"FullBath_3\",\"BedroomAbvGr_8\",\"KitchenQual_TA\"\n",
    "# Removing these variables because they're not statistically significant: \"OverallQual_3\",\"Neighborhood_MeadowV\", \"GarageCars_3\",\"OverallQual_2\",\"BedroomAbvGr_0\",\n",
    "# Redefine X\n",
    "X = X_7.values\n",
    "# Split data into training and testing set\n",
    "# random_state ensures answers are reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2, random_state = 0)\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "regressor = LinearRegression()\n",
    "# fitting linear regressor to our training dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Build the optimal model using backward elimination\n",
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "# X_opt = X[:, [0,1]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   188.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:10:33</td>     <th>  Log-Likelihood:    </th> <td>  806.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1458</td>      <th>  AIC:               </th> <td>  -1503.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1403</td>      <th>  BIC:               </th> <td>  -1212.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    54</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.2635</td> <td>    0.266</td> <td>   34.771</td> <td> 0.000</td> <td>    8.741</td> <td>    9.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4433</td> <td>    0.023</td> <td>   19.311</td> <td> 0.000</td> <td>    0.398</td> <td>    0.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1860</td> <td>    0.040</td> <td>    4.592</td> <td> 0.000</td> <td>    0.107</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0789</td> <td>    0.039</td> <td>   -2.012</td> <td> 0.044</td> <td>   -0.156</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1144</td> <td>    0.023</td> <td>    4.996</td> <td> 0.000</td> <td>    0.069</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3089</td> <td>    0.030</td> <td>   10.134</td> <td> 0.000</td> <td>    0.249</td> <td>    0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2273</td> <td>    0.020</td> <td>   11.202</td> <td> 0.000</td> <td>    0.187</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2743</td> <td>    0.024</td> <td>   11.300</td> <td> 0.000</td> <td>    0.227</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0780</td> <td>    0.019</td> <td>    4.005</td> <td> 0.000</td> <td>    0.040</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2112</td> <td>    0.023</td> <td>    8.991</td> <td> 0.000</td> <td>    0.165</td> <td>    0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0492</td> <td>    0.027</td> <td>   -1.806</td> <td> 0.071</td> <td>   -0.103</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1879</td> <td>    0.025</td> <td>    7.618</td> <td> 0.000</td> <td>    0.140</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1683</td> <td>    0.016</td> <td>   10.349</td> <td> 0.000</td> <td>    0.136</td> <td>    0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.1332</td> <td>    0.051</td> <td>    2.610</td> <td> 0.009</td> <td>    0.033</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.1983</td> <td>    0.023</td> <td>    8.714</td> <td> 0.000</td> <td>    0.154</td> <td>    0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.3018</td> <td>    0.030</td> <td>    9.973</td> <td> 0.000</td> <td>    0.242</td> <td>    0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.2693</td> <td>    0.027</td> <td>   10.139</td> <td> 0.000</td> <td>    0.217</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0830</td> <td>    0.032</td> <td>    2.589</td> <td> 0.010</td> <td>    0.020</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.1654</td> <td>    0.022</td> <td>    7.637</td> <td> 0.000</td> <td>    0.123</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.1715</td> <td>    0.024</td> <td>    7.116</td> <td> 0.000</td> <td>    0.124</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.2311</td> <td>    0.024</td> <td>    9.585</td> <td> 0.000</td> <td>    0.184</td> <td>    0.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2847</td> <td>    0.035</td> <td>    8.119</td> <td> 0.000</td> <td>    0.216</td> <td>    0.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.2466</td> <td>    0.029</td> <td>    8.578</td> <td> 0.000</td> <td>    0.190</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.3133</td> <td>    0.047</td> <td>    6.708</td> <td> 0.000</td> <td>    0.222</td> <td>    0.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.1873</td> <td>    0.033</td> <td>    5.714</td> <td> 0.000</td> <td>    0.123</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.2615</td> <td>    0.032</td> <td>    8.121</td> <td> 0.000</td> <td>    0.198</td> <td>    0.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.3225</td> <td>    0.033</td> <td>    9.863</td> <td> 0.000</td> <td>    0.258</td> <td>    0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.3892</td> <td>    0.034</td> <td>   11.318</td> <td> 0.000</td> <td>    0.322</td> <td>    0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.4903</td> <td>    0.037</td> <td>   13.218</td> <td> 0.000</td> <td>    0.418</td> <td>    0.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.6090</td> <td>    0.047</td> <td>   13.049</td> <td> 0.000</td> <td>    0.517</td> <td>    0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.6881</td> <td>    0.058</td> <td>   11.886</td> <td> 0.000</td> <td>    0.575</td> <td>    0.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.2419</td> <td>    0.024</td> <td>  -10.047</td> <td> 0.000</td> <td>   -0.289</td> <td>   -0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.1411</td> <td>    0.019</td> <td>   -7.626</td> <td> 0.000</td> <td>   -0.177</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.0927</td> <td>    0.015</td> <td>   -6.072</td> <td> 0.000</td> <td>   -0.123</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.0918</td> <td>    0.031</td> <td>    2.935</td> <td> 0.003</td> <td>    0.030</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.0809</td> <td>    0.043</td> <td>   -1.900</td> <td> 0.058</td> <td>   -0.164</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>    0.0194</td> <td>    0.014</td> <td>    1.375</td> <td> 0.169</td> <td>   -0.008</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.4151</td> <td>    0.147</td> <td>   -2.831</td> <td> 0.005</td> <td>   -0.703</td> <td>   -0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.3214</td> <td>    0.147</td> <td>   -2.189</td> <td> 0.029</td> <td>   -0.609</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.1810</td> <td>    0.153</td> <td>   -1.182</td> <td> 0.237</td> <td>   -0.481</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.2419</td> <td>    0.109</td> <td>   -2.229</td> <td> 0.026</td> <td>   -0.455</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.1827</td> <td>    0.110</td> <td>   -1.669</td> <td> 0.095</td> <td>   -0.398</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.3503</td> <td>    0.077</td> <td>   -4.568</td> <td> 0.000</td> <td>   -0.501</td> <td>   -0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.1247</td> <td>    0.032</td> <td>   -3.928</td> <td> 0.000</td> <td>   -0.187</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.1197</td> <td>    0.028</td> <td>   -4.241</td> <td> 0.000</td> <td>   -0.175</td> <td>   -0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>    0.0084</td> <td>    0.010</td> <td>    0.844</td> <td> 0.399</td> <td>   -0.011</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>   -0.1752</td> <td>    0.075</td> <td>   -2.328</td> <td> 0.020</td> <td>   -0.323</td> <td>   -0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.1654</td> <td>    0.075</td> <td>   -2.215</td> <td> 0.027</td> <td>   -0.312</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -0.1669</td> <td>    0.074</td> <td>   -2.240</td> <td> 0.025</td> <td>   -0.313</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>   -0.2072</td> <td>    0.075</td> <td>   -2.759</td> <td> 0.006</td> <td>   -0.354</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>   -0.2979</td> <td>    0.081</td> <td>   -3.688</td> <td> 0.000</td> <td>   -0.456</td> <td>   -0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>   -0.3123</td> <td>    0.093</td> <td>   -3.358</td> <td> 0.001</td> <td>   -0.495</td> <td>   -0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>    0.1278</td> <td>    0.023</td> <td>    5.636</td> <td> 0.000</td> <td>    0.083</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>   -0.0462</td> <td>    0.026</td> <td>   -1.780</td> <td> 0.075</td> <td>   -0.097</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>    0.0604</td> <td>    0.012</td> <td>    5.241</td> <td> 0.000</td> <td>    0.038</td> <td>    0.083</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>248.894</td> <th>  Durbin-Watson:     </th> <td>   1.946</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 874.270</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.814</td>  <th>  Prob(JB):          </th> <td>1.43e-190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.427</td>  <th>  Cond. No.          </th> <td>    670.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.879\n",
       "Model:                            OLS   Adj. R-squared:                  0.874\n",
       "Method:                 Least Squares   F-statistic:                     188.2\n",
       "Date:                Sat, 11 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        00:10:33   Log-Likelihood:                 806.54\n",
       "No. Observations:                1458   AIC:                            -1503.\n",
       "Df Residuals:                    1403   BIC:                            -1212.\n",
       "Df Model:                          54                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.2635      0.266     34.771      0.000       8.741       9.786\n",
       "x1             0.4433      0.023     19.311      0.000       0.398       0.488\n",
       "x2             0.1860      0.040      4.592      0.000       0.107       0.265\n",
       "x3            -0.0789      0.039     -2.012      0.044      -0.156      -0.002\n",
       "x4             0.1144      0.023      4.996      0.000       0.069       0.159\n",
       "x5             0.3089      0.030     10.134      0.000       0.249       0.369\n",
       "x6             0.2273      0.020     11.202      0.000       0.187       0.267\n",
       "x7             0.2743      0.024     11.300      0.000       0.227       0.322\n",
       "x8             0.0780      0.019      4.005      0.000       0.040       0.116\n",
       "x9             0.2112      0.023      8.991      0.000       0.165       0.257\n",
       "x10           -0.0492      0.027     -1.806      0.071      -0.103       0.004\n",
       "x11            0.1879      0.025      7.618      0.000       0.140       0.236\n",
       "x12            0.1683      0.016     10.349      0.000       0.136       0.200\n",
       "x13            0.1332      0.051      2.610      0.009       0.033       0.233\n",
       "x14            0.1983      0.023      8.714      0.000       0.154       0.243\n",
       "x15            0.3018      0.030      9.973      0.000       0.242       0.361\n",
       "x16            0.2693      0.027     10.139      0.000       0.217       0.321\n",
       "x17            0.0830      0.032      2.589      0.010       0.020       0.146\n",
       "x18            0.1654      0.022      7.637      0.000       0.123       0.208\n",
       "x19            0.1715      0.024      7.116      0.000       0.124       0.219\n",
       "x20            0.2311      0.024      9.585      0.000       0.184       0.278\n",
       "x21            0.2847      0.035      8.119      0.000       0.216       0.354\n",
       "x22            0.2466      0.029      8.578      0.000       0.190       0.303\n",
       "x23            0.3133      0.047      6.708      0.000       0.222       0.405\n",
       "x24            0.1873      0.033      5.714      0.000       0.123       0.252\n",
       "x25            0.2615      0.032      8.121      0.000       0.198       0.325\n",
       "x26            0.3225      0.033      9.863      0.000       0.258       0.387\n",
       "x27            0.3892      0.034     11.318      0.000       0.322       0.457\n",
       "x28            0.4903      0.037     13.218      0.000       0.418       0.563\n",
       "x29            0.6090      0.047     13.049      0.000       0.517       0.701\n",
       "x30            0.6881      0.058     11.886      0.000       0.575       0.802\n",
       "x31           -0.2419      0.024    -10.047      0.000      -0.289      -0.195\n",
       "x32           -0.1411      0.019     -7.626      0.000      -0.177      -0.105\n",
       "x33           -0.0927      0.015     -6.072      0.000      -0.123      -0.063\n",
       "x34            0.0918      0.031      2.935      0.003       0.030       0.153\n",
       "x35           -0.0809      0.043     -1.900      0.058      -0.164       0.003\n",
       "x36            0.0194      0.014      1.375      0.169      -0.008       0.047\n",
       "x37           -0.4151      0.147     -2.831      0.005      -0.703      -0.127\n",
       "x38           -0.3214      0.147     -2.189      0.029      -0.609      -0.033\n",
       "x39           -0.1810      0.153     -1.182      0.237      -0.481       0.119\n",
       "x40           -0.2419      0.109     -2.229      0.026      -0.455      -0.029\n",
       "x41           -0.1827      0.110     -1.669      0.095      -0.398       0.032\n",
       "x42           -0.3503      0.077     -4.568      0.000      -0.501      -0.200\n",
       "x43           -0.1247      0.032     -3.928      0.000      -0.187      -0.062\n",
       "x44           -0.1197      0.028     -4.241      0.000      -0.175      -0.064\n",
       "x45            0.0084      0.010      0.844      0.399      -0.011       0.028\n",
       "x46           -0.1752      0.075     -2.328      0.020      -0.323      -0.028\n",
       "x47           -0.1654      0.075     -2.215      0.027      -0.312      -0.019\n",
       "x48           -0.1669      0.074     -2.240      0.025      -0.313      -0.021\n",
       "x49           -0.2072      0.075     -2.759      0.006      -0.354      -0.060\n",
       "x50           -0.2979      0.081     -3.688      0.000      -0.456      -0.139\n",
       "x51           -0.3123      0.093     -3.358      0.001      -0.495      -0.130\n",
       "x52            0.1278      0.023      5.636      0.000       0.083       0.172\n",
       "x53           -0.0462      0.026     -1.780      0.075      -0.097       0.005\n",
       "x54            0.0604      0.012      5.241      0.000       0.038       0.083\n",
       "==============================================================================\n",
       "Omnibus:                      248.894   Durbin-Watson:                   1.946\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              874.270\n",
       "Skew:                          -0.814   Prob(JB):                    1.43e-190\n",
       "Kurtosis:                       6.427   Cond. No.                         670.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables for the multiple linear regression\n",
    "X_8 = data_encoded[[\"GrLivArea\",\"Neighborhood_Blmngtn\",\"Neighborhood_BrDale\",\"Neighborhood_BrkSide\",\"Neighborhood_ClearCr\",\"Neighborhood_CollgCr\",\"Neighborhood_Crawfor\",\"Neighborhood_Edwards\",\"Neighborhood_Gilbert\",\"Neighborhood_IDOTRR\",\"Neighborhood_Mitchel\",\"Neighborhood_NAmes\",\"Neighborhood_NPkVill\",\"Neighborhood_NWAmes\",\"Neighborhood_NoRidge\",\"Neighborhood_NridgHt\",\"Neighborhood_SWISU\",\"Neighborhood_Sawyer\",\"Neighborhood_SawyerW\",\"Neighborhood_Somerst\",\"Neighborhood_StoneBr\",\"Neighborhood_Timber\",\"Neighborhood_Veenker\",\"OverallQual_4\",\"OverallQual_5\",\"OverallQual_6\",\"OverallQual_7\",\"OverallQual_8\",\"OverallQual_9\",\"OverallQual_10\",\"GarageCars_0\",\"GarageCars_1\",\"GarageCars_2\",\"ExterQual_Ex\",\"ExterQual_Fa\",\"ExterQual_Gd\",\"BsmtFullBath_0\",\"BsmtFullBath_1\",\"BsmtFullBath_2\",\"BsmtHalfBath_0\",\"BsmtHalfBath_1\",\"FullBath_0\",\"FullBath_1\",\"FullBath_2\",\"HalfBath_1\",\"BedroomAbvGr_1\",\"BedroomAbvGr_2\",\"BedroomAbvGr_3\",\"BedroomAbvGr_4\",\"BedroomAbvGr_5\",\"BedroomAbvGr_6\",\"KitchenQual_Ex\",\"KitchenQual_Fa\",\"KitchenQual_Gd\"]]\n",
    "# Ignores these variables to avoid the dummy variable trap: \"Neighborhood_Blueste\",\"OverallQual_1\", \"GarageCars_4\",\"ExterQual_TA\", \"BsmtFullBath_3\",\"BsmtHalfBath_2\",\"HalfBath_2\",\"FullBath_3\",\"BedroomAbvGr_8\",\"KitchenQual_TA\"\n",
    "# Removing these variables because they're not statistically significant: \"OverallQual_3\",\"Neighborhood_MeadowV\", \"GarageCars_3\",\"OverallQual_2\",\"BedroomAbvGr_0\",\"HalfBath_0\",\n",
    "# Redefine X\n",
    "X = X_8.values\n",
    "# Split data into training and testing set\n",
    "# random_state ensures answers are reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2, random_state = 0)\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "regressor = LinearRegression()\n",
    "# fitting linear regressor to our training dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Build the optimal model using backward elimination\n",
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "# X_opt = X[:, [0,1]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   191.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:12:33</td>     <th>  Log-Likelihood:    </th> <td>  806.17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1458</td>      <th>  AIC:               </th> <td>  -1504.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1404</td>      <th>  BIC:               </th> <td>  -1219.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    53</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.2137</td> <td>    0.260</td> <td>   35.468</td> <td> 0.000</td> <td>    8.704</td> <td>    9.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4499</td> <td>    0.022</td> <td>   20.852</td> <td> 0.000</td> <td>    0.408</td> <td>    0.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1856</td> <td>    0.040</td> <td>    4.583</td> <td> 0.000</td> <td>    0.106</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0716</td> <td>    0.038</td> <td>   -1.872</td> <td> 0.061</td> <td>   -0.147</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1137</td> <td>    0.023</td> <td>    4.970</td> <td> 0.000</td> <td>    0.069</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3089</td> <td>    0.030</td> <td>   10.135</td> <td> 0.000</td> <td>    0.249</td> <td>    0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2291</td> <td>    0.020</td> <td>   11.361</td> <td> 0.000</td> <td>    0.190</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2744</td> <td>    0.024</td> <td>   11.309</td> <td> 0.000</td> <td>    0.227</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0780</td> <td>    0.019</td> <td>    4.006</td> <td> 0.000</td> <td>    0.040</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2160</td> <td>    0.023</td> <td>    9.492</td> <td> 0.000</td> <td>    0.171</td> <td>    0.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0494</td> <td>    0.027</td> <td>   -1.814</td> <td> 0.070</td> <td>   -0.103</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1879</td> <td>    0.025</td> <td>    7.621</td> <td> 0.000</td> <td>    0.140</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1686</td> <td>    0.016</td> <td>   10.370</td> <td> 0.000</td> <td>    0.137</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.1383</td> <td>    0.051</td> <td>    2.732</td> <td> 0.006</td> <td>    0.039</td> <td>    0.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.2005</td> <td>    0.023</td> <td>    8.869</td> <td> 0.000</td> <td>    0.156</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.3060</td> <td>    0.030</td> <td>   10.251</td> <td> 0.000</td> <td>    0.247</td> <td>    0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.2711</td> <td>    0.026</td> <td>   10.243</td> <td> 0.000</td> <td>    0.219</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0828</td> <td>    0.032</td> <td>    2.584</td> <td> 0.010</td> <td>    0.020</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.1663</td> <td>    0.022</td> <td>    7.683</td> <td> 0.000</td> <td>    0.124</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.1737</td> <td>    0.024</td> <td>    7.253</td> <td> 0.000</td> <td>    0.127</td> <td>    0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.2348</td> <td>    0.024</td> <td>    9.899</td> <td> 0.000</td> <td>    0.188</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2863</td> <td>    0.035</td> <td>    8.178</td> <td> 0.000</td> <td>    0.218</td> <td>    0.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.2484</td> <td>    0.029</td> <td>    8.662</td> <td> 0.000</td> <td>    0.192</td> <td>    0.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.3172</td> <td>    0.046</td> <td>    6.825</td> <td> 0.000</td> <td>    0.226</td> <td>    0.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.1865</td> <td>    0.033</td> <td>    5.693</td> <td> 0.000</td> <td>    0.122</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.2604</td> <td>    0.032</td> <td>    8.094</td> <td> 0.000</td> <td>    0.197</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.3220</td> <td>    0.033</td> <td>    9.849</td> <td> 0.000</td> <td>    0.258</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.3889</td> <td>    0.034</td> <td>   11.311</td> <td> 0.000</td> <td>    0.321</td> <td>    0.456</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.4891</td> <td>    0.037</td> <td>   13.197</td> <td> 0.000</td> <td>    0.416</td> <td>    0.562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.6074</td> <td>    0.047</td> <td>   13.027</td> <td> 0.000</td> <td>    0.516</td> <td>    0.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.6878</td> <td>    0.058</td> <td>   11.882</td> <td> 0.000</td> <td>    0.574</td> <td>    0.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.2411</td> <td>    0.024</td> <td>  -10.023</td> <td> 0.000</td> <td>   -0.288</td> <td>   -0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.1404</td> <td>    0.018</td> <td>   -7.597</td> <td> 0.000</td> <td>   -0.177</td> <td>   -0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.0916</td> <td>    0.015</td> <td>   -6.021</td> <td> 0.000</td> <td>   -0.121</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.0919</td> <td>    0.031</td> <td>    2.939</td> <td> 0.003</td> <td>    0.031</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.0808</td> <td>    0.043</td> <td>   -1.897</td> <td> 0.058</td> <td>   -0.164</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>    0.0194</td> <td>    0.014</td> <td>    1.373</td> <td> 0.170</td> <td>   -0.008</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.4178</td> <td>    0.147</td> <td>   -2.850</td> <td> 0.004</td> <td>   -0.705</td> <td>   -0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.3248</td> <td>    0.147</td> <td>   -2.213</td> <td> 0.027</td> <td>   -0.613</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.1857</td> <td>    0.153</td> <td>   -1.214</td> <td> 0.225</td> <td>   -0.486</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.2402</td> <td>    0.108</td> <td>   -2.214</td> <td> 0.027</td> <td>   -0.453</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.1823</td> <td>    0.110</td> <td>   -1.665</td> <td> 0.096</td> <td>   -0.397</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.3430</td> <td>    0.076</td> <td>   -4.502</td> <td> 0.000</td> <td>   -0.492</td> <td>   -0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.1197</td> <td>    0.031</td> <td>   -3.838</td> <td> 0.000</td> <td>   -0.181</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.1181</td> <td>    0.028</td> <td>   -4.193</td> <td> 0.000</td> <td>   -0.173</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.1734</td> <td>    0.075</td> <td>   -2.306</td> <td> 0.021</td> <td>   -0.321</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>   -0.1648</td> <td>    0.075</td> <td>   -2.207</td> <td> 0.028</td> <td>   -0.311</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.1653</td> <td>    0.074</td> <td>   -2.220</td> <td> 0.027</td> <td>   -0.311</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -0.2051</td> <td>    0.075</td> <td>   -2.733</td> <td> 0.006</td> <td>   -0.352</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>   -0.2984</td> <td>    0.081</td> <td>   -3.695</td> <td> 0.000</td> <td>   -0.457</td> <td>   -0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>   -0.3127</td> <td>    0.093</td> <td>   -3.363</td> <td> 0.001</td> <td>   -0.495</td> <td>   -0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>    0.1288</td> <td>    0.023</td> <td>    5.690</td> <td> 0.000</td> <td>    0.084</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>   -0.0459</td> <td>    0.026</td> <td>   -1.770</td> <td> 0.077</td> <td>   -0.097</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>    0.0607</td> <td>    0.012</td> <td>    5.274</td> <td> 0.000</td> <td>    0.038</td> <td>    0.083</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>253.380</td> <th>  Durbin-Watson:     </th> <td>   1.946</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 896.875</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.826</td>  <th>  Prob(JB):          </th> <td>1.76e-195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.469</td>  <th>  Cond. No.          </th> <td>    664.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.879\n",
       "Model:                            OLS   Adj. R-squared:                  0.874\n",
       "Method:                 Least Squares   F-statistic:                     191.8\n",
       "Date:                Sat, 11 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        00:12:33   Log-Likelihood:                 806.17\n",
       "No. Observations:                1458   AIC:                            -1504.\n",
       "Df Residuals:                    1404   BIC:                            -1219.\n",
       "Df Model:                          53                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.2137      0.260     35.468      0.000       8.704       9.723\n",
       "x1             0.4499      0.022     20.852      0.000       0.408       0.492\n",
       "x2             0.1856      0.040      4.583      0.000       0.106       0.265\n",
       "x3            -0.0716      0.038     -1.872      0.061      -0.147       0.003\n",
       "x4             0.1137      0.023      4.970      0.000       0.069       0.159\n",
       "x5             0.3089      0.030     10.135      0.000       0.249       0.369\n",
       "x6             0.2291      0.020     11.361      0.000       0.190       0.269\n",
       "x7             0.2744      0.024     11.309      0.000       0.227       0.322\n",
       "x8             0.0780      0.019      4.006      0.000       0.040       0.116\n",
       "x9             0.2160      0.023      9.492      0.000       0.171       0.261\n",
       "x10           -0.0494      0.027     -1.814      0.070      -0.103       0.004\n",
       "x11            0.1879      0.025      7.621      0.000       0.140       0.236\n",
       "x12            0.1686      0.016     10.370      0.000       0.137       0.201\n",
       "x13            0.1383      0.051      2.732      0.006       0.039       0.238\n",
       "x14            0.2005      0.023      8.869      0.000       0.156       0.245\n",
       "x15            0.3060      0.030     10.251      0.000       0.247       0.365\n",
       "x16            0.2711      0.026     10.243      0.000       0.219       0.323\n",
       "x17            0.0828      0.032      2.584      0.010       0.020       0.146\n",
       "x18            0.1663      0.022      7.683      0.000       0.124       0.209\n",
       "x19            0.1737      0.024      7.253      0.000       0.127       0.221\n",
       "x20            0.2348      0.024      9.899      0.000       0.188       0.281\n",
       "x21            0.2863      0.035      8.178      0.000       0.218       0.355\n",
       "x22            0.2484      0.029      8.662      0.000       0.192       0.305\n",
       "x23            0.3172      0.046      6.825      0.000       0.226       0.408\n",
       "x24            0.1865      0.033      5.693      0.000       0.122       0.251\n",
       "x25            0.2604      0.032      8.094      0.000       0.197       0.324\n",
       "x26            0.3220      0.033      9.849      0.000       0.258       0.386\n",
       "x27            0.3889      0.034     11.311      0.000       0.321       0.456\n",
       "x28            0.4891      0.037     13.197      0.000       0.416       0.562\n",
       "x29            0.6074      0.047     13.027      0.000       0.516       0.699\n",
       "x30            0.6878      0.058     11.882      0.000       0.574       0.801\n",
       "x31           -0.2411      0.024    -10.023      0.000      -0.288      -0.194\n",
       "x32           -0.1404      0.018     -7.597      0.000      -0.177      -0.104\n",
       "x33           -0.0916      0.015     -6.021      0.000      -0.121      -0.062\n",
       "x34            0.0919      0.031      2.939      0.003       0.031       0.153\n",
       "x35           -0.0808      0.043     -1.897      0.058      -0.164       0.003\n",
       "x36            0.0194      0.014      1.373      0.170      -0.008       0.047\n",
       "x37           -0.4178      0.147     -2.850      0.004      -0.705      -0.130\n",
       "x38           -0.3248      0.147     -2.213      0.027      -0.613      -0.037\n",
       "x39           -0.1857      0.153     -1.214      0.225      -0.486       0.114\n",
       "x40           -0.2402      0.108     -2.214      0.027      -0.453      -0.027\n",
       "x41           -0.1823      0.110     -1.665      0.096      -0.397       0.032\n",
       "x42           -0.3430      0.076     -4.502      0.000      -0.492      -0.194\n",
       "x43           -0.1197      0.031     -3.838      0.000      -0.181      -0.058\n",
       "x44           -0.1181      0.028     -4.193      0.000      -0.173      -0.063\n",
       "x45           -0.1734      0.075     -2.306      0.021      -0.321      -0.026\n",
       "x46           -0.1648      0.075     -2.207      0.028      -0.311      -0.018\n",
       "x47           -0.1653      0.074     -2.220      0.027      -0.311      -0.019\n",
       "x48           -0.2051      0.075     -2.733      0.006      -0.352      -0.058\n",
       "x49           -0.2984      0.081     -3.695      0.000      -0.457      -0.140\n",
       "x50           -0.3127      0.093     -3.363      0.001      -0.495      -0.130\n",
       "x51            0.1288      0.023      5.690      0.000       0.084       0.173\n",
       "x52           -0.0459      0.026     -1.770      0.077      -0.097       0.005\n",
       "x53            0.0607      0.012      5.274      0.000       0.038       0.083\n",
       "==============================================================================\n",
       "Omnibus:                      253.380   Durbin-Watson:                   1.946\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              896.875\n",
       "Skew:                          -0.826   Prob(JB):                    1.76e-195\n",
       "Kurtosis:                       6.469   Cond. No.                         664.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables for the multiple linear regression\n",
    "X_9 = data_encoded[[\"GrLivArea\",\"Neighborhood_Blmngtn\",\"Neighborhood_BrDale\",\"Neighborhood_BrkSide\",\"Neighborhood_ClearCr\",\"Neighborhood_CollgCr\",\"Neighborhood_Crawfor\",\"Neighborhood_Edwards\",\"Neighborhood_Gilbert\",\"Neighborhood_IDOTRR\",\"Neighborhood_Mitchel\",\"Neighborhood_NAmes\",\"Neighborhood_NPkVill\",\"Neighborhood_NWAmes\",\"Neighborhood_NoRidge\",\"Neighborhood_NridgHt\",\"Neighborhood_SWISU\",\"Neighborhood_Sawyer\",\"Neighborhood_SawyerW\",\"Neighborhood_Somerst\",\"Neighborhood_StoneBr\",\"Neighborhood_Timber\",\"Neighborhood_Veenker\",\"OverallQual_4\",\"OverallQual_5\",\"OverallQual_6\",\"OverallQual_7\",\"OverallQual_8\",\"OverallQual_9\",\"OverallQual_10\",\"GarageCars_0\",\"GarageCars_1\",\"GarageCars_2\",\"ExterQual_Ex\",\"ExterQual_Fa\",\"ExterQual_Gd\",\"BsmtFullBath_0\",\"BsmtFullBath_1\",\"BsmtFullBath_2\",\"BsmtHalfBath_0\",\"BsmtHalfBath_1\",\"FullBath_0\",\"FullBath_1\",\"FullBath_2\",\"BedroomAbvGr_1\",\"BedroomAbvGr_2\",\"BedroomAbvGr_3\",\"BedroomAbvGr_4\",\"BedroomAbvGr_5\",\"BedroomAbvGr_6\",\"KitchenQual_Ex\",\"KitchenQual_Fa\",\"KitchenQual_Gd\"]]\n",
    "# Ignores these variables to avoid the dummy variable trap: \"Neighborhood_Blueste\",\"OverallQual_1\", \"GarageCars_4\",\"ExterQual_TA\", \"BsmtFullBath_3\",\"BsmtHalfBath_2\",\"HalfBath_2\",\"FullBath_3\",\"BedroomAbvGr_8\",\"KitchenQual_TA\"\n",
    "# Removing these variables because they're not statistically significant: \"OverallQual_3\",\"Neighborhood_MeadowV\", \"GarageCars_3\",\"OverallQual_2\",\"BedroomAbvGr_0\",\"HalfBath_0\",\"HalfBath_1\",\n",
    "# Redefine X\n",
    "X = X_9.values\n",
    "# Split data into training and testing set\n",
    "# random_state ensures answers are reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2, random_state = 0)\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "regressor = LinearRegression()\n",
    "# fitting linear regressor to our training dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Build the optimal model using backward elimination\n",
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "# X_opt = X[:, [0,1]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   195.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:14:44</td>     <th>  Log-Likelihood:    </th> <td>  805.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1458</td>      <th>  AIC:               </th> <td>  -1505.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1405</td>      <th>  BIC:               </th> <td>  -1225.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    52</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.0580</td> <td>    0.226</td> <td>   40.089</td> <td> 0.000</td> <td>    8.615</td> <td>    9.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4485</td> <td>    0.022</td> <td>   20.814</td> <td> 0.000</td> <td>    0.406</td> <td>    0.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1857</td> <td>    0.040</td> <td>    4.585</td> <td> 0.000</td> <td>    0.106</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0719</td> <td>    0.038</td> <td>   -1.880</td> <td> 0.060</td> <td>   -0.147</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1134</td> <td>    0.023</td> <td>    4.954</td> <td> 0.000</td> <td>    0.068</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3081</td> <td>    0.030</td> <td>   10.109</td> <td> 0.000</td> <td>    0.248</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2286</td> <td>    0.020</td> <td>   11.338</td> <td> 0.000</td> <td>    0.189</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2745</td> <td>    0.024</td> <td>   11.309</td> <td> 0.000</td> <td>    0.227</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0790</td> <td>    0.019</td> <td>    4.061</td> <td> 0.000</td> <td>    0.041</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2157</td> <td>    0.023</td> <td>    9.475</td> <td> 0.000</td> <td>    0.171</td> <td>    0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0493</td> <td>    0.027</td> <td>   -1.811</td> <td> 0.070</td> <td>   -0.103</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1869</td> <td>    0.025</td> <td>    7.581</td> <td> 0.000</td> <td>    0.139</td> <td>    0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1686</td> <td>    0.016</td> <td>   10.367</td> <td> 0.000</td> <td>    0.137</td> <td>    0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.1376</td> <td>    0.051</td> <td>    2.718</td> <td> 0.007</td> <td>    0.038</td> <td>    0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.2001</td> <td>    0.023</td> <td>    8.851</td> <td> 0.000</td> <td>    0.156</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.3060</td> <td>    0.030</td> <td>   10.247</td> <td> 0.000</td> <td>    0.247</td> <td>    0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.2708</td> <td>    0.026</td> <td>   10.230</td> <td> 0.000</td> <td>    0.219</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0828</td> <td>    0.032</td> <td>    2.583</td> <td> 0.010</td> <td>    0.020</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.1661</td> <td>    0.022</td> <td>    7.673</td> <td> 0.000</td> <td>    0.124</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.1732</td> <td>    0.024</td> <td>    7.232</td> <td> 0.000</td> <td>    0.126</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.2343</td> <td>    0.024</td> <td>    9.878</td> <td> 0.000</td> <td>    0.188</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2859</td> <td>    0.035</td> <td>    8.163</td> <td> 0.000</td> <td>    0.217</td> <td>    0.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.2474</td> <td>    0.029</td> <td>    8.630</td> <td> 0.000</td> <td>    0.191</td> <td>    0.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.3151</td> <td>    0.046</td> <td>    6.785</td> <td> 0.000</td> <td>    0.224</td> <td>    0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.1865</td> <td>    0.033</td> <td>    5.689</td> <td> 0.000</td> <td>    0.122</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.2611</td> <td>    0.032</td> <td>    8.115</td> <td> 0.000</td> <td>    0.198</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.3226</td> <td>    0.033</td> <td>    9.868</td> <td> 0.000</td> <td>    0.258</td> <td>    0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.3894</td> <td>    0.034</td> <td>   11.324</td> <td> 0.000</td> <td>    0.322</td> <td>    0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.4896</td> <td>    0.037</td> <td>   13.211</td> <td> 0.000</td> <td>    0.417</td> <td>    0.562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.6076</td> <td>    0.047</td> <td>   13.029</td> <td> 0.000</td> <td>    0.516</td> <td>    0.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.6869</td> <td>    0.058</td> <td>   11.866</td> <td> 0.000</td> <td>    0.573</td> <td>    0.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.2392</td> <td>    0.024</td> <td>   -9.964</td> <td> 0.000</td> <td>   -0.286</td> <td>   -0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.1402</td> <td>    0.018</td> <td>   -7.584</td> <td> 0.000</td> <td>   -0.176</td> <td>   -0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.0915</td> <td>    0.015</td> <td>   -6.017</td> <td> 0.000</td> <td>   -0.121</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.0920</td> <td>    0.031</td> <td>    2.943</td> <td> 0.003</td> <td>    0.031</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.0803</td> <td>    0.043</td> <td>   -1.884</td> <td> 0.060</td> <td>   -0.164</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>    0.0198</td> <td>    0.014</td> <td>    1.404</td> <td> 0.161</td> <td>   -0.008</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.2477</td> <td>    0.043</td> <td>   -5.715</td> <td> 0.000</td> <td>   -0.333</td> <td>   -0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.1545</td> <td>    0.043</td> <td>   -3.580</td> <td> 0.000</td> <td>   -0.239</td> <td>   -0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.2422</td> <td>    0.108</td> <td>   -2.232</td> <td> 0.026</td> <td>   -0.455</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.1840</td> <td>    0.110</td> <td>   -1.681</td> <td> 0.093</td> <td>   -0.399</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.3569</td> <td>    0.075</td> <td>   -4.737</td> <td> 0.000</td> <td>   -0.505</td> <td>   -0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.1271</td> <td>    0.031</td> <td>   -4.160</td> <td> 0.000</td> <td>   -0.187</td> <td>   -0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.1246</td> <td>    0.028</td> <td>   -4.509</td> <td> 0.000</td> <td>   -0.179</td> <td>   -0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.1702</td> <td>    0.075</td> <td>   -2.264</td> <td> 0.024</td> <td>   -0.318</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.1613</td> <td>    0.075</td> <td>   -2.162</td> <td> 0.031</td> <td>   -0.308</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>   -0.1615</td> <td>    0.074</td> <td>   -2.170</td> <td> 0.030</td> <td>   -0.307</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.2022</td> <td>    0.075</td> <td>   -2.695</td> <td> 0.007</td> <td>   -0.349</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -0.2957</td> <td>    0.081</td> <td>   -3.662</td> <td> 0.000</td> <td>   -0.454</td> <td>   -0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>   -0.3098</td> <td>    0.093</td> <td>   -3.332</td> <td> 0.001</td> <td>   -0.492</td> <td>   -0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>    0.1286</td> <td>    0.023</td> <td>    5.680</td> <td> 0.000</td> <td>    0.084</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>   -0.0462</td> <td>    0.026</td> <td>   -1.780</td> <td> 0.075</td> <td>   -0.097</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>    0.0604</td> <td>    0.012</td> <td>    5.245</td> <td> 0.000</td> <td>    0.038</td> <td>    0.083</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>254.345</td> <th>  Durbin-Watson:     </th> <td>   1.948</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 898.708</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.830</td>  <th>  Prob(JB):          </th> <td>7.05e-196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.470</td>  <th>  Cond. No.          </th> <td>    545.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.879\n",
       "Model:                            OLS   Adj. R-squared:                  0.874\n",
       "Method:                 Least Squares   F-statistic:                     195.4\n",
       "Date:                Sat, 11 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        00:14:44   Log-Likelihood:                 805.40\n",
       "No. Observations:                1458   AIC:                            -1505.\n",
       "Df Residuals:                    1405   BIC:                            -1225.\n",
       "Df Model:                          52                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.0580      0.226     40.089      0.000       8.615       9.501\n",
       "x1             0.4485      0.022     20.814      0.000       0.406       0.491\n",
       "x2             0.1857      0.040      4.585      0.000       0.106       0.265\n",
       "x3            -0.0719      0.038     -1.880      0.060      -0.147       0.003\n",
       "x4             0.1134      0.023      4.954      0.000       0.068       0.158\n",
       "x5             0.3081      0.030     10.109      0.000       0.248       0.368\n",
       "x6             0.2286      0.020     11.338      0.000       0.189       0.268\n",
       "x7             0.2745      0.024     11.309      0.000       0.227       0.322\n",
       "x8             0.0790      0.019      4.061      0.000       0.041       0.117\n",
       "x9             0.2157      0.023      9.475      0.000       0.171       0.260\n",
       "x10           -0.0493      0.027     -1.811      0.070      -0.103       0.004\n",
       "x11            0.1869      0.025      7.581      0.000       0.139       0.235\n",
       "x12            0.1686      0.016     10.367      0.000       0.137       0.200\n",
       "x13            0.1376      0.051      2.718      0.007       0.038       0.237\n",
       "x14            0.2001      0.023      8.851      0.000       0.156       0.244\n",
       "x15            0.3060      0.030     10.247      0.000       0.247       0.365\n",
       "x16            0.2708      0.026     10.230      0.000       0.219       0.323\n",
       "x17            0.0828      0.032      2.583      0.010       0.020       0.146\n",
       "x18            0.1661      0.022      7.673      0.000       0.124       0.209\n",
       "x19            0.1732      0.024      7.232      0.000       0.126       0.220\n",
       "x20            0.2343      0.024      9.878      0.000       0.188       0.281\n",
       "x21            0.2859      0.035      8.163      0.000       0.217       0.355\n",
       "x22            0.2474      0.029      8.630      0.000       0.191       0.304\n",
       "x23            0.3151      0.046      6.785      0.000       0.224       0.406\n",
       "x24            0.1865      0.033      5.689      0.000       0.122       0.251\n",
       "x25            0.2611      0.032      8.115      0.000       0.198       0.324\n",
       "x26            0.3226      0.033      9.868      0.000       0.258       0.387\n",
       "x27            0.3894      0.034     11.324      0.000       0.322       0.457\n",
       "x28            0.4896      0.037     13.211      0.000       0.417       0.562\n",
       "x29            0.6076      0.047     13.029      0.000       0.516       0.699\n",
       "x30            0.6869      0.058     11.866      0.000       0.573       0.801\n",
       "x31           -0.2392      0.024     -9.964      0.000      -0.286      -0.192\n",
       "x32           -0.1402      0.018     -7.584      0.000      -0.176      -0.104\n",
       "x33           -0.0915      0.015     -6.017      0.000      -0.121      -0.062\n",
       "x34            0.0920      0.031      2.943      0.003       0.031       0.153\n",
       "x35           -0.0803      0.043     -1.884      0.060      -0.164       0.003\n",
       "x36            0.0198      0.014      1.404      0.161      -0.008       0.048\n",
       "x37           -0.2477      0.043     -5.715      0.000      -0.333      -0.163\n",
       "x38           -0.1545      0.043     -3.580      0.000      -0.239      -0.070\n",
       "x39           -0.2422      0.108     -2.232      0.026      -0.455      -0.029\n",
       "x40           -0.1840      0.110     -1.681      0.093      -0.399       0.031\n",
       "x41           -0.3569      0.075     -4.737      0.000      -0.505      -0.209\n",
       "x42           -0.1271      0.031     -4.160      0.000      -0.187      -0.067\n",
       "x43           -0.1246      0.028     -4.509      0.000      -0.179      -0.070\n",
       "x44           -0.1702      0.075     -2.264      0.024      -0.318      -0.023\n",
       "x45           -0.1613      0.075     -2.162      0.031      -0.308      -0.015\n",
       "x46           -0.1615      0.074     -2.170      0.030      -0.307      -0.016\n",
       "x47           -0.2022      0.075     -2.695      0.007      -0.349      -0.055\n",
       "x48           -0.2957      0.081     -3.662      0.000      -0.454      -0.137\n",
       "x49           -0.3098      0.093     -3.332      0.001      -0.492      -0.127\n",
       "x50            0.1286      0.023      5.680      0.000       0.084       0.173\n",
       "x51           -0.0462      0.026     -1.780      0.075      -0.097       0.005\n",
       "x52            0.0604      0.012      5.245      0.000       0.038       0.083\n",
       "==============================================================================\n",
       "Omnibus:                      254.345   Durbin-Watson:                   1.948\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              898.708\n",
       "Skew:                          -0.830   Prob(JB):                    7.05e-196\n",
       "Kurtosis:                       6.470   Cond. No.                         545.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables for the multiple linear regression\n",
    "X_10 = data_encoded[[\"GrLivArea\",\"Neighborhood_Blmngtn\",\"Neighborhood_BrDale\",\"Neighborhood_BrkSide\",\"Neighborhood_ClearCr\",\"Neighborhood_CollgCr\",\"Neighborhood_Crawfor\",\"Neighborhood_Edwards\",\"Neighborhood_Gilbert\",\"Neighborhood_IDOTRR\",\"Neighborhood_Mitchel\",\"Neighborhood_NAmes\",\"Neighborhood_NPkVill\",\"Neighborhood_NWAmes\",\"Neighborhood_NoRidge\",\"Neighborhood_NridgHt\",\"Neighborhood_SWISU\",\"Neighborhood_Sawyer\",\"Neighborhood_SawyerW\",\"Neighborhood_Somerst\",\"Neighborhood_StoneBr\",\"Neighborhood_Timber\",\"Neighborhood_Veenker\",\"OverallQual_4\",\"OverallQual_5\",\"OverallQual_6\",\"OverallQual_7\",\"OverallQual_8\",\"OverallQual_9\",\"OverallQual_10\",\"GarageCars_0\",\"GarageCars_1\",\"GarageCars_2\",\"ExterQual_Ex\",\"ExterQual_Fa\",\"ExterQual_Gd\",\"BsmtFullBath_0\",\"BsmtFullBath_1\",\"BsmtHalfBath_0\",\"BsmtHalfBath_1\",\"FullBath_0\",\"FullBath_1\",\"FullBath_2\",\"BedroomAbvGr_1\",\"BedroomAbvGr_2\",\"BedroomAbvGr_3\",\"BedroomAbvGr_4\",\"BedroomAbvGr_5\",\"BedroomAbvGr_6\",\"KitchenQual_Ex\",\"KitchenQual_Fa\",\"KitchenQual_Gd\"]]\n",
    "# Ignores these variables to avoid the dummy variable trap: \"Neighborhood_Blueste\",\"OverallQual_1\", \"GarageCars_4\",\"ExterQual_TA\", \"BsmtFullBath_3\",\"BsmtHalfBath_2\",\"HalfBath_2\",\"FullBath_3\",\"BedroomAbvGr_8\",\"KitchenQual_TA\"\n",
    "# Removing these variables because they're not statistically significant: \"OverallQual_3\",\"Neighborhood_MeadowV\", \"GarageCars_3\",\"OverallQual_2\",\"BedroomAbvGr_0\",\"HalfBath_0\",\"HalfBath_1\",\"BsmtFullBath_2\",\n",
    "# Redefine X\n",
    "X = X_10.values\n",
    "# Split data into training and testing set\n",
    "# random_state ensures answers are reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2, random_state = 0)\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "regressor = LinearRegression()\n",
    "# fitting linear regressor to our training dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Build the optimal model using backward elimination\n",
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "# X_opt = X[:, [0,1]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   199.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:17:18</td>     <th>  Log-Likelihood:    </th> <td>  804.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1458</td>      <th>  AIC:               </th> <td>  -1505.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1406</td>      <th>  BIC:               </th> <td>  -1230.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    51</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.0515</td> <td>    0.226</td> <td>   40.055</td> <td> 0.000</td> <td>    8.608</td> <td>    9.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4495</td> <td>    0.022</td> <td>   20.860</td> <td> 0.000</td> <td>    0.407</td> <td>    0.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1937</td> <td>    0.040</td> <td>    4.831</td> <td> 0.000</td> <td>    0.115</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0715</td> <td>    0.038</td> <td>   -1.869</td> <td> 0.062</td> <td>   -0.147</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1147</td> <td>    0.023</td> <td>    5.016</td> <td> 0.000</td> <td>    0.070</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3087</td> <td>    0.030</td> <td>   10.128</td> <td> 0.000</td> <td>    0.249</td> <td>    0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2351</td> <td>    0.020</td> <td>   11.964</td> <td> 0.000</td> <td>    0.197</td> <td>    0.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2755</td> <td>    0.024</td> <td>   11.353</td> <td> 0.000</td> <td>    0.228</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0805</td> <td>    0.019</td> <td>    4.142</td> <td> 0.000</td> <td>    0.042</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2201</td> <td>    0.023</td> <td>    9.761</td> <td> 0.000</td> <td>    0.176</td> <td>    0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0485</td> <td>    0.027</td> <td>   -1.782</td> <td> 0.075</td> <td>   -0.102</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1876</td> <td>    0.025</td> <td>    7.610</td> <td> 0.000</td> <td>    0.139</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1694</td> <td>    0.016</td> <td>   10.424</td> <td> 0.000</td> <td>    0.138</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.1362</td> <td>    0.051</td> <td>    2.689</td> <td> 0.007</td> <td>    0.037</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.1992</td> <td>    0.023</td> <td>    8.812</td> <td> 0.000</td> <td>    0.155</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.3135</td> <td>    0.029</td> <td>   10.669</td> <td> 0.000</td> <td>    0.256</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.2775</td> <td>    0.026</td> <td>   10.653</td> <td> 0.000</td> <td>    0.226</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0825</td> <td>    0.032</td> <td>    2.575</td> <td> 0.010</td> <td>    0.020</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.1670</td> <td>    0.022</td> <td>    7.719</td> <td> 0.000</td> <td>    0.125</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.1780</td> <td>    0.024</td> <td>    7.506</td> <td> 0.000</td> <td>    0.131</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.2416</td> <td>    0.023</td> <td>   10.432</td> <td> 0.000</td> <td>    0.196</td> <td>    0.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2926</td> <td>    0.035</td> <td>    8.429</td> <td> 0.000</td> <td>    0.224</td> <td>    0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.2515</td> <td>    0.029</td> <td>    8.813</td> <td> 0.000</td> <td>    0.195</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.3231</td> <td>    0.046</td> <td>    7.006</td> <td> 0.000</td> <td>    0.233</td> <td>    0.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.1847</td> <td>    0.033</td> <td>    5.637</td> <td> 0.000</td> <td>    0.120</td> <td>    0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.2592</td> <td>    0.032</td> <td>    8.060</td> <td> 0.000</td> <td>    0.196</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.3217</td> <td>    0.033</td> <td>    9.839</td> <td> 0.000</td> <td>    0.258</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.3925</td> <td>    0.034</td> <td>   11.436</td> <td> 0.000</td> <td>    0.325</td> <td>    0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.4953</td> <td>    0.037</td> <td>   13.441</td> <td> 0.000</td> <td>    0.423</td> <td>    0.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.6116</td> <td>    0.047</td> <td>   13.133</td> <td> 0.000</td> <td>    0.520</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.6912</td> <td>    0.058</td> <td>   11.951</td> <td> 0.000</td> <td>    0.578</td> <td>    0.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.2397</td> <td>    0.024</td> <td>   -9.983</td> <td> 0.000</td> <td>   -0.287</td> <td>   -0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.1404</td> <td>    0.018</td> <td>   -7.594</td> <td> 0.000</td> <td>   -0.177</td> <td>   -0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.0915</td> <td>    0.015</td> <td>   -6.016</td> <td> 0.000</td> <td>   -0.121</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.0753</td> <td>    0.029</td> <td>    2.604</td> <td> 0.009</td> <td>    0.019</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.0815</td> <td>    0.043</td> <td>   -1.912</td> <td> 0.056</td> <td>   -0.165</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.2450</td> <td>    0.043</td> <td>   -5.656</td> <td> 0.000</td> <td>   -0.330</td> <td>   -0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.1516</td> <td>    0.043</td> <td>   -3.516</td> <td> 0.000</td> <td>   -0.236</td> <td>   -0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.2423</td> <td>    0.109</td> <td>   -2.232</td> <td> 0.026</td> <td>   -0.455</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.1841</td> <td>    0.110</td> <td>   -1.681</td> <td> 0.093</td> <td>   -0.399</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.3553</td> <td>    0.075</td> <td>   -4.715</td> <td> 0.000</td> <td>   -0.503</td> <td>   -0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.1260</td> <td>    0.031</td> <td>   -4.123</td> <td> 0.000</td> <td>   -0.186</td> <td>   -0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.1222</td> <td>    0.028</td> <td>   -4.430</td> <td> 0.000</td> <td>   -0.176</td> <td>   -0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.1716</td> <td>    0.075</td> <td>   -2.282</td> <td> 0.023</td> <td>   -0.319</td> <td>   -0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.1643</td> <td>    0.075</td> <td>   -2.201</td> <td> 0.028</td> <td>   -0.311</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.1651</td> <td>    0.074</td> <td>   -2.220</td> <td> 0.027</td> <td>   -0.311</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>   -0.2058</td> <td>    0.075</td> <td>   -2.743</td> <td> 0.006</td> <td>   -0.353</td> <td>   -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.2996</td> <td>    0.081</td> <td>   -3.711</td> <td> 0.000</td> <td>   -0.458</td> <td>   -0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -0.3145</td> <td>    0.093</td> <td>   -3.384</td> <td> 0.001</td> <td>   -0.497</td> <td>   -0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>    0.1338</td> <td>    0.022</td> <td>    5.989</td> <td> 0.000</td> <td>    0.090</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>   -0.0465</td> <td>    0.026</td> <td>   -1.789</td> <td> 0.074</td> <td>   -0.097</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>    0.0661</td> <td>    0.011</td> <td>    6.130</td> <td> 0.000</td> <td>    0.045</td> <td>    0.087</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>254.550</td> <th>  Durbin-Watson:     </th> <td>   1.947</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 908.313</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.828</td>  <th>  Prob(JB):          </th> <td>5.79e-198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.495</td>  <th>  Cond. No.          </th> <td>    544.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.878\n",
       "Model:                            OLS   Adj. R-squared:                  0.874\n",
       "Method:                 Least Squares   F-statistic:                     199.0\n",
       "Date:                Sat, 11 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        00:17:18   Log-Likelihood:                 804.38\n",
       "No. Observations:                1458   AIC:                            -1505.\n",
       "Df Residuals:                    1406   BIC:                            -1230.\n",
       "Df Model:                          51                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.0515      0.226     40.055      0.000       8.608       9.495\n",
       "x1             0.4495      0.022     20.860      0.000       0.407       0.492\n",
       "x2             0.1937      0.040      4.831      0.000       0.115       0.272\n",
       "x3            -0.0715      0.038     -1.869      0.062      -0.147       0.004\n",
       "x4             0.1147      0.023      5.016      0.000       0.070       0.160\n",
       "x5             0.3087      0.030     10.128      0.000       0.249       0.369\n",
       "x6             0.2351      0.020     11.964      0.000       0.197       0.274\n",
       "x7             0.2755      0.024     11.353      0.000       0.228       0.323\n",
       "x8             0.0805      0.019      4.142      0.000       0.042       0.119\n",
       "x9             0.2201      0.023      9.761      0.000       0.176       0.264\n",
       "x10           -0.0485      0.027     -1.782      0.075      -0.102       0.005\n",
       "x11            0.1876      0.025      7.610      0.000       0.139       0.236\n",
       "x12            0.1694      0.016     10.424      0.000       0.138       0.201\n",
       "x13            0.1362      0.051      2.689      0.007       0.037       0.236\n",
       "x14            0.1992      0.023      8.812      0.000       0.155       0.244\n",
       "x15            0.3135      0.029     10.669      0.000       0.256       0.371\n",
       "x16            0.2775      0.026     10.653      0.000       0.226       0.329\n",
       "x17            0.0825      0.032      2.575      0.010       0.020       0.145\n",
       "x18            0.1670      0.022      7.719      0.000       0.125       0.209\n",
       "x19            0.1780      0.024      7.506      0.000       0.131       0.225\n",
       "x20            0.2416      0.023     10.432      0.000       0.196       0.287\n",
       "x21            0.2926      0.035      8.429      0.000       0.224       0.361\n",
       "x22            0.2515      0.029      8.813      0.000       0.195       0.307\n",
       "x23            0.3231      0.046      7.006      0.000       0.233       0.414\n",
       "x24            0.1847      0.033      5.637      0.000       0.120       0.249\n",
       "x25            0.2592      0.032      8.060      0.000       0.196       0.322\n",
       "x26            0.3217      0.033      9.839      0.000       0.258       0.386\n",
       "x27            0.3925      0.034     11.436      0.000       0.325       0.460\n",
       "x28            0.4953      0.037     13.441      0.000       0.423       0.568\n",
       "x29            0.6116      0.047     13.133      0.000       0.520       0.703\n",
       "x30            0.6912      0.058     11.951      0.000       0.578       0.805\n",
       "x31           -0.2397      0.024     -9.983      0.000      -0.287      -0.193\n",
       "x32           -0.1404      0.018     -7.594      0.000      -0.177      -0.104\n",
       "x33           -0.0915      0.015     -6.016      0.000      -0.121      -0.062\n",
       "x34            0.0753      0.029      2.604      0.009       0.019       0.132\n",
       "x35           -0.0815      0.043     -1.912      0.056      -0.165       0.002\n",
       "x36           -0.2450      0.043     -5.656      0.000      -0.330      -0.160\n",
       "x37           -0.1516      0.043     -3.516      0.000      -0.236      -0.067\n",
       "x38           -0.2423      0.109     -2.232      0.026      -0.455      -0.029\n",
       "x39           -0.1841      0.110     -1.681      0.093      -0.399       0.031\n",
       "x40           -0.3553      0.075     -4.715      0.000      -0.503      -0.208\n",
       "x41           -0.1260      0.031     -4.123      0.000      -0.186      -0.066\n",
       "x42           -0.1222      0.028     -4.430      0.000      -0.176      -0.068\n",
       "x43           -0.1716      0.075     -2.282      0.023      -0.319      -0.024\n",
       "x44           -0.1643      0.075     -2.201      0.028      -0.311      -0.018\n",
       "x45           -0.1651      0.074     -2.220      0.027      -0.311      -0.019\n",
       "x46           -0.2058      0.075     -2.743      0.006      -0.353      -0.059\n",
       "x47           -0.2996      0.081     -3.711      0.000      -0.458      -0.141\n",
       "x48           -0.3145      0.093     -3.384      0.001      -0.497      -0.132\n",
       "x49            0.1338      0.022      5.989      0.000       0.090       0.178\n",
       "x50           -0.0465      0.026     -1.789      0.074      -0.097       0.004\n",
       "x51            0.0661      0.011      6.130      0.000       0.045       0.087\n",
       "==============================================================================\n",
       "Omnibus:                      254.550   Durbin-Watson:                   1.947\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              908.313\n",
       "Skew:                          -0.828   Prob(JB):                    5.79e-198\n",
       "Kurtosis:                       6.495   Cond. No.                         544.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables for the multiple linear regression\n",
    "X_11 = data_encoded[[\"GrLivArea\",\"Neighborhood_Blmngtn\",\"Neighborhood_BrDale\",\"Neighborhood_BrkSide\",\"Neighborhood_ClearCr\",\"Neighborhood_CollgCr\",\"Neighborhood_Crawfor\",\"Neighborhood_Edwards\",\"Neighborhood_Gilbert\",\"Neighborhood_IDOTRR\",\"Neighborhood_Mitchel\",\"Neighborhood_NAmes\",\"Neighborhood_NPkVill\",\"Neighborhood_NWAmes\",\"Neighborhood_NoRidge\",\"Neighborhood_NridgHt\",\"Neighborhood_SWISU\",\"Neighborhood_Sawyer\",\"Neighborhood_SawyerW\",\"Neighborhood_Somerst\",\"Neighborhood_StoneBr\",\"Neighborhood_Timber\",\"Neighborhood_Veenker\",\"OverallQual_4\",\"OverallQual_5\",\"OverallQual_6\",\"OverallQual_7\",\"OverallQual_8\",\"OverallQual_9\",\"OverallQual_10\",\"GarageCars_0\",\"GarageCars_1\",\"GarageCars_2\",\"ExterQual_Ex\",\"ExterQual_Fa\",\"BsmtFullBath_0\",\"BsmtFullBath_1\",\"BsmtHalfBath_0\",\"BsmtHalfBath_1\",\"FullBath_0\",\"FullBath_1\",\"FullBath_2\",\"BedroomAbvGr_1\",\"BedroomAbvGr_2\",\"BedroomAbvGr_3\",\"BedroomAbvGr_4\",\"BedroomAbvGr_5\",\"BedroomAbvGr_6\",\"KitchenQual_Ex\",\"KitchenQual_Fa\",\"KitchenQual_Gd\"]]\n",
    "# Ignores these variables to avoid the dummy variable trap: \"Neighborhood_Blueste\",\"OverallQual_1\", \"GarageCars_4\",\"ExterQual_TA\", \"BsmtFullBath_3\",\"BsmtHalfBath_2\",\"HalfBath_2\",\"FullBath_3\",\"BedroomAbvGr_8\",\"KitchenQual_TA\"\n",
    "# Removing these variables because they're not statistically significant: \"OverallQual_3\",\"Neighborhood_MeadowV\", \"GarageCars_3\",\"OverallQual_2\",\"BedroomAbvGr_0\",\"HalfBath_0\",\"HalfBath_1\",\"BsmtFullBath_2\",\"ExterQual_Gd\",\n",
    "# Redefine X\n",
    "X = X_11.values\n",
    "# Split data into training and testing set\n",
    "# random_state ensures answers are reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2, random_state = 0)\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "regressor = LinearRegression()\n",
    "# fitting linear regressor to our training dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Build the optimal model using backward elimination\n",
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "# X_opt = X[:, [0,1]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   202.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:19:09</td>     <th>  Log-Likelihood:    </th> <td>  802.92</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1458</td>      <th>  AIC:               </th> <td>  -1504.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1407</td>      <th>  BIC:               </th> <td>  -1234.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    50</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    8.8458</td> <td>    0.190</td> <td>   46.534</td> <td> 0.000</td> <td>    8.473</td> <td>    9.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4485</td> <td>    0.022</td> <td>   20.810</td> <td> 0.000</td> <td>    0.406</td> <td>    0.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.2021</td> <td>    0.040</td> <td>    5.077</td> <td> 0.000</td> <td>    0.124</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0721</td> <td>    0.038</td> <td>   -1.882</td> <td> 0.060</td> <td>   -0.147</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1150</td> <td>    0.023</td> <td>    5.024</td> <td> 0.000</td> <td>    0.070</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3083</td> <td>    0.031</td> <td>   10.107</td> <td> 0.000</td> <td>    0.248</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2352</td> <td>    0.020</td> <td>   11.963</td> <td> 0.000</td> <td>    0.197</td> <td>    0.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2753</td> <td>    0.024</td> <td>   11.338</td> <td> 0.000</td> <td>    0.228</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0818</td> <td>    0.019</td> <td>    4.212</td> <td> 0.000</td> <td>    0.044</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2200</td> <td>    0.023</td> <td>    9.749</td> <td> 0.000</td> <td>    0.176</td> <td>    0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0492</td> <td>    0.027</td> <td>   -1.808</td> <td> 0.071</td> <td>   -0.103</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1874</td> <td>    0.025</td> <td>    7.597</td> <td> 0.000</td> <td>    0.139</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1692</td> <td>    0.016</td> <td>   10.404</td> <td> 0.000</td> <td>    0.137</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.1354</td> <td>    0.051</td> <td>    2.672</td> <td> 0.008</td> <td>    0.036</td> <td>    0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.1984</td> <td>    0.023</td> <td>    8.774</td> <td> 0.000</td> <td>    0.154</td> <td>    0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.3132</td> <td>    0.029</td> <td>   10.652</td> <td> 0.000</td> <td>    0.255</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.2777</td> <td>    0.026</td> <td>   10.652</td> <td> 0.000</td> <td>    0.227</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0833</td> <td>    0.032</td> <td>    2.596</td> <td> 0.010</td> <td>    0.020</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.1668</td> <td>    0.022</td> <td>    7.702</td> <td> 0.000</td> <td>    0.124</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.1773</td> <td>    0.024</td> <td>    7.473</td> <td> 0.000</td> <td>    0.131</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.2417</td> <td>    0.023</td> <td>   10.431</td> <td> 0.000</td> <td>    0.196</td> <td>    0.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2941</td> <td>    0.035</td> <td>    8.471</td> <td> 0.000</td> <td>    0.226</td> <td>    0.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.2516</td> <td>    0.029</td> <td>    8.811</td> <td> 0.000</td> <td>    0.196</td> <td>    0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.3233</td> <td>    0.046</td> <td>    7.006</td> <td> 0.000</td> <td>    0.233</td> <td>    0.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.1876</td> <td>    0.033</td> <td>    5.732</td> <td> 0.000</td> <td>    0.123</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.2625</td> <td>    0.032</td> <td>    8.174</td> <td> 0.000</td> <td>    0.199</td> <td>    0.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.3261</td> <td>    0.033</td> <td>    9.997</td> <td> 0.000</td> <td>    0.262</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.3968</td> <td>    0.034</td> <td>   11.583</td> <td> 0.000</td> <td>    0.330</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.4990</td> <td>    0.037</td> <td>   13.554</td> <td> 0.000</td> <td>    0.427</td> <td>    0.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.6147</td> <td>    0.047</td> <td>   13.201</td> <td> 0.000</td> <td>    0.523</td> <td>    0.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.6945</td> <td>    0.058</td> <td>   12.007</td> <td> 0.000</td> <td>    0.581</td> <td>    0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.2379</td> <td>    0.024</td> <td>   -9.911</td> <td> 0.000</td> <td>   -0.285</td> <td>   -0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.1416</td> <td>    0.018</td> <td>   -7.659</td> <td> 0.000</td> <td>   -0.178</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.0927</td> <td>    0.015</td> <td>   -6.093</td> <td> 0.000</td> <td>   -0.123</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.0751</td> <td>    0.029</td> <td>    2.594</td> <td> 0.010</td> <td>    0.018</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.0814</td> <td>    0.043</td> <td>   -1.909</td> <td> 0.056</td> <td>   -0.165</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.2390</td> <td>    0.043</td> <td>   -5.534</td> <td> 0.000</td> <td>   -0.324</td> <td>   -0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.1456</td> <td>    0.043</td> <td>   -3.387</td> <td> 0.001</td> <td>   -0.230</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.0621</td> <td>    0.017</td> <td>   -3.657</td> <td> 0.000</td> <td>   -0.095</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.3189</td> <td>    0.072</td> <td>   -4.416</td> <td> 0.000</td> <td>   -0.461</td> <td>   -0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.1255</td> <td>    0.031</td> <td>   -4.103</td> <td> 0.000</td> <td>   -0.185</td> <td>   -0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.1218</td> <td>    0.028</td> <td>   -4.410</td> <td> 0.000</td> <td>   -0.176</td> <td>   -0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.1507</td> <td>    0.074</td> <td>   -2.030</td> <td> 0.043</td> <td>   -0.296</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.1413</td> <td>    0.073</td> <td>   -1.925</td> <td> 0.054</td> <td>   -0.285</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.1422</td> <td>    0.073</td> <td>   -1.944</td> <td> 0.052</td> <td>   -0.286</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.1818</td> <td>    0.074</td> <td>   -2.467</td> <td> 0.014</td> <td>   -0.326</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>   -0.2765</td> <td>    0.080</td> <td>   -3.474</td> <td> 0.001</td> <td>   -0.433</td> <td>   -0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.2924</td> <td>    0.092</td> <td>   -3.176</td> <td> 0.002</td> <td>   -0.473</td> <td>   -0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>    0.1339</td> <td>    0.022</td> <td>    5.991</td> <td> 0.000</td> <td>    0.090</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>   -0.0472</td> <td>    0.026</td> <td>   -1.817</td> <td> 0.069</td> <td>   -0.098</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>    0.0659</td> <td>    0.011</td> <td>    6.106</td> <td> 0.000</td> <td>    0.045</td> <td>    0.087</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>253.816</td> <th>  Durbin-Watson:     </th> <td>   1.951</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 897.316</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.828</td>  <th>  Prob(JB):          </th> <td>1.41e-195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.468</td>  <th>  Cond. No.          </th> <td>    452.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.878\n",
       "Model:                            OLS   Adj. R-squared:                  0.874\n",
       "Method:                 Least Squares   F-statistic:                     202.7\n",
       "Date:                Sat, 11 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        00:19:09   Log-Likelihood:                 802.92\n",
       "No. Observations:                1458   AIC:                            -1504.\n",
       "Df Residuals:                    1407   BIC:                            -1234.\n",
       "Df Model:                          50                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          8.8458      0.190     46.534      0.000       8.473       9.219\n",
       "x1             0.4485      0.022     20.810      0.000       0.406       0.491\n",
       "x2             0.2021      0.040      5.077      0.000       0.124       0.280\n",
       "x3            -0.0721      0.038     -1.882      0.060      -0.147       0.003\n",
       "x4             0.1150      0.023      5.024      0.000       0.070       0.160\n",
       "x5             0.3083      0.031     10.107      0.000       0.248       0.368\n",
       "x6             0.2352      0.020     11.963      0.000       0.197       0.274\n",
       "x7             0.2753      0.024     11.338      0.000       0.228       0.323\n",
       "x8             0.0818      0.019      4.212      0.000       0.044       0.120\n",
       "x9             0.2200      0.023      9.749      0.000       0.176       0.264\n",
       "x10           -0.0492      0.027     -1.808      0.071      -0.103       0.004\n",
       "x11            0.1874      0.025      7.597      0.000       0.139       0.236\n",
       "x12            0.1692      0.016     10.404      0.000       0.137       0.201\n",
       "x13            0.1354      0.051      2.672      0.008       0.036       0.235\n",
       "x14            0.1984      0.023      8.774      0.000       0.154       0.243\n",
       "x15            0.3132      0.029     10.652      0.000       0.255       0.371\n",
       "x16            0.2777      0.026     10.652      0.000       0.227       0.329\n",
       "x17            0.0833      0.032      2.596      0.010       0.020       0.146\n",
       "x18            0.1668      0.022      7.702      0.000       0.124       0.209\n",
       "x19            0.1773      0.024      7.473      0.000       0.131       0.224\n",
       "x20            0.2417      0.023     10.431      0.000       0.196       0.287\n",
       "x21            0.2941      0.035      8.471      0.000       0.226       0.362\n",
       "x22            0.2516      0.029      8.811      0.000       0.196       0.308\n",
       "x23            0.3233      0.046      7.006      0.000       0.233       0.414\n",
       "x24            0.1876      0.033      5.732      0.000       0.123       0.252\n",
       "x25            0.2625      0.032      8.174      0.000       0.199       0.325\n",
       "x26            0.3261      0.033      9.997      0.000       0.262       0.390\n",
       "x27            0.3968      0.034     11.583      0.000       0.330       0.464\n",
       "x28            0.4990      0.037     13.554      0.000       0.427       0.571\n",
       "x29            0.6147      0.047     13.201      0.000       0.523       0.706\n",
       "x30            0.6945      0.058     12.007      0.000       0.581       0.808\n",
       "x31           -0.2379      0.024     -9.911      0.000      -0.285      -0.191\n",
       "x32           -0.1416      0.018     -7.659      0.000      -0.178      -0.105\n",
       "x33           -0.0927      0.015     -6.093      0.000      -0.123      -0.063\n",
       "x34            0.0751      0.029      2.594      0.010       0.018       0.132\n",
       "x35           -0.0814      0.043     -1.909      0.056      -0.165       0.002\n",
       "x36           -0.2390      0.043     -5.534      0.000      -0.324      -0.154\n",
       "x37           -0.1456      0.043     -3.387      0.001      -0.230      -0.061\n",
       "x38           -0.0621      0.017     -3.657      0.000      -0.095      -0.029\n",
       "x39           -0.3189      0.072     -4.416      0.000      -0.461      -0.177\n",
       "x40           -0.1255      0.031     -4.103      0.000      -0.185      -0.065\n",
       "x41           -0.1218      0.028     -4.410      0.000      -0.176      -0.068\n",
       "x42           -0.1507      0.074     -2.030      0.043      -0.296      -0.005\n",
       "x43           -0.1413      0.073     -1.925      0.054      -0.285       0.003\n",
       "x44           -0.1422      0.073     -1.944      0.052      -0.286       0.001\n",
       "x45           -0.1818      0.074     -2.467      0.014      -0.326      -0.037\n",
       "x46           -0.2765      0.080     -3.474      0.001      -0.433      -0.120\n",
       "x47           -0.2924      0.092     -3.176      0.002      -0.473      -0.112\n",
       "x48            0.1339      0.022      5.991      0.000       0.090       0.178\n",
       "x49           -0.0472      0.026     -1.817      0.069      -0.098       0.004\n",
       "x50            0.0659      0.011      6.106      0.000       0.045       0.087\n",
       "==============================================================================\n",
       "Omnibus:                      253.816   Durbin-Watson:                   1.951\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              897.316\n",
       "Skew:                          -0.828   Prob(JB):                    1.41e-195\n",
       "Kurtosis:                       6.468   Cond. No.                         452.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables for the multiple linear regression\n",
    "X_12 = data_encoded[[\"GrLivArea\",\"Neighborhood_Blmngtn\",\"Neighborhood_BrDale\",\"Neighborhood_BrkSide\",\"Neighborhood_ClearCr\",\"Neighborhood_CollgCr\",\"Neighborhood_Crawfor\",\"Neighborhood_Edwards\",\"Neighborhood_Gilbert\",\"Neighborhood_IDOTRR\",\"Neighborhood_Mitchel\",\"Neighborhood_NAmes\",\"Neighborhood_NPkVill\",\"Neighborhood_NWAmes\",\"Neighborhood_NoRidge\",\"Neighborhood_NridgHt\",\"Neighborhood_SWISU\",\"Neighborhood_Sawyer\",\"Neighborhood_SawyerW\",\"Neighborhood_Somerst\",\"Neighborhood_StoneBr\",\"Neighborhood_Timber\",\"Neighborhood_Veenker\",\"OverallQual_4\",\"OverallQual_5\",\"OverallQual_6\",\"OverallQual_7\",\"OverallQual_8\",\"OverallQual_9\",\"OverallQual_10\",\"GarageCars_0\",\"GarageCars_1\",\"GarageCars_2\",\"ExterQual_Ex\",\"ExterQual_Fa\",\"BsmtFullBath_0\",\"BsmtFullBath_1\",\"BsmtHalfBath_0\",\"FullBath_0\",\"FullBath_1\",\"FullBath_2\",\"BedroomAbvGr_1\",\"BedroomAbvGr_2\",\"BedroomAbvGr_3\",\"BedroomAbvGr_4\",\"BedroomAbvGr_5\",\"BedroomAbvGr_6\",\"KitchenQual_Ex\",\"KitchenQual_Fa\",\"KitchenQual_Gd\"]]\n",
    "# Ignores these variables to avoid the dummy variable trap: \"Neighborhood_Blueste\",\"OverallQual_1\", \"GarageCars_4\",\"ExterQual_TA\", \"BsmtFullBath_3\",\"BsmtHalfBath_2\",\"HalfBath_2\",\"FullBath_3\",\"BedroomAbvGr_8\",\"KitchenQual_TA\"\n",
    "# Removing these variables because they're not statistically significant: \"OverallQual_3\",\"Neighborhood_MeadowV\", \"GarageCars_3\",\"OverallQual_2\",\"BedroomAbvGr_0\",\"HalfBath_0\",\"HalfBath_1\",\"BsmtFullBath_2\",\"ExterQual_Gd\",\"BsmtHalfBath_1\"\n",
    "# Redefine X\n",
    "X = X_12.values\n",
    "# Split data into training and testing set\n",
    "# random_state ensures answers are reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2, random_state = 0)\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "regressor = LinearRegression()\n",
    "# fitting linear regressor to our training dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Build the optimal model using backward elimination\n",
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "# X_opt = X[:, [0,1]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   206.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:21:01</td>     <th>  Log-Likelihood:    </th> <td>  801.23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1458</td>      <th>  AIC:               </th> <td>  -1502.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1408</td>      <th>  BIC:               </th> <td>  -1238.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    49</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    8.8413</td> <td>    0.190</td> <td>   46.477</td> <td> 0.000</td> <td>    8.468</td> <td>    9.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4490</td> <td>    0.022</td> <td>   20.818</td> <td> 0.000</td> <td>    0.407</td> <td>    0.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.2107</td> <td>    0.040</td> <td>    5.328</td> <td> 0.000</td> <td>    0.133</td> <td>    0.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0614</td> <td>    0.038</td> <td>   -1.622</td> <td> 0.105</td> <td>   -0.136</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1264</td> <td>    0.022</td> <td>    5.746</td> <td> 0.000</td> <td>    0.083</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3168</td> <td>    0.030</td> <td>   10.503</td> <td> 0.000</td> <td>    0.258</td> <td>    0.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2442</td> <td>    0.019</td> <td>   12.828</td> <td> 0.000</td> <td>    0.207</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2851</td> <td>    0.024</td> <td>   12.032</td> <td> 0.000</td> <td>    0.239</td> <td>    0.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0924</td> <td>    0.019</td> <td>    4.986</td> <td> 0.000</td> <td>    0.056</td> <td>    0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2289</td> <td>    0.022</td> <td>   10.384</td> <td> 0.000</td> <td>    0.186</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.1966</td> <td>    0.024</td> <td>    8.137</td> <td> 0.000</td> <td>    0.149</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1792</td> <td>    0.015</td> <td>   11.697</td> <td> 0.000</td> <td>    0.149</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1445</td> <td>    0.050</td> <td>    2.862</td> <td> 0.004</td> <td>    0.045</td> <td>    0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.2071</td> <td>    0.022</td> <td>    9.367</td> <td> 0.000</td> <td>    0.164</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.3213</td> <td>    0.029</td> <td>   11.051</td> <td> 0.000</td> <td>    0.264</td> <td>    0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.2862</td> <td>    0.026</td> <td>   11.156</td> <td> 0.000</td> <td>    0.236</td> <td>    0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0934</td> <td>    0.032</td> <td>    2.956</td> <td> 0.003</td> <td>    0.031</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.1766</td> <td>    0.021</td> <td>    8.422</td> <td> 0.000</td> <td>    0.135</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.1867</td> <td>    0.023</td> <td>    8.059</td> <td> 0.000</td> <td>    0.141</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.2506</td> <td>    0.023</td> <td>   11.051</td> <td> 0.000</td> <td>    0.206</td> <td>    0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.3021</td> <td>    0.034</td> <td>    8.767</td> <td> 0.000</td> <td>    0.235</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2603</td> <td>    0.028</td> <td>    9.241</td> <td> 0.000</td> <td>    0.205</td> <td>    0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.3318</td> <td>    0.046</td> <td>    7.222</td> <td> 0.000</td> <td>    0.242</td> <td>    0.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.1877</td> <td>    0.033</td> <td>    5.728</td> <td> 0.000</td> <td>    0.123</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.2642</td> <td>    0.032</td> <td>    8.223</td> <td> 0.000</td> <td>    0.201</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.3268</td> <td>    0.033</td> <td>   10.013</td> <td> 0.000</td> <td>    0.263</td> <td>    0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.3980</td> <td>    0.034</td> <td>   11.612</td> <td> 0.000</td> <td>    0.331</td> <td>    0.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.5001</td> <td>    0.037</td> <td>   13.574</td> <td> 0.000</td> <td>    0.428</td> <td>    0.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.6156</td> <td>    0.047</td> <td>   13.210</td> <td> 0.000</td> <td>    0.524</td> <td>    0.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.6968</td> <td>    0.058</td> <td>   12.041</td> <td> 0.000</td> <td>    0.583</td> <td>    0.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>   -0.2392</td> <td>    0.024</td> <td>   -9.959</td> <td> 0.000</td> <td>   -0.286</td> <td>   -0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.1428</td> <td>    0.018</td> <td>   -7.719</td> <td> 0.000</td> <td>   -0.179</td> <td>   -0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.0927</td> <td>    0.015</td> <td>   -6.088</td> <td> 0.000</td> <td>   -0.123</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>    0.0746</td> <td>    0.029</td> <td>    2.574</td> <td> 0.010</td> <td>    0.018</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>   -0.0914</td> <td>    0.042</td> <td>   -2.161</td> <td> 0.031</td> <td>   -0.174</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.2390</td> <td>    0.043</td> <td>   -5.529</td> <td> 0.000</td> <td>   -0.324</td> <td>   -0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.1454</td> <td>    0.043</td> <td>   -3.378</td> <td> 0.001</td> <td>   -0.230</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.0628</td> <td>    0.017</td> <td>   -3.697</td> <td> 0.000</td> <td>   -0.096</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.3257</td> <td>    0.072</td> <td>   -4.512</td> <td> 0.000</td> <td>   -0.467</td> <td>   -0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.1261</td> <td>    0.031</td> <td>   -4.120</td> <td> 0.000</td> <td>   -0.186</td> <td>   -0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.1213</td> <td>    0.028</td> <td>   -4.389</td> <td> 0.000</td> <td>   -0.175</td> <td>   -0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.1564</td> <td>    0.074</td> <td>   -2.108</td> <td> 0.035</td> <td>   -0.302</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.1499</td> <td>    0.073</td> <td>   -2.045</td> <td> 0.041</td> <td>   -0.294</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.1510</td> <td>    0.073</td> <td>   -2.067</td> <td> 0.039</td> <td>   -0.294</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.1900</td> <td>    0.074</td> <td>   -2.581</td> <td> 0.010</td> <td>   -0.334</td> <td>   -0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.2825</td> <td>    0.080</td> <td>   -3.549</td> <td> 0.000</td> <td>   -0.439</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>   -0.3024</td> <td>    0.092</td> <td>   -3.288</td> <td> 0.001</td> <td>   -0.483</td> <td>   -0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>    0.1341</td> <td>    0.022</td> <td>    5.992</td> <td> 0.000</td> <td>    0.090</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -0.0503</td> <td>    0.026</td> <td>   -1.936</td> <td> 0.053</td> <td>   -0.101</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>    0.0655</td> <td>    0.011</td> <td>    6.068</td> <td> 0.000</td> <td>    0.044</td> <td>    0.087</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>274.731</td> <th>  Durbin-Watson:     </th> <td>   1.950</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1035.211</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.877</td>  <th>  Prob(JB):          </th> <td>1.61e-225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.737</td>  <th>  Cond. No.          </th> <td>    452.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.878\n",
       "Model:                            OLS   Adj. R-squared:                  0.874\n",
       "Method:                 Least Squares   F-statistic:                     206.4\n",
       "Date:                Sat, 11 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        00:21:01   Log-Likelihood:                 801.23\n",
       "No. Observations:                1458   AIC:                            -1502.\n",
       "Df Residuals:                    1408   BIC:                            -1238.\n",
       "Df Model:                          49                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          8.8413      0.190     46.477      0.000       8.468       9.214\n",
       "x1             0.4490      0.022     20.818      0.000       0.407       0.491\n",
       "x2             0.2107      0.040      5.328      0.000       0.133       0.288\n",
       "x3            -0.0614      0.038     -1.622      0.105      -0.136       0.013\n",
       "x4             0.1264      0.022      5.746      0.000       0.083       0.170\n",
       "x5             0.3168      0.030     10.503      0.000       0.258       0.376\n",
       "x6             0.2442      0.019     12.828      0.000       0.207       0.282\n",
       "x7             0.2851      0.024     12.032      0.000       0.239       0.332\n",
       "x8             0.0924      0.019      4.986      0.000       0.056       0.129\n",
       "x9             0.2289      0.022     10.384      0.000       0.186       0.272\n",
       "x10            0.1966      0.024      8.137      0.000       0.149       0.244\n",
       "x11            0.1792      0.015     11.697      0.000       0.149       0.209\n",
       "x12            0.1445      0.050      2.862      0.004       0.045       0.243\n",
       "x13            0.2071      0.022      9.367      0.000       0.164       0.251\n",
       "x14            0.3213      0.029     11.051      0.000       0.264       0.378\n",
       "x15            0.2862      0.026     11.156      0.000       0.236       0.337\n",
       "x16            0.0934      0.032      2.956      0.003       0.031       0.155\n",
       "x17            0.1766      0.021      8.422      0.000       0.135       0.218\n",
       "x18            0.1867      0.023      8.059      0.000       0.141       0.232\n",
       "x19            0.2506      0.023     11.051      0.000       0.206       0.295\n",
       "x20            0.3021      0.034      8.767      0.000       0.235       0.370\n",
       "x21            0.2603      0.028      9.241      0.000       0.205       0.316\n",
       "x22            0.3318      0.046      7.222      0.000       0.242       0.422\n",
       "x23            0.1877      0.033      5.728      0.000       0.123       0.252\n",
       "x24            0.2642      0.032      8.223      0.000       0.201       0.327\n",
       "x25            0.3268      0.033     10.013      0.000       0.263       0.391\n",
       "x26            0.3980      0.034     11.612      0.000       0.331       0.465\n",
       "x27            0.5001      0.037     13.574      0.000       0.428       0.572\n",
       "x28            0.6156      0.047     13.210      0.000       0.524       0.707\n",
       "x29            0.6968      0.058     12.041      0.000       0.583       0.810\n",
       "x30           -0.2392      0.024     -9.959      0.000      -0.286      -0.192\n",
       "x31           -0.1428      0.018     -7.719      0.000      -0.179      -0.106\n",
       "x32           -0.0927      0.015     -6.088      0.000      -0.123      -0.063\n",
       "x33            0.0746      0.029      2.574      0.010       0.018       0.131\n",
       "x34           -0.0914      0.042     -2.161      0.031      -0.174      -0.008\n",
       "x35           -0.2390      0.043     -5.529      0.000      -0.324      -0.154\n",
       "x36           -0.1454      0.043     -3.378      0.001      -0.230      -0.061\n",
       "x37           -0.0628      0.017     -3.697      0.000      -0.096      -0.029\n",
       "x38           -0.3257      0.072     -4.512      0.000      -0.467      -0.184\n",
       "x39           -0.1261      0.031     -4.120      0.000      -0.186      -0.066\n",
       "x40           -0.1213      0.028     -4.389      0.000      -0.175      -0.067\n",
       "x41           -0.1564      0.074     -2.108      0.035      -0.302      -0.011\n",
       "x42           -0.1499      0.073     -2.045      0.041      -0.294      -0.006\n",
       "x43           -0.1510      0.073     -2.067      0.039      -0.294      -0.008\n",
       "x44           -0.1900      0.074     -2.581      0.010      -0.334      -0.046\n",
       "x45           -0.2825      0.080     -3.549      0.000      -0.439      -0.126\n",
       "x46           -0.3024      0.092     -3.288      0.001      -0.483      -0.122\n",
       "x47            0.1341      0.022      5.992      0.000       0.090       0.178\n",
       "x48           -0.0503      0.026     -1.936      0.053      -0.101       0.001\n",
       "x49            0.0655      0.011      6.068      0.000       0.044       0.087\n",
       "==============================================================================\n",
       "Omnibus:                      274.731   Durbin-Watson:                   1.950\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1035.211\n",
       "Skew:                          -0.877   Prob(JB):                    1.61e-225\n",
       "Kurtosis:                       6.737   Cond. No.                         452.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables for the multiple linear regression\n",
    "X_13 = data_encoded[[\"GrLivArea\",\"Neighborhood_Blmngtn\",\"Neighborhood_BrDale\",\"Neighborhood_BrkSide\",\"Neighborhood_ClearCr\",\"Neighborhood_CollgCr\",\"Neighborhood_Crawfor\",\"Neighborhood_Edwards\",\"Neighborhood_Gilbert\",\"Neighborhood_Mitchel\",\"Neighborhood_NAmes\",\"Neighborhood_NPkVill\",\"Neighborhood_NWAmes\",\"Neighborhood_NoRidge\",\"Neighborhood_NridgHt\",\"Neighborhood_SWISU\",\"Neighborhood_Sawyer\",\"Neighborhood_SawyerW\",\"Neighborhood_Somerst\",\"Neighborhood_StoneBr\",\"Neighborhood_Timber\",\"Neighborhood_Veenker\",\"OverallQual_4\",\"OverallQual_5\",\"OverallQual_6\",\"OverallQual_7\",\"OverallQual_8\",\"OverallQual_9\",\"OverallQual_10\",\"GarageCars_0\",\"GarageCars_1\",\"GarageCars_2\",\"ExterQual_Ex\",\"ExterQual_Fa\",\"BsmtFullBath_0\",\"BsmtFullBath_1\",\"BsmtHalfBath_0\",\"FullBath_0\",\"FullBath_1\",\"FullBath_2\",\"BedroomAbvGr_1\",\"BedroomAbvGr_2\",\"BedroomAbvGr_3\",\"BedroomAbvGr_4\",\"BedroomAbvGr_5\",\"BedroomAbvGr_6\",\"KitchenQual_Ex\",\"KitchenQual_Fa\",\"KitchenQual_Gd\"]]\n",
    "# Ignores these variables to avoid the dummy variable trap: \"Neighborhood_Blueste\",\"OverallQual_1\", \"GarageCars_4\",\"ExterQual_TA\", \"BsmtFullBath_3\",\"BsmtHalfBath_2\",\"HalfBath_2\",\"FullBath_3\",\"BedroomAbvGr_8\",\"KitchenQual_TA\"\n",
    "# Removing these variables because they're not statistically significant: \"OverallQual_3\",\"Neighborhood_MeadowV\", \"GarageCars_3\",\"OverallQual_2\",\"BedroomAbvGr_0\",\"HalfBath_0\",\"HalfBath_1\",\"BsmtFullBath_2\",\"ExterQual_Gd\",\"BsmtHalfBath_1\",\"Neighborhood_IDOTRR\",\n",
    "# Redefine X\n",
    "X = X_13.values\n",
    "# Split data into training and testing set\n",
    "# random_state ensures answers are reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2, random_state = 0)\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "regressor = LinearRegression()\n",
    "# fitting linear regressor to our training dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Build the optimal model using backward elimination\n",
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "# X_opt = X[:, [0,1]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   210.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:22:23</td>     <th>  Log-Likelihood:    </th> <td>  799.29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1458</td>      <th>  AIC:               </th> <td>  -1501.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1409</td>      <th>  BIC:               </th> <td>  -1242.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    48</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    8.8369</td> <td>    0.190</td> <td>   46.412</td> <td> 0.000</td> <td>    8.463</td> <td>    9.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4488</td> <td>    0.022</td> <td>   20.785</td> <td> 0.000</td> <td>    0.406</td> <td>    0.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.2109</td> <td>    0.040</td> <td>    5.327</td> <td> 0.000</td> <td>    0.133</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0601</td> <td>    0.038</td> <td>   -1.585</td> <td> 0.113</td> <td>   -0.134</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1210</td> <td>    0.022</td> <td>    5.539</td> <td> 0.000</td> <td>    0.078</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3175</td> <td>    0.030</td> <td>   10.516</td> <td> 0.000</td> <td>    0.258</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2438</td> <td>    0.019</td> <td>   12.795</td> <td> 0.000</td> <td>    0.206</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2824</td> <td>    0.024</td> <td>   11.927</td> <td> 0.000</td> <td>    0.236</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0910</td> <td>    0.019</td> <td>    4.910</td> <td> 0.000</td> <td>    0.055</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2288</td> <td>    0.022</td> <td>   10.368</td> <td> 0.000</td> <td>    0.185</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.1971</td> <td>    0.024</td> <td>    8.153</td> <td> 0.000</td> <td>    0.150</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1792</td> <td>    0.015</td> <td>   11.686</td> <td> 0.000</td> <td>    0.149</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.1453</td> <td>    0.051</td> <td>    2.875</td> <td> 0.004</td> <td>    0.046</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.2072</td> <td>    0.022</td> <td>    9.359</td> <td> 0.000</td> <td>    0.164</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.3206</td> <td>    0.029</td> <td>   11.016</td> <td> 0.000</td> <td>    0.263</td> <td>    0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.2856</td> <td>    0.026</td> <td>   11.123</td> <td> 0.000</td> <td>    0.235</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0866</td> <td>    0.031</td> <td>    2.756</td> <td> 0.006</td> <td>    0.025</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.1764</td> <td>    0.021</td> <td>    8.406</td> <td> 0.000</td> <td>    0.135</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.1870</td> <td>    0.023</td> <td>    8.063</td> <td> 0.000</td> <td>    0.141</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.2501</td> <td>    0.023</td> <td>   11.021</td> <td> 0.000</td> <td>    0.206</td> <td>    0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.3018</td> <td>    0.034</td> <td>    8.750</td> <td> 0.000</td> <td>    0.234</td> <td>    0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2597</td> <td>    0.028</td> <td>    9.212</td> <td> 0.000</td> <td>    0.204</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.3316</td> <td>    0.046</td> <td>    7.211</td> <td> 0.000</td> <td>    0.241</td> <td>    0.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.1916</td> <td>    0.033</td> <td>    5.854</td> <td> 0.000</td> <td>    0.127</td> <td>    0.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.2703</td> <td>    0.032</td> <td>    8.445</td> <td> 0.000</td> <td>    0.208</td> <td>    0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.3321</td> <td>    0.033</td> <td>   10.201</td> <td> 0.000</td> <td>    0.268</td> <td>    0.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.4034</td> <td>    0.034</td> <td>   11.799</td> <td> 0.000</td> <td>    0.336</td> <td>    0.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.5054</td> <td>    0.037</td> <td>   13.742</td> <td> 0.000</td> <td>    0.433</td> <td>    0.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.6205</td> <td>    0.047</td> <td>   13.324</td> <td> 0.000</td> <td>    0.529</td> <td>    0.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.7014</td> <td>    0.058</td> <td>   12.119</td> <td> 0.000</td> <td>    0.588</td> <td>    0.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>   -0.2440</td> <td>    0.024</td> <td>  -10.204</td> <td> 0.000</td> <td>   -0.291</td> <td>   -0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.1439</td> <td>    0.019</td> <td>   -7.776</td> <td> 0.000</td> <td>   -0.180</td> <td>   -0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.0929</td> <td>    0.015</td> <td>   -6.094</td> <td> 0.000</td> <td>   -0.123</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>    0.0748</td> <td>    0.029</td> <td>    2.579</td> <td> 0.010</td> <td>    0.018</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>   -0.1123</td> <td>    0.041</td> <td>   -2.742</td> <td> 0.006</td> <td>   -0.193</td> <td>   -0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.2418</td> <td>    0.043</td> <td>   -5.592</td> <td> 0.000</td> <td>   -0.327</td> <td>   -0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.1477</td> <td>    0.043</td> <td>   -3.431</td> <td> 0.001</td> <td>   -0.232</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.0624</td> <td>    0.017</td> <td>   -3.665</td> <td> 0.000</td> <td>   -0.096</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.3263</td> <td>    0.072</td> <td>   -4.515</td> <td> 0.000</td> <td>   -0.468</td> <td>   -0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.1266</td> <td>    0.031</td> <td>   -4.134</td> <td> 0.000</td> <td>   -0.187</td> <td>   -0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.1221</td> <td>    0.028</td> <td>   -4.413</td> <td> 0.000</td> <td>   -0.176</td> <td>   -0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.1550</td> <td>    0.074</td> <td>   -2.088</td> <td> 0.037</td> <td>   -0.301</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.1467</td> <td>    0.073</td> <td>   -2.000</td> <td> 0.046</td> <td>   -0.291</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.1474</td> <td>    0.073</td> <td>   -2.015</td> <td> 0.044</td> <td>   -0.291</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   -0.1861</td> <td>    0.074</td> <td>   -2.527</td> <td> 0.012</td> <td>   -0.331</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.2816</td> <td>    0.080</td> <td>   -3.534</td> <td> 0.000</td> <td>   -0.438</td> <td>   -0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>   -0.3035</td> <td>    0.092</td> <td>   -3.297</td> <td> 0.001</td> <td>   -0.484</td> <td>   -0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>    0.1354</td> <td>    0.022</td> <td>    6.050</td> <td> 0.000</td> <td>    0.092</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>    0.0667</td> <td>    0.011</td> <td>    6.181</td> <td> 0.000</td> <td>    0.046</td> <td>    0.088</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>269.719</td> <th>  Durbin-Watson:     </th> <td>   1.950</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1009.418</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.863</td>  <th>  Prob(JB):          </th> <td>6.42e-220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.693</td>  <th>  Cond. No.          </th> <td>    452.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.877\n",
       "Model:                            OLS   Adj. R-squared:                  0.873\n",
       "Method:                 Least Squares   F-statistic:                     210.3\n",
       "Date:                Sat, 11 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        00:22:23   Log-Likelihood:                 799.29\n",
       "No. Observations:                1458   AIC:                            -1501.\n",
       "Df Residuals:                    1409   BIC:                            -1242.\n",
       "Df Model:                          48                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          8.8369      0.190     46.412      0.000       8.463       9.210\n",
       "x1             0.4488      0.022     20.785      0.000       0.406       0.491\n",
       "x2             0.2109      0.040      5.327      0.000       0.133       0.289\n",
       "x3            -0.0601      0.038     -1.585      0.113      -0.134       0.014\n",
       "x4             0.1210      0.022      5.539      0.000       0.078       0.164\n",
       "x5             0.3175      0.030     10.516      0.000       0.258       0.377\n",
       "x6             0.2438      0.019     12.795      0.000       0.206       0.281\n",
       "x7             0.2824      0.024     11.927      0.000       0.236       0.329\n",
       "x8             0.0910      0.019      4.910      0.000       0.055       0.127\n",
       "x9             0.2288      0.022     10.368      0.000       0.185       0.272\n",
       "x10            0.1971      0.024      8.153      0.000       0.150       0.245\n",
       "x11            0.1792      0.015     11.686      0.000       0.149       0.209\n",
       "x12            0.1453      0.051      2.875      0.004       0.046       0.244\n",
       "x13            0.2072      0.022      9.359      0.000       0.164       0.251\n",
       "x14            0.3206      0.029     11.016      0.000       0.263       0.378\n",
       "x15            0.2856      0.026     11.123      0.000       0.235       0.336\n",
       "x16            0.0866      0.031      2.756      0.006       0.025       0.148\n",
       "x17            0.1764      0.021      8.406      0.000       0.135       0.218\n",
       "x18            0.1870      0.023      8.063      0.000       0.141       0.232\n",
       "x19            0.2501      0.023     11.021      0.000       0.206       0.295\n",
       "x20            0.3018      0.034      8.750      0.000       0.234       0.369\n",
       "x21            0.2597      0.028      9.212      0.000       0.204       0.315\n",
       "x22            0.3316      0.046      7.211      0.000       0.241       0.422\n",
       "x23            0.1916      0.033      5.854      0.000       0.127       0.256\n",
       "x24            0.2703      0.032      8.445      0.000       0.208       0.333\n",
       "x25            0.3321      0.033     10.201      0.000       0.268       0.396\n",
       "x26            0.4034      0.034     11.799      0.000       0.336       0.471\n",
       "x27            0.5054      0.037     13.742      0.000       0.433       0.577\n",
       "x28            0.6205      0.047     13.324      0.000       0.529       0.712\n",
       "x29            0.7014      0.058     12.119      0.000       0.588       0.815\n",
       "x30           -0.2440      0.024    -10.204      0.000      -0.291      -0.197\n",
       "x31           -0.1439      0.019     -7.776      0.000      -0.180      -0.108\n",
       "x32           -0.0929      0.015     -6.094      0.000      -0.123      -0.063\n",
       "x33            0.0748      0.029      2.579      0.010       0.018       0.132\n",
       "x34           -0.1123      0.041     -2.742      0.006      -0.193      -0.032\n",
       "x35           -0.2418      0.043     -5.592      0.000      -0.327      -0.157\n",
       "x36           -0.1477      0.043     -3.431      0.001      -0.232      -0.063\n",
       "x37           -0.0624      0.017     -3.665      0.000      -0.096      -0.029\n",
       "x38           -0.3263      0.072     -4.515      0.000      -0.468      -0.185\n",
       "x39           -0.1266      0.031     -4.134      0.000      -0.187      -0.067\n",
       "x40           -0.1221      0.028     -4.413      0.000      -0.176      -0.068\n",
       "x41           -0.1550      0.074     -2.088      0.037      -0.301      -0.009\n",
       "x42           -0.1467      0.073     -2.000      0.046      -0.291      -0.003\n",
       "x43           -0.1474      0.073     -2.015      0.044      -0.291      -0.004\n",
       "x44           -0.1861      0.074     -2.527      0.012      -0.331      -0.042\n",
       "x45           -0.2816      0.080     -3.534      0.000      -0.438      -0.125\n",
       "x46           -0.3035      0.092     -3.297      0.001      -0.484      -0.123\n",
       "x47            0.1354      0.022      6.050      0.000       0.092       0.179\n",
       "x48            0.0667      0.011      6.181      0.000       0.046       0.088\n",
       "==============================================================================\n",
       "Omnibus:                      269.719   Durbin-Watson:                   1.950\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1009.418\n",
       "Skew:                          -0.863   Prob(JB):                    6.42e-220\n",
       "Kurtosis:                       6.693   Cond. No.                         452.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables for the multiple linear regression\n",
    "X_14 = data_encoded[[\"GrLivArea\",\"Neighborhood_Blmngtn\",\"Neighborhood_BrDale\",\"Neighborhood_BrkSide\",\"Neighborhood_ClearCr\",\"Neighborhood_CollgCr\",\"Neighborhood_Crawfor\",\"Neighborhood_Edwards\",\"Neighborhood_Gilbert\",\"Neighborhood_Mitchel\",\"Neighborhood_NAmes\",\"Neighborhood_NPkVill\",\"Neighborhood_NWAmes\",\"Neighborhood_NoRidge\",\"Neighborhood_NridgHt\",\"Neighborhood_SWISU\",\"Neighborhood_Sawyer\",\"Neighborhood_SawyerW\",\"Neighborhood_Somerst\",\"Neighborhood_StoneBr\",\"Neighborhood_Timber\",\"Neighborhood_Veenker\",\"OverallQual_4\",\"OverallQual_5\",\"OverallQual_6\",\"OverallQual_7\",\"OverallQual_8\",\"OverallQual_9\",\"OverallQual_10\",\"GarageCars_0\",\"GarageCars_1\",\"GarageCars_2\",\"ExterQual_Ex\",\"ExterQual_Fa\",\"BsmtFullBath_0\",\"BsmtFullBath_1\",\"BsmtHalfBath_0\",\"FullBath_0\",\"FullBath_1\",\"FullBath_2\",\"BedroomAbvGr_1\",\"BedroomAbvGr_2\",\"BedroomAbvGr_3\",\"BedroomAbvGr_4\",\"BedroomAbvGr_5\",\"BedroomAbvGr_6\",\"KitchenQual_Ex\",\"KitchenQual_Gd\"]]\n",
    "# Ignores these variables to avoid the dummy variable trap: \"Neighborhood_Blueste\",\"OverallQual_1\", \"GarageCars_4\",\"ExterQual_TA\", \"BsmtFullBath_3\",\"BsmtHalfBath_2\",\"HalfBath_2\",\"FullBath_3\",\"BedroomAbvGr_8\",\"KitchenQual_TA\"\n",
    "# Removing these variables because they're not statistically significant: \"OverallQual_3\",\"Neighborhood_MeadowV\", \"GarageCars_3\",\"OverallQual_2\",\"BedroomAbvGr_0\",\"HalfBath_0\",\"HalfBath_1\",\"BsmtFullBath_2\",\"ExterQual_Gd\",\"BsmtHalfBath_1\",\"Neighborhood_IDOTRR\",\"KitchenQual_Fa\",\n",
    "# Redefine X\n",
    "X = X_14.values\n",
    "# Split data into training and testing set\n",
    "# random_state ensures answers are reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .2, random_state = 0)\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "regressor = LinearRegression()\n",
    "# fitting linear regressor to our training dataset\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "# Build the optimal model using backward elimination\n",
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "# X_opt = X[:, [0,1]]\n",
    "regressor_ols = sm.OLS(endog = y, exog = X).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8725874605001136\n",
      "Testing Score: 0.8809642640991775\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data and calculate the scores for the training and testing data\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "training_score = regressor.score(X_train, y_train)\n",
    "testing_score = regressor.score(X_test, y_test)\n",
    "\n",
    "### END SOLUTION \n",
    "\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
